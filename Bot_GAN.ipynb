{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bot_GAN.ipynb",
      "private_outputs": true,
      "provenance": [],
      "mount_file_id": "1d1wgTIl-szOE6Rh0Xtkma0cArxXB3PKM",
      "authorship_tag": "ABX9TyMSr3AoRRRrl7i3Q5Grz04K",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DanhKiD/Bot_GAN/blob/main/Bot_GAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FmTLQuRA2mBB"
      },
      "source": [
        "from keras.activations import sigmoid\n",
        "from keras.backend import binary_crossentropy\n",
        "from keras.layers import Input, Dense, Activation, dense_attention\n",
        "from keras.layers.merge import Maximum, Concatenate\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam\n",
        "from numpy.lib.function_base import blackman\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn import linear_model, svm, tree\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "#from VOTEClassifier import VOTEClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ha_2dRdH4Ftn"
      },
      "source": [
        "class BotGAN():\n",
        "    def __init__(self, blackbox='RF', same_train_data=1, filename='/content/drive/MyDrive/Dataset/train.csv') -> None:\n",
        "        self.apifeatures_dims = 53\n",
        "        self.z_dims = 10\n",
        "        self.hide_layers = 256\n",
        "        self.generator_layers = [self.apifeatures_dims + self.z_dims, self.hide_layers, self.apifeatures_dims]\n",
        "        self.substitue_detector_layers = [self.apifeatures_dims, self.hide_layers, 1]\n",
        "        self.blackbox = blackbox  # RF, LR, DT, SVM, MLP, VOTE\n",
        "        self.same_train_data = same_train_data # BotGAN and the blackbox_detector are trained on same or different training set\n",
        "        optimizer = Adam(learning_rate=0.001)\n",
        "        self.filename = filename\n",
        "\n",
        "        # Build and Train blackbox_detector\n",
        "        self.blackbox_detector = self.build_blackbox_detector()\n",
        "\n",
        "        # Build and compile the substitute_detector\n",
        "        self.substitue_detector = self.build_substitute_detector()\n",
        "        self.substitue_detector.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "        # Build the generator\n",
        "        self.generator = self.build_generator()\n",
        "\n",
        "        #The generator takes botnet and noise as input and generates adversarial botnet examples\n",
        "        examples = Input(shape=(self.apifeatures_dims,))\n",
        "        noise = Input(shape=(self.z_dims,))\n",
        "        input = [examples, noise]\n",
        "        botnet_examples = self.generator(input)\n",
        "\n",
        "        # For the combine model we will only train the generator\n",
        "        self.substitue_detector.trainable = False\n",
        "\n",
        "        # The discriminator takes generated botnet as input an determines validity\n",
        "        validity = self.substitue_detector(botnet_examples)\n",
        "\n",
        "        # The combine model (stacked generator and substitute_detector)\n",
        "        # Trains the generator to fool the discriminator\n",
        "        self.combine = Model(input, validity)\n",
        "        self.combine.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
        "    \n",
        "    def build_blackbox_detector(self):\n",
        "        blackbox_detector = None\n",
        "        if self.blackbox == 'RF':\n",
        "            blackbox_detector = RandomForestClassifier(n_estimators=100, max_depth=3, random_state=1)\n",
        "        elif self.blackbox == 'SVM':\n",
        "            blackbox_detector = svm.SVC()\n",
        "        elif self.blackbox == 'LR':\n",
        "            blackbox_detector = linear_model.LogisticRegression()\n",
        "        elif self.blackbox == 'DT':\n",
        "            blackbox_detector = tree.DecisionTreeRegressor()\n",
        "        elif self.blackbox == 'MLP':\n",
        "            blackbox_detector = MLPClassifier(hidden_layer_sizes=(10,), max_iter=10, alpha=1e-1,\n",
        "                                solver='sgd', verbose=0, tol=1e-4, random_state=1,\n",
        "                                learning_rate_init=.1)\n",
        "        #elif self.blackbox == 'VOTE':\n",
        "        #    blackbox_detector = VOTEClassifier()\n",
        "        \n",
        "        return blackbox_detector\n",
        "\n",
        "    def build_generator(self):\n",
        "        examples = Input(shape=(self.apifeatures_dims,))\n",
        "        noise = Input(shape=(self.z_dims,))\n",
        "        x = Concatenate(axis=1)([examples, noise])\n",
        "        for dim in self.generator_layers[1:]:\n",
        "            x = Dense(dim)(x)\n",
        "        x = Activation(activation='sigmoid')(x)\n",
        "        x = Maximum()([examples, x])\n",
        "        generator = Model([examples, noise], x, name='generator')\n",
        "        generator.summary()\n",
        "\n",
        "        return generator\n",
        "\n",
        "    def build_substitute_detector(self):\n",
        "        input = Input(shape=(self.substitue_detector_layers[0],))\n",
        "        x = input\n",
        "        for dim in self.substitue_detector_layers[1:]:\n",
        "            x = Dense(dim)(x)\n",
        "        x = Activation(activation='sigmoid')(x)\n",
        "        substitute_detector = Model(input, x, name='substitute_detector')\n",
        "        substitute_detector.summary()\n",
        "\n",
        "        return substitute_detector\n",
        "\n",
        "    def preprocessing(self):\n",
        "        # Load dataset\n",
        "        data = pd.read_csv(self.filename)\n",
        "        \n",
        "        # Drop unnecessary columns\n",
        "        data.drop([\"pkSeqID\",\"seq\",\"subcategory\", \"category\"], axis=1, inplace=True)\n",
        "        \n",
        "        # Convert source port from hex to dec\n",
        "        data['sport']=data['sport'].replace(['0x0303'],'771') \n",
        "        data['sport']=data['sport'].replace(['0x0011'],'17')\n",
        "        data['sport']=data['sport'].replace(['0x000d'],'13')\n",
        "        data['sport']=data['sport'].replace(['0x0008'],'8')\n",
        "\n",
        "        # Change type from object to int\n",
        "        data[\"sport\"] = data[\"sport\"].astype(str).astype(int)\n",
        "\n",
        "        # Encoding data\n",
        "        le = LabelEncoder()\n",
        "        data[\"saddr_enc\"]= le.fit_transform(data.saddr)\n",
        "        data[\"daddr_enc\"]= le.fit_transform(data.daddr)\n",
        "        data[\"proto_enc\"]= le.fit_transform(data.proto)\n",
        "        data.drop(['saddr','daddr','proto'], axis=1, inplace=True)\n",
        "\n",
        "        # Convert dest port from hex to dec\n",
        "        data['dport']=data.dport.apply(lambda x: int(x,16) if len(x)>1 and x[1]==\"x\" else int(x))\n",
        "\n",
        "        # Swap label to end\n",
        "        titles = list(data.columns)\n",
        "        titles[11], titles[14] = titles[14], titles[11]\n",
        "        data = data[titles]\n",
        "        del titles\n",
        "        # Scale dataset\n",
        "        label = data['attack']\n",
        "        scaler=StandardScaler()\n",
        "        features = data.iloc[:,:-1]\n",
        "        cols=features.columns\n",
        "        scaled_features= scaler.fit_transform(features)\n",
        "        pre_data = pd.DataFrame(scaled_features,columns=cols)\n",
        "        pre_data['attack'] = label.values\n",
        "        del label\n",
        "        \n",
        "        return pre_data\n",
        "\n",
        "    def load_data(self):\n",
        "        #data = self.preprocessing()\n",
        "        data = pd.read_csv('/content/drive/MyDrive/Dataset/train.csv')\n",
        "        ynor = np.array(data[data['label'] == 0]['label'])\n",
        "        ybot = np.array(data[data['label'] == 1]['label'])\n",
        "        xnor = np.array(data[data['label'] == 0].iloc[:, :-1])\n",
        "        xbot = np.array(data[data['label'] == 1].iloc[:, :-1])\n",
        "        #xbot = data.loc[np.random.choice(data[data['attack'] == 1].index.values, 1148)].iloc[:, :-1]\n",
        "        \n",
        "        return (xbot, ybot), (xnor, ynor)\n",
        "\n",
        "    def train(self, epochs, batch_size=32, is_first=1):\n",
        "        # Load and split the dataset\n",
        "        (xbot, ybot), (xnor, ynor) = self.load_data()\n",
        "        xtrain_bot, xtest_bot, ytrain_bot, ytest_bot = train_test_split(xbot, ybot, test_size=0.3)\n",
        "        xtrain_nor, xtest_nor, ytrain_nor, ytest_nor = train_test_split(xnor, ynor, test_size=0.3)\n",
        "        if self.same_train_data:\n",
        "            bl_xtrain_bot, bl_ytrain_bot, bl_xtrain_nor, bl_ytrain_nor = xtrain_bot, ytrain_bot, xtrain_nor, ytrain_nor\n",
        "        else:\n",
        "            xtrain_bot, bl_xtrain_bot, ytrain_bot, bl_ytrain_bot = train_test_split(xtrain_bot, ytrain_bot, test_size=0.5)\n",
        "            xtrain_nor, bl_xtrain_nor, ytrain_nor, bl_ytrain_nor = train_test_split(xtrain_nor, ytrain_nor, test_size=0.5)\n",
        "        \n",
        "        # If is_first is True, train the blackbox_detector\n",
        "        if is_first:\n",
        "            self.blackbox_detector.fit(np.concatenate([xbot, xnor]), \n",
        "                                    np.concatenate([ybot, ynor]))\n",
        "\n",
        "        ytrain_nor_blackbox = self.blackbox_detector.predict(bl_xtrain_nor)\n",
        "        Original_Train_TPR = self.blackbox_detector.score(bl_xtrain_bot, bl_ytrain_bot)\n",
        "        Original_Test_TPR = self.blackbox_detector.score(xtest_bot, ytest_bot)\n",
        "        Train_TPR, Test_TPR = [Original_Train_TPR], [Original_Test_TPR]\n",
        "        best_TPR = 1.0\n",
        "        print(Train_TPR, Test_TPR, '\\n')\n",
        "        print('Training epochs.....')\n",
        "        for epoch in range(epochs):\n",
        "            for step in range(xtrain_bot.shape[0] // batch_size):\n",
        "                # Train substitute_detector\n",
        "\n",
        "                # Select a random batch of botnet examples\n",
        "                idx = np.random.randint(0, xtrain_bot.shape[0], batch_size)\n",
        "                xbot_batch = xtrain_bot[idx]\n",
        "                noise = np.random.uniform(0, 1, (batch_size, self.z_dims))\n",
        "                idx = np.random.randint(0, xbot_batch.shape[0], batch_size)\n",
        "                xnor_batch = xtrain_nor[idx]\n",
        "                ynor_batch = ytrain_nor_blackbox[idx]\n",
        "\n",
        "                # Generate a batch of new malware examples\n",
        "                gen_examples = self.generator.predict([xnor_batch, noise])\n",
        "                ybot_batch = self.blackbox_detector.predict(np.ones(gen_examples.shape)*(gen_examples > 0.5))\n",
        "\n",
        "                # Train the substitute_detector\n",
        "                d_loss_real = self.substitue_detector.train_on_batch(gen_examples, ybot_batch)\n",
        "                d_loss_fake = self.substitue_detector.train_on_batch(xnor_batch, ynor_batch)\n",
        "                d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
        "\n",
        "                # Train Generator\n",
        "                idx = np.random.randint(0, xtrain_bot.shape[0], batch_size)\n",
        "                xbot_batch = xtrain_bot[idx]\n",
        "                noise = np.random.uniform(0, 1, (batch_size, self.z_dims))\n",
        "\n",
        "                g_loss = self.combine.train_on_batch([xbot_batch, noise], np.zeros((batch_size, 1)))\n",
        "            \n",
        "            # Compute Train TPR\n",
        "            noise = np.random.uniform(0, 1, (xtrain_bot.shape[0], self.z_dims))\n",
        "            gen_examples = self.generator.predict([xtrain_bot, noise])\n",
        "            TPR = self.blackbox_detector.score(np.ones(gen_examples.shape) * (gen_examples > 0.5), ytrain_bot)\n",
        "            Train_TPR.append(TPR)\n",
        "\n",
        "            # Compute Test TPR\n",
        "            noise = np.random.uniform(0, 1, (xtest_bot.shape[0], self.z_dims))\n",
        "            gen_examples = self.generator.predict([xtest_bot, noise])\n",
        "            TPR = self.blackbox_detector.score(np.ones(gen_examples.shape) * (gen_examples > 0.5), ytest_bot)\n",
        "            Test_TPR.append(TPR)\n",
        "            print(Train_TPR[-1], Test_TPR[-1])\n",
        "\n",
        "            # Save best model\n",
        "            if TPR < best_TPR:\n",
        "                self.combine.save_weights('/content/drive/MyDrive/Dataset/saves/BotGAN.h5')\n",
        "                best_TPR = TPR\n",
        "            \n",
        "            # Plot the progress\n",
        "            if is_first:\n",
        "                print(\"%d [D loss: %f, acc.: %.4f%%] [G loss: %f]\" % (epoch, d_loss[0], 100*d_loss[1], g_loss))\n",
        "        \n",
        "        flag = ['DiffTrainData', 'SameTrainData']\n",
        "        print('\\n\\n---{0} {1}'.format(self.blackbox, flag[self.same_train_data]))\n",
        "        print('\\nOriginal_Train_TPR: {0}, Adver_Train_TPR: {1}'.format(Original_Train_TPR, Train_TPR[-1]))\n",
        "        print('\\nOriginal_Test_TPR: {0}, Adver_Test_TPR: {1}'.format(Original_Test_TPR, Test_TPR[-1]))\n",
        "\n",
        "        # Plot TPR\n",
        "        plt.figure()\n",
        "        plt.plot(range(len(Train_TPR)), Train_TPR, c='r', label='Training Set', linewidth=2)\n",
        "        plt.plot(range(len(Test_TPR)), Test_TPR, c='g', linestyle='--', label='Validation Set', linewidth=2)\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('TPR')\n",
        "        plt.legend()\n",
        "        plt.savefig('/content/drive/MyDrive/Dataset/saves/Epoch_TPR{0}, {1}, {2}.png'.format(self.blackbox, flag[self.same_train_data], is_first))\n",
        "        plt.show()\n",
        "\n",
        "    def retrain_blackbox_detector(self):\n",
        "        (xbot, ybot), (xnor, ynor) = self.load_data()\n",
        "        xtrain_bot, xtest_bot, ytrain_bot, ytest_bot = train_test_split(xbot, ybot, test_size=0.2)\n",
        "        xtrain_nor, xtest_nor, ytrain_nor, ytest_nor = train_test_split(xnor, ynor, test_size=0.2)\n",
        "\n",
        "        # Generate Train Adversarial Examples\n",
        "        noise = np.random.uniform(0, 1, (xtrain_bot.shape[0], self.z_dims))\n",
        "        gen_examples = self.generator.predict([xtrain_bot, noise])\n",
        "        gen_examples = np.ones(gen_examples.shape) * (gen_examples > 0.5)\n",
        "        self.blackbox_detector.fit(np.concatenate([xtrain_bot, xtrain_nor, gen_examples]), \n",
        "                                    np.concatenate([ytrain_bot, ytrain_nor, ytrain_bot]))\n",
        "        \n",
        "        # Compute train TPR\n",
        "        train_TPR = self.blackbox_detector.score(gen_examples, ytrain_bot)\n",
        "\n",
        "        # Compute test TPR\n",
        "        noise = np.random.uniform(0, 1, (xtest_bot.shape[0], self.z_dims))\n",
        "        gen_examples = self.generator.predict([xtest_bot, noise])\n",
        "        gen_examples = np.ones(gen_examples.shape) * (gen_examples > 0.5)\n",
        "        test_TPR = self.blackbox_detector.score(gen_examples, ytest_bot)\n",
        "\n",
        "        print('\\n---TPR after the blackbox_detector is retrained (Before retraining MalGAN).')\n",
        "        print('\\nTrain_TPR: {0}, Test_TPR: {1}'.format(train_TPR, test_TPR))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2LOsjEu0iHzG"
      },
      "source": [
        "botgan_RF = BotGAN(blackbox='RF')\n",
        "botgan_RF.train(epochs=500, batch_size=4096)\n",
        "botgan_RF.retrain_blackbox_detector()\n",
        "botgan_RF.train(epochs=100, batch_size=4096, is_first=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nKfyr2IzVclY"
      },
      "source": [
        "botgan_MLP = BotGAN(blackbox='MLP')\n",
        "botgan_MLP.train(epochs=500, batch_size=4096)\n",
        "botgan_MLP.retrain_blackbox_detector()\n",
        "botgan_MLP.train(epochs=100, batch_size=4096, is_first=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A590JtPheVPQ"
      },
      "source": [
        "botgan_LR = BotGAN(blackbox='LR')\n",
        "botgan_LR.train(epochs=500, batch_size=4096)\n",
        "botgan_LR.retrain_blackbox_detector()\n",
        "botgan_LR.train(epochs=100, batch_size=4096, is_first=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AFTYNGVDe2eV"
      },
      "source": [
        "botgan_SVM = BotGAN(blackbox='SVM')\n",
        "botgan_SVM.train(epochs=100, batch_size=4096)\n",
        "botgan_SVM.retrain_blackbox_detector()\n",
        "botgan_SVM.train(epochs=20, batch_size=4096, is_first=False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}