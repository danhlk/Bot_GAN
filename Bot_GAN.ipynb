{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bot_GAN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1d1wgTIl-szOE6Rh0Xtkma0cArxXB3PKM",
      "authorship_tag": "ABX9TyMAp0PKm1JQeyab7MVinhZD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DanhKiD/Bot_GAN/blob/main/Bot_GAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FmTLQuRA2mBB"
      },
      "source": [
        "from keras.activations import sigmoid\n",
        "from keras.backend import binary_crossentropy\n",
        "from keras.layers import Input, Dense, Activation, dense_attention\n",
        "from keras.layers.merge import Maximum, Concatenate\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam\n",
        "from numpy.lib.function_base import blackman\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn import linear_model, svm, tree\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "#from VOTEClassifier import VOTEClassifier"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ha_2dRdH4Ftn"
      },
      "source": [
        "class BotGAN():\n",
        "    def __init__(self, blackbox='RF', same_train_data=1, filename='/content/drive/MyDrive/Dataset/train.csv') -> None:\n",
        "        self.apifeatures_dims = 53\n",
        "        self.z_dims = 10\n",
        "        self.hide_layers = 256\n",
        "        self.generator_layers = [self.apifeatures_dims + self.z_dims, self.hide_layers, self.apifeatures_dims]\n",
        "        self.substitue_detector_layers = [self.apifeatures_dims, self.hide_layers, 1]\n",
        "        self.blackbox = blackbox  # RF, LR, DT, SVM, MLP, VOTE\n",
        "        self.same_train_data = same_train_data # BotGAN and the blackbox_detector are trained on same or different training set\n",
        "        optimizer = Adam(learning_rate=0.001)\n",
        "        self.filename = filename\n",
        "\n",
        "        # Build and Train blackbox_detector\n",
        "        self.blackbox_detector = self.build_blackbox_detector()\n",
        "\n",
        "        # Build and compile the substitute_detector\n",
        "        self.substitue_detector = self.build_substitute_detector()\n",
        "        self.substitue_detector.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "        # Build the generator\n",
        "        self.generator = self.build_generator()\n",
        "\n",
        "        #The generator takes botnet and noise as input and generates adversarial botnet examples\n",
        "        examples = Input(shape=(self.apifeatures_dims,))\n",
        "        noise = Input(shape=(self.z_dims,))\n",
        "        input = [examples, noise]\n",
        "        botnet_examples = self.generator(input)\n",
        "\n",
        "        # For the combine model we will only train the generator\n",
        "        self.substitue_detector.trainable = False\n",
        "\n",
        "        # The discriminator takes generated botnet as input an determines validity\n",
        "        validity = self.substitue_detector(botnet_examples)\n",
        "\n",
        "        # The combine model (stacked generator and substitute_detector)\n",
        "        # Trains the generator to fool the discriminator\n",
        "        self.combine = Model(input, validity)\n",
        "        self.combine.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
        "    \n",
        "    def build_blackbox_detector(self):\n",
        "        blackbox_detector = None\n",
        "        if self.blackbox == 'RF':\n",
        "            blackbox_detector = RandomForestClassifier(n_estimators=100, max_depth=3, random_state=1)\n",
        "        elif self.blackbox == 'SVM':\n",
        "            blackbox_detector = svm.SVC()\n",
        "        elif self.blackbox == 'LR':\n",
        "            blackbox_detector = linear_model.LogisticRegression()\n",
        "        elif self.blackbox == 'DT':\n",
        "            blackbox_detector = tree.DecisionTreeRegressor()\n",
        "        elif self.blackbox == 'MLP':\n",
        "            blackbox_detector = MLPClassifier(hidden_layer_sizes=(10,), max_iter=10, alpha=1e-1,\n",
        "                                solver='sgd', verbose=0, tol=1e-4, random_state=1,\n",
        "                                learning_rate_init=.1)\n",
        "        elif self.blackbox == 'GBC':\n",
        "            blackbox_detector = GradientBoostingClassifier(learning_rate=0.01, n_estimators=100, random_state=1)\n",
        "        #elif self.blackbox == 'VOTE':\n",
        "        #    blackbox_detector = VOTEClassifier()\n",
        "        \n",
        "        return blackbox_detector\n",
        "\n",
        "    def build_generator(self):\n",
        "        examples = Input(shape=(self.apifeatures_dims,))\n",
        "        noise = Input(shape=(self.z_dims,))\n",
        "        x = Concatenate(axis=1)([examples, noise])\n",
        "        for dim in self.generator_layers[1:]:\n",
        "            x = Dense(dim)(x)\n",
        "        x = Activation(activation='sigmoid')(x)\n",
        "        x = Maximum()([examples, x])\n",
        "        generator = Model([examples, noise], x, name='generator')\n",
        "        generator.summary()\n",
        "\n",
        "        return generator\n",
        "\n",
        "    def build_substitute_detector(self):\n",
        "        input = Input(shape=(self.substitue_detector_layers[0],))\n",
        "        x = input\n",
        "        for dim in self.substitue_detector_layers[1:]:\n",
        "            x = Dense(dim)(x)\n",
        "        x = Activation(activation='sigmoid')(x)\n",
        "        substitute_detector = Model(input, x, name='substitute_detector')\n",
        "        substitute_detector.summary()\n",
        "\n",
        "        return substitute_detector\n",
        "\n",
        "    def preprocessing(self):\n",
        "        # Load dataset\n",
        "        data = pd.read_csv(self.filename)\n",
        "        \n",
        "        # Drop unnecessary columns\n",
        "        data.drop([\"pkSeqID\",\"seq\",\"subcategory\", \"category\"], axis=1, inplace=True)\n",
        "        \n",
        "        # Convert source port from hex to dec\n",
        "        data['sport']=data['sport'].replace(['0x0303'],'771') \n",
        "        data['sport']=data['sport'].replace(['0x0011'],'17')\n",
        "        data['sport']=data['sport'].replace(['0x000d'],'13')\n",
        "        data['sport']=data['sport'].replace(['0x0008'],'8')\n",
        "\n",
        "        # Change type from object to int\n",
        "        data[\"sport\"] = data[\"sport\"].astype(str).astype(int)\n",
        "\n",
        "        # Encoding data\n",
        "        le = LabelEncoder()\n",
        "        data[\"saddr_enc\"]= le.fit_transform(data.saddr)\n",
        "        data[\"daddr_enc\"]= le.fit_transform(data.daddr)\n",
        "        data[\"proto_enc\"]= le.fit_transform(data.proto)\n",
        "        data.drop(['saddr','daddr','proto'], axis=1, inplace=True)\n",
        "\n",
        "        # Convert dest port from hex to dec\n",
        "        data['dport']=data.dport.apply(lambda x: int(x,16) if len(x)>1 and x[1]==\"x\" else int(x))\n",
        "\n",
        "        # Swap label to end\n",
        "        titles = list(data.columns)\n",
        "        titles[11], titles[14] = titles[14], titles[11]\n",
        "        data = data[titles]\n",
        "        del titles\n",
        "        # Scale dataset\n",
        "        label = data['attack']\n",
        "        scaler=StandardScaler()\n",
        "        features = data.iloc[:,:-1]\n",
        "        cols=features.columns\n",
        "        scaled_features= scaler.fit_transform(features)\n",
        "        pre_data = pd.DataFrame(scaled_features,columns=cols)\n",
        "        pre_data['attack'] = label.values\n",
        "        del label\n",
        "        \n",
        "        return pre_data\n",
        "\n",
        "    def load_data(self):\n",
        "        #data = self.preprocessing()\n",
        "        data = pd.read_csv('/content/drive/MyDrive/Dataset/train.csv')\n",
        "        ynor = np.array(data[data['label'] == 0]['label'])\n",
        "        ybot = np.array(data[data['label'] == 1]['label'])\n",
        "        xnor = np.array(data[data['label'] == 0].iloc[:, :-1])\n",
        "        xbot = np.array(data[data['label'] == 1].iloc[:, :-1])\n",
        "        #xbot = data.loc[np.random.choice(data[data['attack'] == 1].index.values, 1148)].iloc[:, :-1]\n",
        "        \n",
        "        return (xbot, ybot), (xnor, ynor)\n",
        "\n",
        "    def train(self, epochs, batch_size=32, is_first=1):\n",
        "        # Load and split the dataset\n",
        "        (xbot, ybot), (xnor, ynor) = self.load_data()\n",
        "        xtrain_bot, xtest_bot, ytrain_bot, ytest_bot = train_test_split(xbot, ybot, test_size=0.3)\n",
        "        xtrain_nor, xtest_nor, ytrain_nor, ytest_nor = train_test_split(xnor, ynor, test_size=0.3)\n",
        "        if self.same_train_data:\n",
        "            bl_xtrain_bot, bl_ytrain_bot, bl_xtrain_nor, bl_ytrain_nor = xtrain_bot, ytrain_bot, xtrain_nor, ytrain_nor\n",
        "        else:\n",
        "            xtrain_bot, bl_xtrain_bot, ytrain_bot, bl_ytrain_bot = train_test_split(xtrain_bot, ytrain_bot, test_size=0.5)\n",
        "            xtrain_nor, bl_xtrain_nor, ytrain_nor, bl_ytrain_nor = train_test_split(xtrain_nor, ytrain_nor, test_size=0.5)\n",
        "        \n",
        "        # If is_first is True, train the blackbox_detector\n",
        "        if is_first:\n",
        "            self.blackbox_detector.fit(np.concatenate([xbot, xnor]), \n",
        "                                    np.concatenate([ybot, ynor]))\n",
        "\n",
        "        ytrain_nor_blackbox = self.blackbox_detector.predict(bl_xtrain_nor)\n",
        "        Original_Train_TPR = self.blackbox_detector.score(bl_xtrain_bot, bl_ytrain_bot)\n",
        "        Original_Test_TPR = self.blackbox_detector.score(xtest_bot, ytest_bot)\n",
        "        Train_TPR, Test_TPR = [Original_Train_TPR], [Original_Test_TPR]\n",
        "        best_TPR = 1.0\n",
        "        print(Train_TPR, Test_TPR, '\\n')\n",
        "        print('Training epochs.....')\n",
        "        for epoch in range(epochs):\n",
        "            for step in range(xtrain_bot.shape[0] // batch_size):\n",
        "                # Train substitute_detector\n",
        "\n",
        "                # Select a random batch of botnet examples\n",
        "                idx = np.random.randint(0, xtrain_bot.shape[0], batch_size)\n",
        "                xbot_batch = xtrain_bot[idx]\n",
        "                noise = np.random.uniform(0, 1, (batch_size, self.z_dims))\n",
        "                idx = np.random.randint(0, xbot_batch.shape[0], batch_size)\n",
        "                xnor_batch = xtrain_nor[idx]\n",
        "                ynor_batch = ytrain_nor_blackbox[idx]\n",
        "\n",
        "                # Generate a batch of new malware examples\n",
        "                gen_examples = self.generator.predict([xnor_batch, noise])\n",
        "                ybot_batch = self.blackbox_detector.predict(np.ones(gen_examples.shape)*(gen_examples > 0.5))\n",
        "\n",
        "                # Train the substitute_detector\n",
        "                d_loss_real = self.substitue_detector.train_on_batch(gen_examples, ybot_batch)\n",
        "                d_loss_fake = self.substitue_detector.train_on_batch(xnor_batch, ynor_batch)\n",
        "                d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
        "\n",
        "                # Train Generator\n",
        "                idx = np.random.randint(0, xtrain_bot.shape[0], batch_size)\n",
        "                xbot_batch = xtrain_bot[idx]\n",
        "                noise = np.random.uniform(0, 1, (batch_size, self.z_dims))\n",
        "\n",
        "                g_loss = self.combine.train_on_batch([xbot_batch, noise], np.zeros((batch_size, 1)))\n",
        "            \n",
        "            # Compute Train TPR\n",
        "            noise = np.random.uniform(0, 1, (xtrain_bot.shape[0], self.z_dims))\n",
        "            gen_examples = self.generator.predict([xtrain_bot, noise])\n",
        "            TPR = self.blackbox_detector.score(np.ones(gen_examples.shape) * (gen_examples > 0.5), ytrain_bot)\n",
        "            Train_TPR.append(TPR)\n",
        "\n",
        "            # Compute Test TPR\n",
        "            noise = np.random.uniform(0, 1, (xtest_bot.shape[0], self.z_dims))\n",
        "            gen_examples = self.generator.predict([xtest_bot, noise])\n",
        "            TPR = self.blackbox_detector.score(np.ones(gen_examples.shape) * (gen_examples > 0.5), ytest_bot)\n",
        "            Test_TPR.append(TPR)\n",
        "            print(Train_TPR[-1], Test_TPR[-1])\n",
        "\n",
        "            # Save best model\n",
        "            if TPR < best_TPR:\n",
        "                self.combine.save_weights('/content/drive/MyDrive/Dataset/saves/BotGAN.h5')\n",
        "                best_TPR = TPR\n",
        "            \n",
        "            # Plot the progress\n",
        "            if is_first:\n",
        "                print(\"%d [D loss: %f, acc.: %.4f%%] [G loss: %f]\" % (epoch, d_loss[0], 100*d_loss[1], g_loss))\n",
        "        \n",
        "        flag = ['DiffTrainData', 'SameTrainData']\n",
        "        print('\\n\\n---{0} {1}'.format(self.blackbox, flag[self.same_train_data]))\n",
        "        print('\\nOriginal_Train_TPR: {0}, Adver_Train_TPR: {1}'.format(Original_Train_TPR, Train_TPR[-1]))\n",
        "        print('\\nOriginal_Test_TPR: {0}, Adver_Test_TPR: {1}'.format(Original_Test_TPR, Test_TPR[-1]))\n",
        "\n",
        "        # Plot TPR\n",
        "        plt.figure()\n",
        "        plt.plot(range(len(Train_TPR)), Train_TPR, c='r', label='Training Set', linewidth=2)\n",
        "        plt.plot(range(len(Test_TPR)), Test_TPR, c='g', linestyle='--', label='Validation Set', linewidth=2)\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('TPR')\n",
        "        plt.legend()\n",
        "        plt.savefig('/content/drive/MyDrive/Dataset/saves/Epoch_TPR_{0}, {1}, {2}.png'.format(self.blackbox, flag[self.same_train_data], is_first))\n",
        "        plt.show()\n",
        "\n",
        "    def retrain_blackbox_detector(self):\n",
        "        (xbot, ybot), (xnor, ynor) = self.load_data()\n",
        "        xtrain_bot, xtest_bot, ytrain_bot, ytest_bot = train_test_split(xbot, ybot, test_size=0.2)\n",
        "        xtrain_nor, xtest_nor, ytrain_nor, ytest_nor = train_test_split(xnor, ynor, test_size=0.2)\n",
        "\n",
        "        # Generate Train Adversarial Examples\n",
        "        noise = np.random.uniform(0, 1, (xtrain_bot.shape[0], self.z_dims))\n",
        "        gen_examples = self.generator.predict([xtrain_bot, noise])\n",
        "        gen_examples = np.ones(gen_examples.shape) * (gen_examples > 0.5)\n",
        "        self.blackbox_detector.fit(np.concatenate([xtrain_bot, xtrain_nor, gen_examples]), \n",
        "                                    np.concatenate([ytrain_bot, ytrain_nor, ytrain_bot]))\n",
        "        \n",
        "        # Compute train TPR\n",
        "        train_TPR = self.blackbox_detector.score(gen_examples, ytrain_bot)\n",
        "\n",
        "        # Compute test TPR\n",
        "        noise = np.random.uniform(0, 1, (xtest_bot.shape[0], self.z_dims))\n",
        "        gen_examples = self.generator.predict([xtest_bot, noise])\n",
        "        gen_examples = np.ones(gen_examples.shape) * (gen_examples > 0.5)\n",
        "        test_TPR = self.blackbox_detector.score(gen_examples, ytest_bot)\n",
        "\n",
        "        print('\\n---TPR after the blackbox_detector is retrained (Before retraining MalGAN).')\n",
        "        print('\\nTrain_TPR: {0}, Test_TPR: {1}'.format(train_TPR, test_TPR))"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2LOsjEu0iHzG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f7fa8b09-19ec-4be8-cb8e-ee30f616d873"
      },
      "source": [
        "botgan_RF = BotGAN(blackbox='RF')\n",
        "botgan_RF.train(epochs=500, batch_size=4096)\n",
        "botgan_RF.retrain_blackbox_detector()\n",
        "botgan_RF.train(epochs=100, batch_size=4096, is_first=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"substitute_detector\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 53)]              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 256)               13824     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 257       \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 1)                 0         \n",
            "=================================================================\n",
            "Total params: 14,081\n",
            "Trainable params: 14,081\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"generator\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, 53)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_3 (InputLayer)            [(None, 10)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 63)           0           input_2[0][0]                    \n",
            "                                                                 input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 256)          16384       concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 53)           13621       dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 53)           0           dense_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "maximum (Maximum)               (None, 53)           0           input_2[0][0]                    \n",
            "                                                                 activation_1[0][0]               \n",
            "==================================================================================================\n",
            "Total params: 30,005\n",
            "Trainable params: 30,005\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "[0.8991239127694441] [0.8980882352941176] \n",
            "\n",
            "Training epochs.....\n",
            "1.0 1.0\n",
            "0 [D loss: 0.271079, acc.: 91.0522%] [G loss: 3.909436]\n",
            "0.9999369721416866 0.9999264705882352\n",
            "1 [D loss: 0.186884, acc.: 93.5913%] [G loss: 4.286942]\n",
            "1.0 1.0\n",
            "2 [D loss: 0.204212, acc.: 93.7134%] [G loss: 3.900260]\n",
            "1.0 1.0\n",
            "3 [D loss: 0.206223, acc.: 93.4082%] [G loss: 4.289903]\n",
            "1.0 1.0\n",
            "4 [D loss: 0.177326, acc.: 94.9585%] [G loss: 4.957098]\n",
            "1.0 1.0\n",
            "5 [D loss: 0.163747, acc.: 95.6665%] [G loss: 5.502991]\n",
            "1.0 1.0\n",
            "6 [D loss: 0.165383, acc.: 95.6055%] [G loss: 6.124468]\n",
            "1.0 1.0\n",
            "7 [D loss: 0.155799, acc.: 95.8008%] [G loss: 6.324513]\n",
            "1.0 1.0\n",
            "8 [D loss: 0.150491, acc.: 95.9473%] [G loss: 6.446600]\n",
            "1.0 1.0\n",
            "9 [D loss: 0.141019, acc.: 96.0205%] [G loss: 6.833713]\n",
            "1.0 1.0\n",
            "10 [D loss: 0.141156, acc.: 96.2891%] [G loss: 7.030082]\n",
            "0.9792008067565864 0.9779411764705882\n",
            "11 [D loss: 0.179919, acc.: 94.7266%] [G loss: 7.275091]\n",
            "0.9475608218832724 0.9463235294117647\n",
            "12 [D loss: 0.290237, acc.: 90.3442%] [G loss: 6.433259]\n",
            "0.9470250850876087 0.9459558823529411\n",
            "13 [D loss: 0.260552, acc.: 91.9067%] [G loss: 6.488182]\n",
            "0.9470250850876087 0.9459558823529411\n",
            "14 [D loss: 0.256374, acc.: 91.1255%] [G loss: 6.501040]\n",
            "0.9472771965208622 0.9465441176470588\n",
            "15 [D loss: 0.250117, acc.: 91.0034%] [G loss: 6.734192]\n",
            "0.9478759611748393 0.9474264705882353\n",
            "16 [D loss: 0.236251, acc.: 91.3940%] [G loss: 6.868252]\n",
            "0.9445039707550738 0.9454411764705882\n",
            "17 [D loss: 0.272621, acc.: 89.8315%] [G loss: 5.802207]\n",
            "0.9405332156813312 0.9411764705882353\n",
            "18 [D loss: 0.255665, acc.: 89.9292%] [G loss: 6.048828]\n",
            "0.8921278204966595 0.8929411764705882\n",
            "19 [D loss: 0.267741, acc.: 90.0024%] [G loss: 5.741457]\n",
            "0.7413651834110677 0.7446323529411765\n",
            "20 [D loss: 0.223210, acc.: 91.6504%] [G loss: 3.756311]\n",
            "0.7328879364679188 0.7366176470588235\n",
            "21 [D loss: 0.198672, acc.: 92.9932%] [G loss: 4.358764]\n",
            "0.7316904071599647 0.7352941176470589\n",
            "22 [D loss: 0.187230, acc.: 93.8232%] [G loss: 4.534708]\n",
            "0.7372368586915417 0.7423529411764705\n",
            "23 [D loss: 0.209025, acc.: 93.8721%] [G loss: 4.567182]\n",
            "0.7940564729610488 0.7959558823529411\n",
            "24 [D loss: 0.288814, acc.: 89.4653%] [G loss: 5.298228]\n",
            "0.8175658641119374 0.8218382352941176\n",
            "25 [D loss: 0.328959, acc.: 87.3169%] [G loss: 5.744734]\n",
            "0.8186688516324215 0.8227941176470588\n",
            "26 [D loss: 0.310117, acc.: 89.0015%] [G loss: 5.450260]\n",
            "0.8210954241774865 0.8241911764705883\n",
            "27 [D loss: 0.396336, acc.: 83.9966%] [G loss: 6.249299]\n",
            "0.8164943905206101 0.8183823529411764\n",
            "28 [D loss: 0.313703, acc.: 89.7461%] [G loss: 7.853803]\n",
            "0.7579099962183286 0.7615441176470589\n",
            "29 [D loss: 0.282205, acc.: 91.5894%] [G loss: 7.791213]\n",
            "0.7353775368712971 0.7375735294117647\n",
            "30 [D loss: 0.225047, acc.: 94.2017%] [G loss: 7.313291]\n",
            "0.7347157443590067 0.7372058823529412\n",
            "31 [D loss: 0.193003, acc.: 94.8242%] [G loss: 8.024200]\n",
            "0.7345581747132233 0.7369117647058824\n",
            "32 [D loss: 0.189986, acc.: 95.0562%] [G loss: 8.271824]\n",
            "0.7345581747132233 0.7369117647058824\n",
            "33 [D loss: 0.176843, acc.: 95.0195%] [G loss: 8.300765]\n",
            "0.73468423042985 0.7371323529411765\n",
            "34 [D loss: 0.172065, acc.: 95.0684%] [G loss: 8.435664]\n",
            "0.735188453296357 0.7375735294117647\n",
            "35 [D loss: 0.179039, acc.: 94.7876%] [G loss: 8.595933]\n",
            "0.7401046262448002 0.7425735294117647\n",
            "36 [D loss: 0.181518, acc.: 94.6777%] [G loss: 8.564934]\n",
            "0.7486449010462625 0.7494852941176471\n",
            "37 [D loss: 0.175459, acc.: 94.7876%] [G loss: 8.640655]\n",
            "0.7585717887306189 0.7593382352941176\n",
            "38 [D loss: 0.193057, acc.: 94.3604%] [G loss: 8.871644]\n",
            "0.7640867263330392 0.763235294117647\n",
            "39 [D loss: 0.173694, acc.: 94.9341%] [G loss: 9.124681]\n",
            "0.7659775620824404 0.7650735294117647\n",
            "40 [D loss: 0.177494, acc.: 94.7632%] [G loss: 9.159132]\n",
            "0.7665132988781042 0.7658088235294118\n",
            "41 [D loss: 0.173096, acc.: 94.9707%] [G loss: 9.162318]\n",
            "0.7666393545947309 0.7660294117647058\n",
            "42 [D loss: 0.161907, acc.: 95.0806%] [G loss: 9.476601]\n",
            "0.7667338963822009 0.7661029411764706\n",
            "43 [D loss: 0.170741, acc.: 95.0684%] [G loss: 9.668138]\n",
            "0.7666708685238875 0.76625\n",
            "44 [D loss: 0.177015, acc.: 94.7754%] [G loss: 9.698587]\n",
            "0.7667023824530442 0.7663235294117647\n",
            "45 [D loss: 0.181785, acc.: 94.8242%] [G loss: 9.592809]\n",
            "0.7667023824530442 0.7663235294117647\n",
            "46 [D loss: 0.176291, acc.: 94.7144%] [G loss: 10.178265]\n",
            "0.7666393545947309 0.7663970588235294\n",
            "47 [D loss: 0.164909, acc.: 95.5444%] [G loss: 9.909241]\n",
            "0.765914534224127 0.7655882352941177\n",
            "48 [D loss: 0.185269, acc.: 94.9463%] [G loss: 9.885669]\n",
            "0.7661666456573806 0.7661029411764706\n",
            "49 [D loss: 0.195335, acc.: 94.7144%] [G loss: 10.509323]\n",
            "0.7642127820496659 0.7654411764705882\n",
            "50 [D loss: 0.204573, acc.: 93.8965%] [G loss: 10.243813]\n",
            "0.7640867263330392 0.7641176470588236\n",
            "51 [D loss: 0.203045, acc.: 94.3237%] [G loss: 9.972536]\n",
            "0.7367326358250347 0.7394852941176471\n",
            "52 [D loss: 0.192310, acc.: 94.7144%] [G loss: 9.676747]\n",
            "0.7332030757594857 0.7355147058823529\n",
            "53 [D loss: 0.177791, acc.: 95.1050%] [G loss: 8.638442]\n",
            "0.7346212025715366 0.7376470588235294\n",
            "54 [D loss: 0.165644, acc.: 94.0430%] [G loss: 7.945330]\n",
            "0.7338018404134627 0.7372794117647059\n",
            "55 [D loss: 0.164859, acc.: 94.9463%] [G loss: 8.481712]\n",
            "0.7329509643262322 0.7366176470588235\n",
            "56 [D loss: 0.145079, acc.: 95.1294%] [G loss: 7.373632]\n",
            "0.7328249086096055 0.7363970588235295\n",
            "57 [D loss: 0.139344, acc.: 95.1904%] [G loss: 7.124777]\n",
            "0.7328564225387622 0.7361029411764706\n",
            "58 [D loss: 0.138970, acc.: 95.2271%] [G loss: 7.661767]\n",
            "0.732667338963822 0.73625\n",
            "59 [D loss: 0.134241, acc.: 95.4468%] [G loss: 8.159998]\n",
            "0.7322891718139417 0.7358088235294118\n",
            "60 [D loss: 0.122071, acc.: 95.8374%] [G loss: 7.912960]\n",
            "0.731060128576831 0.7345588235294118\n",
            "61 [D loss: 0.117093, acc.: 95.8496%] [G loss: 7.572639]\n",
            "0.7307134753561074 0.7341911764705882\n",
            "62 [D loss: 0.123883, acc.: 95.5078%] [G loss: 8.971581]\n",
            "0.730146224631287 0.7336029411764706\n",
            "63 [D loss: 0.117039, acc.: 95.7397%] [G loss: 8.588429]\n",
            "0.7297365435522501 0.7332352941176471\n",
            "64 [D loss: 0.114030, acc.: 96.0083%] [G loss: 8.752733]\n",
            "0.7294214042606832 0.7330882352941176\n",
            "65 [D loss: 0.120943, acc.: 95.7642%] [G loss: 8.785276]\n",
            "0.7293268624732132 0.7330882352941176\n",
            "66 [D loss: 0.119950, acc.: 95.6665%] [G loss: 8.568553]\n",
            "0.7292953485440564 0.733014705882353\n",
            "67 [D loss: 0.121755, acc.: 95.4102%] [G loss: 8.982187]\n",
            "0.7292953485440564 0.733014705882353\n",
            "68 [D loss: 0.117338, acc.: 96.0083%] [G loss: 8.883092]\n",
            "0.7292953485440564 0.733014705882353\n",
            "69 [D loss: 0.117138, acc.: 95.7886%] [G loss: 9.227818]\n",
            "0.7292953485440564 0.733014705882353\n",
            "70 [D loss: 0.127677, acc.: 95.2759%] [G loss: 9.038759]\n",
            "0.7292953485440564 0.733014705882353\n",
            "71 [D loss: 0.118235, acc.: 95.5322%] [G loss: 9.354290]\n",
            "0.7292953485440564 0.733014705882353\n",
            "72 [D loss: 0.114134, acc.: 95.7520%] [G loss: 8.967387]\n",
            "0.7292953485440564 0.733014705882353\n",
            "73 [D loss: 0.116581, acc.: 95.7153%] [G loss: 9.054073]\n",
            "0.7292953485440564 0.733014705882353\n",
            "74 [D loss: 0.113893, acc.: 95.9961%] [G loss: 8.848804]\n",
            "0.7294529181898399 0.7332352941176471\n",
            "75 [D loss: 0.112045, acc.: 96.1304%] [G loss: 9.328819]\n",
            "0.7364174965334678 0.7384558823529411\n",
            "76 [D loss: 0.228937, acc.: 93.6401%] [G loss: 12.454750]\n",
            "0.736795663683348 0.7391911764705882\n",
            "77 [D loss: 0.227063, acc.: 93.7744%] [G loss: 13.721993]\n",
            "0.7375519979831086 0.7408088235294118\n",
            "78 [D loss: 0.229105, acc.: 93.9819%] [G loss: 14.276097]\n",
            "0.7384343879994958 0.7416176470588235\n",
            "79 [D loss: 0.247101, acc.: 92.8467%] [G loss: 14.373020]\n",
            "0.7390646665826295 0.7418382352941176\n",
            "80 [D loss: 0.208304, acc.: 93.8232%] [G loss: 14.247530]\n",
            "0.7385604437161225 0.7415441176470589\n",
            "81 [D loss: 0.206298, acc.: 93.5425%] [G loss: 14.750641]\n",
            "0.7378356233455187 0.7408088235294118\n",
            "82 [D loss: 0.213434, acc.: 93.3105%] [G loss: 14.501068]\n",
            "0.7374889701247952 0.7402205882352941\n",
            "83 [D loss: 0.207192, acc.: 94.0552%] [G loss: 14.209791]\n",
            "0.7370792890457583 0.7392647058823529\n",
            "84 [D loss: 0.273287, acc.: 92.7246%] [G loss: 12.841675]\n",
            "0.7371423169040716 0.7392647058823529\n",
            "85 [D loss: 0.241080, acc.: 92.8223%] [G loss: 13.083324]\n",
            "0.7371738308332283 0.7391911764705882\n",
            "86 [D loss: 0.218848, acc.: 93.4692%] [G loss: 12.912291]\n",
            "0.7372368586915417 0.7394852941176471\n",
            "87 [D loss: 0.243382, acc.: 92.8345%] [G loss: 12.815874]\n",
            "0.7372683726206983 0.7395588235294117\n",
            "88 [D loss: 0.216564, acc.: 93.6279%] [G loss: 12.429440]\n",
            "0.737299886549855 0.7394117647058823\n",
            "89 [D loss: 0.218815, acc.: 93.4326%] [G loss: 13.379515]\n",
            "0.7373314004790117 0.7395588235294117\n",
            "90 [D loss: 0.214743, acc.: 93.4448%] [G loss: 13.512298]\n",
            "0.7374574561956385 0.7391911764705882\n",
            "91 [D loss: 0.193151, acc.: 93.9941%] [G loss: 13.814963]\n",
            "0.7374574561956385 0.74\n",
            "92 [D loss: 0.183865, acc.: 94.0552%] [G loss: 13.704639]\n",
            "0.7372368586915417 0.7397058823529412\n",
            "93 [D loss: 0.193001, acc.: 93.6157%] [G loss: 14.042617]\n",
            "0.7372368586915417 0.7394852941176471\n",
            "94 [D loss: 0.182884, acc.: 93.8232%] [G loss: 14.068241]\n",
            "0.7372683726206983 0.7397794117647059\n",
            "95 [D loss: 0.179798, acc.: 94.1162%] [G loss: 14.264112]\n",
            "0.737299886549855 0.7396323529411765\n",
            "96 [D loss: 0.175218, acc.: 93.1641%] [G loss: 14.054001]\n",
            "0.7371738308332283 0.7393382352941177\n",
            "97 [D loss: 0.177994, acc.: 94.2749%] [G loss: 14.719090]\n",
            "0.7371423169040716 0.7395588235294117\n",
            "98 [D loss: 0.168656, acc.: 94.1650%] [G loss: 15.059429]\n",
            "0.7371738308332283 0.7394852941176471\n",
            "99 [D loss: 0.164333, acc.: 94.5068%] [G loss: 15.682206]\n",
            "0.7373314004790117 0.7394852941176471\n",
            "100 [D loss: 0.159584, acc.: 94.5435%] [G loss: 15.202295]\n",
            "0.7372368586915417 0.7394117647058823\n",
            "101 [D loss: 0.150295, acc.: 95.3247%] [G loss: 15.762046]\n",
            "0.737205344762385 0.7394852941176471\n",
            "102 [D loss: 0.173135, acc.: 94.2261%] [G loss: 16.037161]\n",
            "0.7373314004790117 0.7395588235294117\n",
            "103 [D loss: 0.167766, acc.: 94.1406%] [G loss: 15.746593]\n",
            "0.7375204840539519 0.7397794117647059\n",
            "104 [D loss: 0.163467, acc.: 94.7266%] [G loss: 16.525118]\n",
            "0.7378356233455187 0.7398529411764706\n",
            "105 [D loss: 0.163084, acc.: 94.6289%] [G loss: 16.723042]\n",
            "0.7380247069204589 0.7400735294117647\n",
            "106 [D loss: 0.161782, acc.: 94.7144%] [G loss: 17.502756]\n",
            "0.7380877347787722 0.7401470588235294\n",
            "107 [D loss: 0.173214, acc.: 93.8477%] [G loss: 18.840954]\n",
            "0.7379931929913022 0.7400735294117647\n",
            "108 [D loss: 0.152229, acc.: 94.3970%] [G loss: 18.697104]\n",
            "0.7378356233455187 0.7402205882352941\n",
            "109 [D loss: 0.150626, acc.: 94.6289%] [G loss: 19.379875]\n",
            "0.7379616790621455 0.74\n",
            "110 [D loss: 0.153525, acc.: 94.4336%] [G loss: 20.387585]\n",
            "0.7377410815580486 0.74\n",
            "111 [D loss: 0.146626, acc.: 94.8242%] [G loss: 20.175194]\n",
            "0.7377725954872053 0.7400735294117647\n",
            "112 [D loss: 0.140395, acc.: 94.8730%] [G loss: 20.720896]\n",
            "0.7378356233455187 0.7400735294117647\n",
            "113 [D loss: 0.136197, acc.: 95.4102%] [G loss: 21.061350]\n",
            "0.737709567628892 0.7398529411764706\n",
            "114 [D loss: 0.142971, acc.: 95.1782%] [G loss: 22.015896]\n",
            "0.737709567628892 0.7399264705882352\n",
            "115 [D loss: 0.139788, acc.: 94.8853%] [G loss: 21.543890]\n",
            "0.7377410815580486 0.7399264705882352\n",
            "116 [D loss: 0.138390, acc.: 95.0562%] [G loss: 21.271673]\n",
            "0.737804109416362 0.7398529411764706\n",
            "117 [D loss: 0.132770, acc.: 94.9707%] [G loss: 22.119831]\n",
            "0.737709567628892 0.7398529411764706\n",
            "118 [D loss: 0.134318, acc.: 94.8853%] [G loss: 21.905598]\n",
            "0.7377410815580486 0.7399264705882352\n",
            "119 [D loss: 0.128764, acc.: 95.4590%] [G loss: 22.128277]\n",
            "0.7377410815580486 0.7397794117647059\n",
            "120 [D loss: 0.131482, acc.: 94.9219%] [G loss: 22.274649]\n",
            "0.737709567628892 0.7399264705882352\n",
            "121 [D loss: 0.131094, acc.: 95.3735%] [G loss: 22.509727]\n",
            "0.7376780536997353 0.7399264705882352\n",
            "122 [D loss: 0.130225, acc.: 95.0684%] [G loss: 22.935282]\n",
            "0.737709567628892 0.7396323529411765\n",
            "123 [D loss: 0.123558, acc.: 95.3003%] [G loss: 22.905575]\n",
            "0.737709567628892 0.7397058823529412\n",
            "124 [D loss: 0.128957, acc.: 95.2026%] [G loss: 23.449892]\n",
            "0.7376780536997353 0.7397058823529412\n",
            "125 [D loss: 0.127454, acc.: 95.3247%] [G loss: 23.192883]\n",
            "0.7376465397705786 0.7397794117647059\n",
            "126 [D loss: 0.127674, acc.: 95.1538%] [G loss: 23.139687]\n",
            "0.7376780536997353 0.7397794117647059\n",
            "127 [D loss: 0.129703, acc.: 95.0317%] [G loss: 22.098038]\n",
            "0.7376780536997353 0.7398529411764706\n",
            "128 [D loss: 0.125784, acc.: 95.3247%] [G loss: 23.481455]\n",
            "0.7377410815580486 0.7397794117647059\n",
            "129 [D loss: 0.138475, acc.: 95.0073%] [G loss: 23.354774]\n",
            "0.7376150258414219 0.7398529411764706\n",
            "130 [D loss: 0.129838, acc.: 95.1782%] [G loss: 23.193041]\n",
            "0.7376780536997353 0.7397058823529412\n",
            "131 [D loss: 0.146843, acc.: 94.7998%] [G loss: 23.543840]\n",
            "0.7367326358250347 0.7388970588235294\n",
            "132 [D loss: 0.142943, acc.: 95.0562%] [G loss: 23.445246]\n",
            "0.7355666204462372 0.7378676470588236\n",
            "133 [D loss: 0.146541, acc.: 94.8242%] [G loss: 23.338007]\n",
            "0.7350939115088869 0.7374264705882353\n",
            "134 [D loss: 0.159619, acc.: 95.0684%] [G loss: 23.980955]\n",
            "0.7349363418631035 0.7375735294117647\n",
            "135 [D loss: 0.161629, acc.: 94.8853%] [G loss: 24.100683]\n",
            "0.7349048279339468 0.7376470588235294\n",
            "136 [D loss: 0.168578, acc.: 95.0562%] [G loss: 24.091795]\n",
            "0.7349048279339468 0.7375735294117647\n",
            "137 [D loss: 0.188624, acc.: 94.5435%] [G loss: 23.881466]\n",
            "0.7347472582881633 0.7373529411764705\n",
            "138 [D loss: 0.181544, acc.: 94.7632%] [G loss: 22.966885]\n",
            "0.734274549350813 0.7363235294117647\n",
            "139 [D loss: 0.215565, acc.: 93.6646%] [G loss: 23.237846]\n",
            "0.7327933946804488 0.7355147058823529\n",
            "140 [D loss: 0.215088, acc.: 92.9565%] [G loss: 20.368450]\n",
            "0.7323837136014119 0.7353676470588235\n",
            "141 [D loss: 0.226276, acc.: 93.2007%] [G loss: 16.881733]\n",
            "0.7335182150510525 0.73625\n",
            "142 [D loss: 0.250811, acc.: 93.1885%] [G loss: 17.191942]\n",
            "0.7400731123156435 0.7442647058823529\n",
            "143 [D loss: 0.319433, acc.: 90.6006%] [G loss: 15.899053]\n",
            "0.7748014622463129 0.7791911764705882\n",
            "144 [D loss: 0.323304, acc.: 90.6494%] [G loss: 16.462435]\n",
            "0.8099079793268624 0.8118382352941177\n",
            "145 [D loss: 0.314801, acc.: 87.9150%] [G loss: 15.367247]\n",
            "0.8166834740955502 0.8191911764705883\n",
            "146 [D loss: 0.285126, acc.: 88.8550%] [G loss: 16.131504]\n",
            "0.8175343501827808 0.8201470588235295\n",
            "147 [D loss: 0.263784, acc.: 91.0645%] [G loss: 16.283623]\n",
            "0.8159586537249465 0.8175\n",
            "148 [D loss: 0.261090, acc.: 91.1011%] [G loss: 15.690852]\n",
            "0.8105382579099962 0.8131617647058823\n",
            "149 [D loss: 0.250868, acc.: 91.2231%] [G loss: 15.318534]\n",
            "0.778110424807765 0.7805882352941177\n",
            "150 [D loss: 0.238674, acc.: 91.4185%] [G loss: 15.411334]\n",
            "0.7330455061137022 0.7359558823529412\n",
            "151 [D loss: 0.203841, acc.: 93.2861%] [G loss: 14.910499]\n",
            "0.7300831967729736 0.7338970588235294\n",
            "152 [D loss: 0.158436, acc.: 94.9707%] [G loss: 12.679241]\n",
            "0.7299256271271902 0.7333823529411765\n",
            "153 [D loss: 0.143276, acc.: 94.9219%] [G loss: 11.642426]\n",
            "0.7297365435522501 0.7333088235294117\n",
            "154 [D loss: 0.129890, acc.: 95.7520%] [G loss: 12.804404]\n",
            "0.7298310853397202 0.7333088235294117\n",
            "155 [D loss: 0.124817, acc.: 95.3979%] [G loss: 12.084805]\n",
            "0.7297050296230934 0.7333823529411765\n",
            "156 [D loss: 0.122798, acc.: 95.6787%] [G loss: 12.135673]\n",
            "0.7297050296230934 0.7333088235294117\n",
            "157 [D loss: 0.116582, acc.: 95.6299%] [G loss: 12.027663]\n",
            "0.7296735156939367 0.7334558823529411\n",
            "158 [D loss: 0.114875, acc.: 96.0938%] [G loss: 12.471406]\n",
            "0.7299571410563469 0.7333823529411765\n",
            "159 [D loss: 0.110224, acc.: 96.1792%] [G loss: 12.373989]\n",
            "0.7299886549855036 0.7334558823529411\n",
            "160 [D loss: 0.123120, acc.: 95.1172%] [G loss: 12.685568]\n",
            "0.7302092524896004 0.7336764705882353\n",
            "161 [D loss: 0.117793, acc.: 95.7153%] [G loss: 12.270980]\n",
            "0.7304613639228539 0.7338235294117647\n",
            "162 [D loss: 0.117424, acc.: 95.5688%] [G loss: 12.537873]\n",
            "0.7316273793016513 0.7345588235294118\n",
            "163 [D loss: 0.163638, acc.: 95.0806%] [G loss: 12.711529]\n",
            "0.7342430354216564 0.7364705882352941\n",
            "164 [D loss: 0.250755, acc.: 89.4409%] [G loss: 16.305016]\n",
            "0.7358187318794908 0.7379411764705882\n",
            "165 [D loss: 0.145324, acc.: 95.2026%] [G loss: 16.260128]\n",
            "0.7370792890457583 0.7394117647058823\n",
            "166 [D loss: 0.130813, acc.: 95.4956%] [G loss: 15.921988]\n",
            "0.7371108029749149 0.7394117647058823\n",
            "167 [D loss: 0.114722, acc.: 95.9717%] [G loss: 15.760323]\n",
            "0.7371738308332283 0.7395588235294117\n",
            "168 [D loss: 0.122193, acc.: 95.4956%] [G loss: 15.931519]\n",
            "0.737205344762385 0.7394117647058823\n",
            "169 [D loss: 0.120439, acc.: 95.5933%] [G loss: 16.389320]\n",
            "0.7372683726206983 0.7394117647058823\n",
            "170 [D loss: 0.110857, acc.: 95.8618%] [G loss: 17.162701]\n",
            "0.737205344762385 0.7394852941176471\n",
            "171 [D loss: 0.111962, acc.: 95.8008%] [G loss: 15.770626]\n",
            "0.7372368586915417 0.7396323529411765\n",
            "172 [D loss: 0.119155, acc.: 95.3857%] [G loss: 15.688318]\n",
            "0.737205344762385 0.7394117647058823\n",
            "173 [D loss: 0.118410, acc.: 95.5078%] [G loss: 16.392807]\n",
            "0.7372683726206983 0.7396323529411765\n",
            "174 [D loss: 0.114803, acc.: 95.8984%] [G loss: 16.993414]\n",
            "0.7372683726206983 0.7395588235294117\n",
            "175 [D loss: 0.114931, acc.: 95.6909%] [G loss: 16.860518]\n",
            "0.737299886549855 0.7395588235294117\n",
            "176 [D loss: 0.116170, acc.: 95.8252%] [G loss: 17.293457]\n",
            "0.7372683726206983 0.7395588235294117\n",
            "177 [D loss: 0.106428, acc.: 95.8130%] [G loss: 17.987886]\n",
            "0.7373314004790117 0.7394852941176471\n",
            "178 [D loss: 0.107258, acc.: 95.8252%] [G loss: 17.412949]\n",
            "0.7372683726206983 0.7394852941176471\n",
            "179 [D loss: 0.099655, acc.: 95.8496%] [G loss: 17.848598]\n",
            "0.7374574561956385 0.7394852941176471\n",
            "180 [D loss: 0.114241, acc.: 95.8130%] [G loss: 18.001860]\n",
            "0.7374259422664818 0.7394852941176471\n",
            "181 [D loss: 0.106784, acc.: 95.7886%] [G loss: 17.603632]\n",
            "0.737299886549855 0.7395588235294117\n",
            "182 [D loss: 0.101887, acc.: 96.1304%] [G loss: 17.758545]\n",
            "0.737299886549855 0.7397794117647059\n",
            "183 [D loss: 0.104212, acc.: 95.7886%] [G loss: 18.147877]\n",
            "0.7373314004790117 0.7395588235294117\n",
            "184 [D loss: 0.106513, acc.: 96.0693%] [G loss: 18.372211]\n",
            "0.7378986512038321 0.7399264705882352\n",
            "185 [D loss: 0.104201, acc.: 96.1304%] [G loss: 18.186096]\n",
            "0.7389386108660028 0.7411029411764706\n",
            "186 [D loss: 0.103485, acc.: 95.9351%] [G loss: 18.309168]\n",
            "0.7390646665826295 0.7410294117647059\n",
            "187 [D loss: 0.109688, acc.: 95.8618%] [G loss: 17.983805]\n",
            "0.7391907222992563 0.7408823529411764\n",
            "188 [D loss: 0.125918, acc.: 95.4102%] [G loss: 18.778809]\n",
            "0.7411760998361275 0.743014705882353\n",
            "189 [D loss: 0.157321, acc.: 95.1050%] [G loss: 19.076656]\n",
            "0.7471637463758981 0.7490441176470588\n",
            "190 [D loss: 0.179338, acc.: 95.1660%] [G loss: 18.651289]\n",
            "0.7518908357494012 0.7547794117647059\n",
            "191 [D loss: 0.207397, acc.: 94.2993%] [G loss: 19.634212]\n",
            "0.7528047396949452 0.7563235294117647\n",
            "192 [D loss: 0.246871, acc.: 93.2007%] [G loss: 19.961079]\n",
            "0.7550737425942267 0.7577205882352941\n",
            "193 [D loss: 0.240075, acc.: 92.1265%] [G loss: 21.238789]\n",
            "0.768341106769192 0.7725735294117647\n",
            "194 [D loss: 0.227443, acc.: 91.1377%] [G loss: 22.159300]\n",
            "0.8008319677297365 0.8025735294117647\n",
            "195 [D loss: 0.223458, acc.: 91.2354%] [G loss: 22.620369]\n",
            "0.7655678810034034 0.7676470588235295\n",
            "196 [D loss: 0.194239, acc.: 93.1885%] [G loss: 21.433601]\n",
            "0.7407349048279339 0.7425735294117647\n",
            "197 [D loss: 0.182656, acc.: 93.9331%] [G loss: 21.600994]\n",
            "0.7389386108660028 0.7408823529411764\n",
            "198 [D loss: 0.137728, acc.: 95.0928%] [G loss: 19.852402]\n",
            "0.7381192487079289 0.7404411764705883\n",
            "199 [D loss: 0.122771, acc.: 94.9951%] [G loss: 18.674931]\n",
            "0.7372368586915417 0.7394852941176471\n",
            "200 [D loss: 0.124419, acc.: 95.3613%] [G loss: 19.349415]\n",
            "0.7372368586915417 0.7394852941176471\n",
            "201 [D loss: 0.128096, acc.: 95.5444%] [G loss: 18.981285]\n",
            "0.7372368586915417 0.7394852941176471\n",
            "202 [D loss: 0.114073, acc.: 95.6177%] [G loss: 19.240379]\n",
            "0.7371423169040716 0.7394852941176471\n",
            "203 [D loss: 0.117281, acc.: 95.3003%] [G loss: 18.759239]\n",
            "0.737205344762385 0.7394117647058823\n",
            "204 [D loss: 0.108522, acc.: 96.1670%] [G loss: 18.281788]\n",
            "0.7371738308332283 0.7394852941176471\n",
            "205 [D loss: 0.098711, acc.: 96.0571%] [G loss: 18.290028]\n",
            "0.7372368586915417 0.7394852941176471\n",
            "206 [D loss: 0.110449, acc.: 95.7397%] [G loss: 18.707823]\n",
            "0.7371738308332283 0.7394117647058823\n",
            "207 [D loss: 0.105491, acc.: 95.9839%] [G loss: 18.601418]\n",
            "0.7372368586915417 0.7394117647058823\n",
            "208 [D loss: 0.113631, acc.: 95.7520%] [G loss: 18.594990]\n",
            "0.737205344762385 0.7395588235294117\n",
            "209 [D loss: 0.102840, acc.: 96.0693%] [G loss: 18.758383]\n",
            "0.7371738308332283 0.7394117647058823\n",
            "210 [D loss: 0.111327, acc.: 95.4102%] [G loss: 19.355923]\n",
            "0.7371423169040716 0.7394117647058823\n",
            "211 [D loss: 0.117293, acc.: 95.5322%] [G loss: 19.858452]\n",
            "0.7371738308332283 0.7394852941176471\n",
            "212 [D loss: 0.108670, acc.: 95.8740%] [G loss: 19.506542]\n",
            "0.7372683726206983 0.7395588235294117\n",
            "213 [D loss: 0.119430, acc.: 95.4834%] [G loss: 19.624659]\n",
            "0.737205344762385 0.7395588235294117\n",
            "214 [D loss: 0.114701, acc.: 95.8984%] [G loss: 18.773853]\n",
            "0.737205344762385 0.7394852941176471\n",
            "215 [D loss: 0.109575, acc.: 95.5933%] [G loss: 19.422426]\n",
            "0.737205344762385 0.7394852941176471\n",
            "216 [D loss: 0.110221, acc.: 95.7031%] [G loss: 19.736523]\n",
            "0.7371423169040716 0.7394852941176471\n",
            "217 [D loss: 0.101421, acc.: 96.1304%] [G loss: 19.742912]\n",
            "0.7372683726206983 0.7394852941176471\n",
            "218 [D loss: 0.115366, acc.: 95.7886%] [G loss: 19.901442]\n",
            "0.737205344762385 0.7394852941176471\n",
            "219 [D loss: 0.118480, acc.: 95.4102%] [G loss: 20.101768]\n",
            "0.737205344762385 0.7394852941176471\n",
            "220 [D loss: 0.109646, acc.: 95.7886%] [G loss: 20.613850]\n",
            "0.7372368586915417 0.7394852941176471\n",
            "221 [D loss: 0.114290, acc.: 95.5322%] [G loss: 20.547029]\n",
            "0.7372368586915417 0.7395588235294117\n",
            "222 [D loss: 0.107687, acc.: 96.0449%] [G loss: 20.513166]\n",
            "0.737205344762385 0.7395588235294117\n",
            "223 [D loss: 0.106956, acc.: 96.0571%] [G loss: 20.715965]\n",
            "0.7371738308332283 0.7395588235294117\n",
            "224 [D loss: 0.104987, acc.: 95.9229%] [G loss: 20.253153]\n",
            "0.7372368586915417 0.7394852941176471\n",
            "225 [D loss: 0.110768, acc.: 95.8618%] [G loss: 20.653759]\n",
            "0.7372368586915417 0.7394852941176471\n",
            "226 [D loss: 0.113901, acc.: 95.6055%] [G loss: 20.560703]\n",
            "0.7371738308332283 0.7394852941176471\n",
            "227 [D loss: 0.101819, acc.: 96.0083%] [G loss: 20.504658]\n",
            "0.7371423169040716 0.7394117647058823\n",
            "228 [D loss: 0.113245, acc.: 95.8740%] [G loss: 20.308950]\n",
            "0.737205344762385 0.7393382352941177\n",
            "229 [D loss: 0.114860, acc.: 95.5688%] [G loss: 21.045870]\n",
            "0.7371423169040716 0.7394117647058823\n",
            "230 [D loss: 0.109497, acc.: 95.8008%] [G loss: 21.193834]\n",
            "0.7371738308332283 0.7394117647058823\n",
            "231 [D loss: 0.114651, acc.: 95.8374%] [G loss: 20.445221]\n",
            "0.7371423169040716 0.7394117647058823\n",
            "232 [D loss: 0.100419, acc.: 96.2524%] [G loss: 20.742125]\n",
            "0.7371423169040716 0.7393382352941177\n",
            "233 [D loss: 0.117539, acc.: 95.4956%] [G loss: 21.084953]\n",
            "0.7370477751166016 0.7394852941176471\n",
            "234 [D loss: 0.112224, acc.: 95.8618%] [G loss: 21.139334]\n",
            "0.7370792890457583 0.7394852941176471\n",
            "235 [D loss: 0.100486, acc.: 96.4600%] [G loss: 21.374437]\n",
            "0.7370792890457583 0.7394852941176471\n",
            "236 [D loss: 0.101613, acc.: 96.0449%] [G loss: 20.553959]\n",
            "0.7370477751166016 0.7394117647058823\n",
            "237 [D loss: 0.098133, acc.: 96.1304%] [G loss: 21.226629]\n",
            "0.7369847472582881 0.7394117647058823\n",
            "238 [D loss: 0.112038, acc.: 95.6055%] [G loss: 21.162512]\n",
            "0.7369847472582881 0.7394117647058823\n",
            "239 [D loss: 0.108187, acc.: 96.1792%] [G loss: 21.328663]\n",
            "0.7369217193999748 0.7392647058823529\n",
            "240 [D loss: 0.101462, acc.: 96.0693%] [G loss: 21.442446]\n",
            "0.7368271776125047 0.7390441176470588\n",
            "241 [D loss: 0.108760, acc.: 95.5078%] [G loss: 21.112991]\n",
            "0.736795663683348 0.7391176470588235\n",
            "242 [D loss: 0.109047, acc.: 95.4590%] [G loss: 20.944191]\n",
            "0.7368271776125047 0.7391911764705882\n",
            "243 [D loss: 0.098929, acc.: 96.1182%] [G loss: 20.604530]\n",
            "0.7367641497541914 0.7390441176470588\n",
            "244 [D loss: 0.099347, acc.: 96.0938%] [G loss: 21.123140]\n",
            "0.7368271776125047 0.7391176470588235\n",
            "245 [D loss: 0.105116, acc.: 95.8984%] [G loss: 21.218765]\n",
            "0.7368271776125047 0.7388970588235294\n",
            "246 [D loss: 0.109543, acc.: 96.1792%] [G loss: 22.173460]\n",
            "0.7368271776125047 0.7389705882352942\n",
            "247 [D loss: 0.106736, acc.: 95.8008%] [G loss: 20.955446]\n",
            "0.7368586915416614 0.7389705882352942\n",
            "248 [D loss: 0.101096, acc.: 96.4600%] [G loss: 21.671133]\n",
            "0.7368586915416614 0.7389705882352942\n",
            "249 [D loss: 0.101475, acc.: 96.0083%] [G loss: 21.266407]\n",
            "0.7368586915416614 0.7390441176470588\n",
            "250 [D loss: 0.105690, acc.: 96.0938%] [G loss: 21.365837]\n",
            "0.736795663683348 0.7389705882352942\n",
            "251 [D loss: 0.091064, acc.: 96.8018%] [G loss: 21.625669]\n",
            "0.736795663683348 0.7390441176470588\n",
            "252 [D loss: 0.101416, acc.: 96.1426%] [G loss: 21.766125]\n",
            "0.7368586915416614 0.7389705882352942\n",
            "253 [D loss: 0.096097, acc.: 96.3745%] [G loss: 21.946577]\n",
            "0.7368586915416614 0.7390441176470588\n",
            "254 [D loss: 0.096847, acc.: 96.5210%] [G loss: 21.464390]\n",
            "0.7368271776125047 0.7389705882352942\n",
            "255 [D loss: 0.095115, acc.: 96.3257%] [G loss: 20.969666]\n",
            "0.7368271776125047 0.7388970588235294\n",
            "256 [D loss: 0.095586, acc.: 96.2769%] [G loss: 21.873596]\n",
            "0.7367641497541914 0.7389705882352942\n",
            "257 [D loss: 0.100488, acc.: 96.0815%] [G loss: 21.522299]\n",
            "0.7368586915416614 0.7388970588235294\n",
            "258 [D loss: 0.103560, acc.: 96.0571%] [G loss: 21.642977]\n",
            "0.7368586915416614 0.7389705882352942\n",
            "259 [D loss: 0.094556, acc.: 96.1182%] [G loss: 21.658953]\n",
            "0.7368271776125047 0.7391176470588235\n",
            "260 [D loss: 0.101048, acc.: 96.1792%] [G loss: 21.237501]\n",
            "0.736795663683348 0.7389705882352942\n",
            "261 [D loss: 0.097810, acc.: 96.1060%] [G loss: 21.447462]\n",
            "0.7368902054708181 0.7390441176470588\n",
            "262 [D loss: 0.107019, acc.: 95.8252%] [G loss: 21.177706]\n",
            "0.736795663683348 0.7389705882352942\n",
            "263 [D loss: 0.097463, acc.: 96.2036%] [G loss: 21.710949]\n",
            "0.7368586915416614 0.7390441176470588\n",
            "264 [D loss: 0.092614, acc.: 96.4478%] [G loss: 22.300701]\n",
            "0.7369532333291314 0.7390441176470588\n",
            "265 [D loss: 0.102034, acc.: 96.1670%] [G loss: 21.996599]\n",
            "0.736795663683348 0.7391176470588235\n",
            "266 [D loss: 0.098222, acc.: 96.3013%] [G loss: 22.385532]\n",
            "0.7369217193999748 0.7391911764705882\n",
            "267 [D loss: 0.099048, acc.: 96.2280%] [G loss: 21.967991]\n",
            "0.7368902054708181 0.7390441176470588\n",
            "268 [D loss: 0.097697, acc.: 96.2402%] [G loss: 22.341515]\n",
            "0.7369217193999748 0.7391911764705882\n",
            "269 [D loss: 0.107737, acc.: 95.8984%] [G loss: 22.151871]\n",
            "0.7369847472582881 0.7390441176470588\n",
            "270 [D loss: 0.106852, acc.: 95.8618%] [G loss: 22.256582]\n",
            "0.7369532333291314 0.7391176470588235\n",
            "271 [D loss: 0.112397, acc.: 96.2402%] [G loss: 22.229973]\n",
            "0.7369532333291314 0.7391911764705882\n",
            "272 [D loss: 0.111259, acc.: 95.7520%] [G loss: 22.233093]\n",
            "0.7369532333291314 0.7391176470588235\n",
            "273 [D loss: 0.102921, acc.: 96.2769%] [G loss: 22.716900]\n",
            "0.7369217193999748 0.7391911764705882\n",
            "274 [D loss: 0.104542, acc.: 96.0571%] [G loss: 22.353609]\n",
            "0.7368586915416614 0.7391911764705882\n",
            "275 [D loss: 0.105873, acc.: 95.8862%] [G loss: 22.130001]\n",
            "0.7368902054708181 0.7391911764705882\n",
            "276 [D loss: 0.102471, acc.: 96.2891%] [G loss: 22.446016]\n",
            "0.7368586915416614 0.7391176470588235\n",
            "277 [D loss: 0.112253, acc.: 95.9106%] [G loss: 22.179651]\n",
            "0.7369532333291314 0.7391911764705882\n",
            "278 [D loss: 0.107432, acc.: 96.0571%] [G loss: 22.695929]\n",
            "0.7368902054708181 0.7392647058823529\n",
            "279 [D loss: 0.107631, acc.: 95.9839%] [G loss: 22.990099]\n",
            "0.7369532333291314 0.7391911764705882\n",
            "280 [D loss: 0.106161, acc.: 95.9229%] [G loss: 22.845638]\n",
            "0.7368902054708181 0.7391176470588235\n",
            "281 [D loss: 0.115483, acc.: 95.8862%] [G loss: 23.888687]\n",
            "0.7369217193999748 0.7391176470588235\n",
            "282 [D loss: 0.114257, acc.: 95.9351%] [G loss: 24.078888]\n",
            "0.7369847472582881 0.7394117647058823\n",
            "283 [D loss: 0.102063, acc.: 96.4722%] [G loss: 23.812998]\n",
            "0.7369532333291314 0.7393382352941177\n",
            "284 [D loss: 0.107834, acc.: 96.2158%] [G loss: 24.439966]\n",
            "0.7369217193999748 0.7391911764705882\n",
            "285 [D loss: 0.115974, acc.: 95.7764%] [G loss: 24.161842]\n",
            "0.7369532333291314 0.7393382352941177\n",
            "286 [D loss: 0.108871, acc.: 95.8496%] [G loss: 24.513248]\n",
            "0.7369847472582881 0.7394852941176471\n",
            "287 [D loss: 0.113161, acc.: 95.4102%] [G loss: 24.307800]\n",
            "0.7369847472582881 0.7396323529411765\n",
            "288 [D loss: 0.109569, acc.: 96.0327%] [G loss: 24.829750]\n",
            "0.7370162611874449 0.7394852941176471\n",
            "289 [D loss: 0.106090, acc.: 95.7031%] [G loss: 24.607195]\n",
            "0.7368902054708181 0.7394852941176471\n",
            "290 [D loss: 0.101071, acc.: 96.1304%] [G loss: 24.450674]\n",
            "0.7369847472582881 0.7395588235294117\n",
            "291 [D loss: 0.111363, acc.: 95.6299%] [G loss: 24.098866]\n",
            "0.7370162611874449 0.7394852941176471\n",
            "292 [D loss: 0.117001, acc.: 95.5811%] [G loss: 24.635561]\n",
            "0.7369217193999748 0.7394852941176471\n",
            "293 [D loss: 0.104944, acc.: 96.1548%] [G loss: 24.735886]\n",
            "0.7369532333291314 0.7392647058823529\n",
            "294 [D loss: 0.107800, acc.: 95.7764%] [G loss: 25.196527]\n",
            "0.7369217193999748 0.7391911764705882\n",
            "295 [D loss: 0.117195, acc.: 95.4346%] [G loss: 24.470011]\n",
            "0.7368586915416614 0.7391911764705882\n",
            "296 [D loss: 0.104222, acc.: 96.1060%] [G loss: 24.755548]\n",
            "0.7369217193999748 0.7391911764705882\n",
            "297 [D loss: 0.109353, acc.: 95.8740%] [G loss: 24.776556]\n",
            "0.7368902054708181 0.7391911764705882\n",
            "298 [D loss: 0.107289, acc.: 96.1426%] [G loss: 24.284954]\n",
            "0.7369847472582881 0.7391176470588235\n",
            "299 [D loss: 0.111455, acc.: 96.0083%] [G loss: 24.562973]\n",
            "0.7368271776125047 0.7391911764705882\n",
            "300 [D loss: 0.101357, acc.: 96.1548%] [G loss: 24.725039]\n",
            "0.7368271776125047 0.7391911764705882\n",
            "301 [D loss: 0.108340, acc.: 96.1182%] [G loss: 25.020031]\n",
            "0.7369217193999748 0.7391911764705882\n",
            "302 [D loss: 0.114623, acc.: 95.6909%] [G loss: 24.728157]\n",
            "0.7368271776125047 0.7390441176470588\n",
            "303 [D loss: 0.103790, acc.: 96.1060%] [G loss: 25.328047]\n",
            "0.7368586915416614 0.7391911764705882\n",
            "304 [D loss: 0.108734, acc.: 96.1426%] [G loss: 25.358734]\n",
            "0.736795663683348 0.7391911764705882\n",
            "305 [D loss: 0.104617, acc.: 96.1792%] [G loss: 25.373356]\n",
            "0.7368586915416614 0.7389705882352942\n",
            "306 [D loss: 0.093543, acc.: 96.5210%] [G loss: 25.369888]\n",
            "0.7368586915416614 0.7391176470588235\n",
            "307 [D loss: 0.096766, acc.: 96.8140%] [G loss: 25.462059]\n",
            "0.7368271776125047 0.7391176470588235\n",
            "308 [D loss: 0.106969, acc.: 95.9229%] [G loss: 25.488955]\n",
            "0.7368586915416614 0.7391911764705882\n",
            "309 [D loss: 0.107172, acc.: 95.5933%] [G loss: 24.785889]\n",
            "0.7368271776125047 0.7391176470588235\n",
            "310 [D loss: 0.102007, acc.: 95.9961%] [G loss: 25.795952]\n",
            "0.736795663683348 0.7391176470588235\n",
            "311 [D loss: 0.100127, acc.: 96.2524%] [G loss: 25.401295]\n",
            "0.7368902054708181 0.7391176470588235\n",
            "312 [D loss: 0.098875, acc.: 96.1182%] [G loss: 25.230583]\n",
            "0.7368586915416614 0.7391176470588235\n",
            "313 [D loss: 0.098837, acc.: 96.2158%] [G loss: 25.911741]\n",
            "0.7368271776125047 0.7391911764705882\n",
            "314 [D loss: 0.106192, acc.: 96.0815%] [G loss: 25.776026]\n",
            "0.7368902054708181 0.7392647058823529\n",
            "315 [D loss: 0.099135, acc.: 96.2891%] [G loss: 26.044777]\n",
            "0.7368586915416614 0.7391911764705882\n",
            "316 [D loss: 0.099793, acc.: 96.0205%] [G loss: 25.280230]\n",
            "0.7368902054708181 0.7391176470588235\n",
            "317 [D loss: 0.102682, acc.: 96.2891%] [G loss: 25.207043]\n",
            "0.7368586915416614 0.7391911764705882\n",
            "318 [D loss: 0.107501, acc.: 95.7520%] [G loss: 25.352989]\n",
            "0.7368902054708181 0.7391176470588235\n",
            "319 [D loss: 0.104563, acc.: 96.1304%] [G loss: 26.137058]\n",
            "0.7368586915416614 0.7391176470588235\n",
            "320 [D loss: 0.107087, acc.: 96.0205%] [G loss: 25.667583]\n",
            "0.736795663683348 0.7391911764705882\n",
            "321 [D loss: 0.110795, acc.: 96.1182%] [G loss: 25.696392]\n",
            "0.736795663683348 0.7389705882352942\n",
            "322 [D loss: 0.104166, acc.: 95.8618%] [G loss: 25.302469]\n",
            "0.7368586915416614 0.7391176470588235\n",
            "323 [D loss: 0.098306, acc.: 96.4355%] [G loss: 25.527246]\n",
            "0.7368586915416614 0.7392647058823529\n",
            "324 [D loss: 0.115423, acc.: 95.7642%] [G loss: 25.813053]\n",
            "0.7368902054708181 0.7391911764705882\n",
            "325 [D loss: 0.106085, acc.: 95.7397%] [G loss: 26.013178]\n",
            "0.7368902054708181 0.7390441176470588\n",
            "326 [D loss: 0.099489, acc.: 96.3379%] [G loss: 26.518473]\n",
            "0.7368902054708181 0.7391176470588235\n",
            "327 [D loss: 0.099591, acc.: 96.4600%] [G loss: 25.621479]\n",
            "0.7367641497541914 0.7391176470588235\n",
            "328 [D loss: 0.107970, acc.: 95.8618%] [G loss: 26.742317]\n",
            "0.7369217193999748 0.7392647058823529\n",
            "329 [D loss: 0.108226, acc.: 95.9106%] [G loss: 26.217140]\n",
            "0.7368271776125047 0.7390441176470588\n",
            "330 [D loss: 0.102077, acc.: 96.2769%] [G loss: 25.921167]\n",
            "0.7368271776125047 0.7392647058823529\n",
            "331 [D loss: 0.101289, acc.: 96.3501%] [G loss: 26.592470]\n",
            "0.7368271776125047 0.7392647058823529\n",
            "332 [D loss: 0.106477, acc.: 96.2280%] [G loss: 26.790911]\n",
            "0.736795663683348 0.7392647058823529\n",
            "333 [D loss: 0.097727, acc.: 96.4722%] [G loss: 26.842457]\n",
            "0.7368586915416614 0.7390441176470588\n",
            "334 [D loss: 0.108466, acc.: 95.9961%] [G loss: 26.388462]\n",
            "0.736795663683348 0.7389705882352942\n",
            "335 [D loss: 0.100703, acc.: 96.2524%] [G loss: 26.685984]\n",
            "0.7368271776125047 0.7391911764705882\n",
            "336 [D loss: 0.098456, acc.: 96.4111%] [G loss: 26.614853]\n",
            "0.7368586915416614 0.7391911764705882\n",
            "337 [D loss: 0.107711, acc.: 96.0571%] [G loss: 26.612045]\n",
            "0.736795663683348 0.7391911764705882\n",
            "338 [D loss: 0.094943, acc.: 96.2646%] [G loss: 26.697559]\n",
            "0.7368271776125047 0.7391911764705882\n",
            "339 [D loss: 0.098548, acc.: 96.3867%] [G loss: 26.273060]\n",
            "0.736795663683348 0.7391176470588235\n",
            "340 [D loss: 0.099296, acc.: 96.1914%] [G loss: 26.731955]\n",
            "0.7368271776125047 0.7389705882352942\n",
            "341 [D loss: 0.099826, acc.: 96.6309%] [G loss: 26.595652]\n",
            "0.736795663683348 0.7391176470588235\n",
            "342 [D loss: 0.089777, acc.: 96.6187%] [G loss: 26.830105]\n",
            "0.736795663683348 0.7388970588235294\n",
            "343 [D loss: 0.089793, acc.: 96.5698%] [G loss: 26.546694]\n",
            "0.736795663683348 0.7390441176470588\n",
            "344 [D loss: 0.094039, acc.: 96.7163%] [G loss: 26.200878]\n",
            "0.7368271776125047 0.7391176470588235\n",
            "345 [D loss: 0.101610, acc.: 96.3257%] [G loss: 26.280066]\n",
            "0.736795663683348 0.7390441176470588\n",
            "346 [D loss: 0.096848, acc.: 96.1914%] [G loss: 26.902317]\n",
            "0.736795663683348 0.7390441176470588\n",
            "347 [D loss: 0.098968, acc.: 96.2280%] [G loss: 26.834261]\n",
            "0.7367641497541914 0.7391911764705882\n",
            "348 [D loss: 0.093883, acc.: 96.1426%] [G loss: 26.762939]\n",
            "0.7368271776125047 0.7389705882352942\n",
            "349 [D loss: 0.095596, acc.: 96.6064%] [G loss: 26.786730]\n",
            "0.7367641497541914 0.7391176470588235\n",
            "350 [D loss: 0.098400, acc.: 96.2036%] [G loss: 26.004917]\n",
            "0.736795663683348 0.7390441176470588\n",
            "351 [D loss: 0.099685, acc.: 96.3745%] [G loss: 26.700653]\n",
            "0.736795663683348 0.7391911764705882\n",
            "352 [D loss: 0.107771, acc.: 96.3257%] [G loss: 26.221800]\n",
            "0.7368271776125047 0.7390441176470588\n",
            "353 [D loss: 0.090998, acc.: 96.4966%] [G loss: 26.414560]\n",
            "0.7368586915416614 0.7391176470588235\n",
            "354 [D loss: 0.096150, acc.: 96.4722%] [G loss: 27.610443]\n",
            "0.7367641497541914 0.7392647058823529\n",
            "355 [D loss: 0.097008, acc.: 96.3989%] [G loss: 27.164486]\n",
            "0.7368271776125047 0.7391911764705882\n",
            "356 [D loss: 0.092201, acc.: 96.4233%] [G loss: 27.022144]\n",
            "0.7367641497541914 0.7391911764705882\n",
            "357 [D loss: 0.098951, acc.: 96.2769%] [G loss: 27.524336]\n",
            "0.7368271776125047 0.7392647058823529\n",
            "358 [D loss: 0.100453, acc.: 96.3623%] [G loss: 27.210960]\n",
            "0.7368271776125047 0.7392647058823529\n",
            "359 [D loss: 0.097666, acc.: 96.1182%] [G loss: 26.944855]\n",
            "0.736795663683348 0.7391911764705882\n",
            "360 [D loss: 0.099834, acc.: 96.0327%] [G loss: 27.126404]\n",
            "0.7368271776125047 0.7392647058823529\n",
            "361 [D loss: 0.091982, acc.: 96.6309%] [G loss: 27.490210]\n",
            "0.736795663683348 0.7392647058823529\n",
            "362 [D loss: 0.096419, acc.: 96.5454%] [G loss: 26.832209]\n",
            "0.7368586915416614 0.7391911764705882\n",
            "363 [D loss: 0.096037, acc.: 96.6553%] [G loss: 27.144604]\n",
            "0.7368586915416614 0.7391911764705882\n",
            "364 [D loss: 0.096984, acc.: 96.4111%] [G loss: 27.893448]\n",
            "0.736795663683348 0.7391911764705882\n",
            "365 [D loss: 0.105805, acc.: 96.1182%] [G loss: 27.181562]\n",
            "0.7368271776125047 0.7392647058823529\n",
            "366 [D loss: 0.104316, acc.: 96.2524%] [G loss: 27.014040]\n",
            "0.7368902054708181 0.7393382352941177\n",
            "367 [D loss: 0.097124, acc.: 96.5576%] [G loss: 27.267506]\n",
            "0.736795663683348 0.7391911764705882\n",
            "368 [D loss: 0.092560, acc.: 96.4233%] [G loss: 27.976315]\n",
            "0.7368902054708181 0.7391911764705882\n",
            "369 [D loss: 0.090554, acc.: 96.3623%] [G loss: 27.658447]\n",
            "0.7368586915416614 0.7393382352941177\n",
            "370 [D loss: 0.100411, acc.: 96.0693%] [G loss: 27.437271]\n",
            "0.7368586915416614 0.7392647058823529\n",
            "371 [D loss: 0.087842, acc.: 96.5088%] [G loss: 27.336525]\n",
            "0.7369217193999748 0.7391911764705882\n",
            "372 [D loss: 0.091028, acc.: 96.3013%] [G loss: 26.657072]\n",
            "0.7368271776125047 0.7392647058823529\n",
            "373 [D loss: 0.102863, acc.: 96.2280%] [G loss: 26.476151]\n",
            "0.7368271776125047 0.7391176470588235\n",
            "374 [D loss: 0.097603, acc.: 96.7896%] [G loss: 26.550314]\n",
            "0.7368271776125047 0.7392647058823529\n",
            "375 [D loss: 0.093538, acc.: 96.3745%] [G loss: 28.064053]\n",
            "0.736795663683348 0.7391911764705882\n",
            "376 [D loss: 0.094734, acc.: 96.2524%] [G loss: 27.853708]\n",
            "0.7368586915416614 0.7390441176470588\n",
            "377 [D loss: 0.088392, acc.: 96.7163%] [G loss: 27.876743]\n",
            "0.7368271776125047 0.7391911764705882\n",
            "378 [D loss: 0.084407, acc.: 96.8262%] [G loss: 27.095629]\n",
            "0.7368271776125047 0.7391176470588235\n",
            "379 [D loss: 0.088743, acc.: 96.4355%] [G loss: 28.183750]\n",
            "0.7368271776125047 0.7391911764705882\n",
            "380 [D loss: 0.095045, acc.: 96.2646%] [G loss: 27.382786]\n",
            "0.7367641497541914 0.7390441176470588\n",
            "381 [D loss: 0.091067, acc.: 96.3989%] [G loss: 27.043329]\n",
            "0.736795663683348 0.7391176470588235\n",
            "382 [D loss: 0.094224, acc.: 96.3013%] [G loss: 27.297838]\n",
            "0.736795663683348 0.7390441176470588\n",
            "383 [D loss: 0.092059, acc.: 96.6309%] [G loss: 27.246138]\n",
            "0.736795663683348 0.7390441176470588\n",
            "384 [D loss: 0.090323, acc.: 96.4355%] [G loss: 27.258219]\n",
            "0.7368271776125047 0.7391176470588235\n",
            "385 [D loss: 0.085121, acc.: 96.6919%] [G loss: 27.961956]\n",
            "0.736795663683348 0.7389705882352942\n",
            "386 [D loss: 0.081737, acc.: 96.5820%] [G loss: 27.185543]\n",
            "0.7368271776125047 0.7389705882352942\n",
            "387 [D loss: 0.077849, acc.: 97.0093%] [G loss: 26.531738]\n",
            "0.736795663683348 0.7390441176470588\n",
            "388 [D loss: 0.090849, acc.: 96.4355%] [G loss: 27.143505]\n",
            "0.7368271776125047 0.7391176470588235\n",
            "389 [D loss: 0.083595, acc.: 96.8018%] [G loss: 27.497152]\n",
            "0.7368271776125047 0.7390441176470588\n",
            "390 [D loss: 0.089740, acc.: 96.5820%] [G loss: 27.516167]\n",
            "0.7368586915416614 0.7389705882352942\n",
            "391 [D loss: 0.087755, acc.: 96.9604%] [G loss: 26.943439]\n",
            "0.7368271776125047 0.7390441176470588\n",
            "392 [D loss: 0.081053, acc.: 96.8140%] [G loss: 29.106951]\n",
            "0.7367641497541914 0.7390441176470588\n",
            "393 [D loss: 0.082393, acc.: 96.6797%] [G loss: 27.438885]\n",
            "0.7368586915416614 0.7391911764705882\n",
            "394 [D loss: 0.088756, acc.: 96.5820%] [G loss: 26.593620]\n",
            "0.7368586915416614 0.7391176470588235\n",
            "395 [D loss: 0.085105, acc.: 96.6675%] [G loss: 27.371212]\n",
            "0.7368271776125047 0.7390441176470588\n",
            "396 [D loss: 0.082595, acc.: 96.6919%] [G loss: 27.315197]\n",
            "0.736795663683348 0.7390441176470588\n",
            "397 [D loss: 0.085882, acc.: 96.8750%] [G loss: 27.225843]\n",
            "0.7368271776125047 0.7391176470588235\n",
            "398 [D loss: 0.088762, acc.: 96.6919%] [G loss: 27.438751]\n",
            "0.7368586915416614 0.7391911764705882\n",
            "399 [D loss: 0.094181, acc.: 96.7651%] [G loss: 27.616043]\n",
            "0.7368586915416614 0.7393382352941177\n",
            "400 [D loss: 0.088308, acc.: 96.5576%] [G loss: 27.419586]\n",
            "0.7368902054708181 0.7393382352941177\n",
            "401 [D loss: 0.080585, acc.: 96.7896%] [G loss: 27.605623]\n",
            "0.7368586915416614 0.7392647058823529\n",
            "402 [D loss: 0.089041, acc.: 96.2891%] [G loss: 28.273621]\n",
            "0.7368586915416614 0.7391911764705882\n",
            "403 [D loss: 0.089963, acc.: 96.6919%] [G loss: 28.161266]\n",
            "0.7369217193999748 0.7392647058823529\n",
            "404 [D loss: 0.092529, acc.: 96.5454%] [G loss: 28.032000]\n",
            "0.7368586915416614 0.7394117647058823\n",
            "405 [D loss: 0.086080, acc.: 96.8628%] [G loss: 28.168896]\n",
            "0.7368586915416614 0.7392647058823529\n",
            "406 [D loss: 0.097558, acc.: 96.0693%] [G loss: 27.877600]\n",
            "0.7369532333291314 0.7394117647058823\n",
            "407 [D loss: 0.086156, acc.: 97.0825%] [G loss: 27.498148]\n",
            "0.7368271776125047 0.7392647058823529\n",
            "408 [D loss: 0.081486, acc.: 96.6797%] [G loss: 28.115173]\n",
            "0.7369532333291314 0.7393382352941177\n",
            "409 [D loss: 0.087858, acc.: 96.5698%] [G loss: 28.978491]\n",
            "0.7369217193999748 0.7392647058823529\n",
            "410 [D loss: 0.082847, acc.: 96.9360%] [G loss: 28.569237]\n",
            "0.7369217193999748 0.7393382352941177\n",
            "411 [D loss: 0.081619, acc.: 96.7163%] [G loss: 27.997490]\n",
            "0.7369847472582881 0.7393382352941177\n",
            "412 [D loss: 0.094118, acc.: 96.6919%] [G loss: 29.213749]\n",
            "0.7369217193999748 0.7394117647058823\n",
            "413 [D loss: 0.080418, acc.: 97.0947%] [G loss: 28.290956]\n",
            "0.7369217193999748 0.7394117647058823\n",
            "414 [D loss: 0.080283, acc.: 96.8750%] [G loss: 28.997353]\n",
            "0.7368586915416614 0.7394117647058823\n",
            "415 [D loss: 0.084168, acc.: 96.8384%] [G loss: 28.717445]\n",
            "0.7369217193999748 0.7393382352941177\n",
            "416 [D loss: 0.094150, acc.: 96.5088%] [G loss: 28.539497]\n",
            "0.7369847472582881 0.7392647058823529\n",
            "417 [D loss: 0.078626, acc.: 96.9604%] [G loss: 28.163300]\n",
            "0.7368271776125047 0.7391911764705882\n",
            "418 [D loss: 0.083694, acc.: 97.0459%] [G loss: 28.937250]\n",
            "0.7369217193999748 0.7392647058823529\n",
            "419 [D loss: 0.077542, acc.: 97.0337%] [G loss: 29.729721]\n",
            "0.7369217193999748 0.7393382352941177\n",
            "420 [D loss: 0.083626, acc.: 96.9360%] [G loss: 28.677059]\n",
            "0.7369217193999748 0.7392647058823529\n",
            "421 [D loss: 0.079682, acc.: 96.8506%] [G loss: 27.940094]\n",
            "0.736795663683348 0.7391911764705882\n",
            "422 [D loss: 0.091375, acc.: 96.6064%] [G loss: 28.112934]\n",
            "0.7368902054708181 0.7391911764705882\n",
            "423 [D loss: 0.083125, acc.: 97.1924%] [G loss: 27.709564]\n",
            "0.7368271776125047 0.7391911764705882\n",
            "424 [D loss: 0.089741, acc.: 96.2402%] [G loss: 29.577917]\n",
            "0.7368271776125047 0.7391176470588235\n",
            "425 [D loss: 0.089994, acc.: 96.7773%] [G loss: 28.510834]\n",
            "0.7368271776125047 0.7391176470588235\n",
            "426 [D loss: 0.074420, acc.: 96.8628%] [G loss: 28.493412]\n",
            "0.736795663683348 0.7390441176470588\n",
            "427 [D loss: 0.081860, acc.: 96.8994%] [G loss: 28.927437]\n",
            "0.7368586915416614 0.7389705882352942\n",
            "428 [D loss: 0.088088, acc.: 96.7651%] [G loss: 28.634251]\n",
            "0.736795663683348 0.7389705882352942\n",
            "429 [D loss: 0.086619, acc.: 96.3989%] [G loss: 29.678011]\n",
            "0.736795663683348 0.7389705882352942\n",
            "430 [D loss: 0.080095, acc.: 96.9604%] [G loss: 27.699318]\n",
            "0.736795663683348 0.7389705882352942\n",
            "431 [D loss: 0.082245, acc.: 96.9727%] [G loss: 27.654287]\n",
            "0.736795663683348 0.7389705882352942\n",
            "432 [D loss: 0.082421, acc.: 97.0337%] [G loss: 27.671288]\n",
            "0.736795663683348 0.7390441176470588\n",
            "433 [D loss: 0.081847, acc.: 96.8872%] [G loss: 28.464005]\n",
            "0.7367641497541914 0.7389705882352942\n",
            "434 [D loss: 0.070001, acc.: 97.2778%] [G loss: 28.442337]\n",
            "0.736795663683348 0.7389705882352942\n",
            "435 [D loss: 0.079943, acc.: 96.9849%] [G loss: 29.135693]\n",
            "0.7368271776125047 0.7389705882352942\n",
            "436 [D loss: 0.068702, acc.: 97.3877%] [G loss: 28.196497]\n",
            "0.736795663683348 0.7389705882352942\n",
            "437 [D loss: 0.071714, acc.: 97.4487%] [G loss: 28.471577]\n",
            "0.7367641497541914 0.7390441176470588\n",
            "438 [D loss: 0.082399, acc.: 97.0215%] [G loss: 28.744234]\n",
            "0.7367326358250347 0.7389705882352942\n",
            "439 [D loss: 0.073661, acc.: 97.2900%] [G loss: 28.114964]\n",
            "0.7368586915416614 0.7389705882352942\n",
            "440 [D loss: 0.079969, acc.: 96.8750%] [G loss: 28.061075]\n",
            "0.7368271776125047 0.7390441176470588\n",
            "441 [D loss: 0.082770, acc.: 96.8262%] [G loss: 28.110180]\n",
            "0.736795663683348 0.7389705882352942\n",
            "442 [D loss: 0.076795, acc.: 96.6553%] [G loss: 27.755743]\n",
            "0.7368271776125047 0.7391176470588235\n",
            "443 [D loss: 0.077479, acc.: 96.7285%] [G loss: 27.348471]\n",
            "0.736795663683348 0.7390441176470588\n",
            "444 [D loss: 0.085453, acc.: 96.4844%] [G loss: 28.731192]\n",
            "0.7368586915416614 0.7390441176470588\n",
            "445 [D loss: 0.085314, acc.: 96.8506%] [G loss: 28.925100]\n",
            "0.736795663683348 0.7390441176470588\n",
            "446 [D loss: 0.077655, acc.: 96.9849%] [G loss: 27.983208]\n",
            "0.736795663683348 0.7390441176470588\n",
            "447 [D loss: 0.080646, acc.: 97.1191%] [G loss: 28.585928]\n",
            "0.736795663683348 0.7391176470588235\n",
            "448 [D loss: 0.079349, acc.: 96.9482%] [G loss: 28.014875]\n",
            "0.736795663683348 0.7391911764705882\n",
            "449 [D loss: 0.086815, acc.: 96.5210%] [G loss: 29.102373]\n",
            "0.7368586915416614 0.7391176470588235\n",
            "450 [D loss: 0.077450, acc.: 96.7896%] [G loss: 29.575426]\n",
            "0.7368902054708181 0.7393382352941177\n",
            "451 [D loss: 0.085429, acc.: 96.9971%] [G loss: 28.780426]\n",
            "0.7368586915416614 0.7394117647058823\n",
            "452 [D loss: 0.072654, acc.: 97.3267%] [G loss: 29.355026]\n",
            "0.7369532333291314 0.7394852941176471\n",
            "453 [D loss: 0.084172, acc.: 97.2900%] [G loss: 28.466108]\n",
            "0.7369217193999748 0.7394852941176471\n",
            "454 [D loss: 0.082436, acc.: 96.5942%] [G loss: 29.023403]\n",
            "0.7369532333291314 0.7393382352941177\n",
            "455 [D loss: 0.081839, acc.: 96.8384%] [G loss: 29.144892]\n",
            "0.7371423169040716 0.7394852941176471\n",
            "456 [D loss: 0.081141, acc.: 96.5942%] [G loss: 29.313568]\n",
            "0.7370792890457583 0.7394852941176471\n",
            "457 [D loss: 0.085785, acc.: 96.5820%] [G loss: 29.456337]\n",
            "0.7371108029749149 0.7394117647058823\n",
            "458 [D loss: 0.079148, acc.: 96.9116%] [G loss: 29.729990]\n",
            "0.737205344762385 0.7394117647058823\n",
            "459 [D loss: 0.084480, acc.: 96.7163%] [G loss: 29.131950]\n",
            "0.7371738308332283 0.7394852941176471\n",
            "460 [D loss: 0.087653, acc.: 96.5698%] [G loss: 29.871309]\n",
            "0.7372368586915417 0.7394117647058823\n",
            "461 [D loss: 0.072261, acc.: 97.2534%] [G loss: 29.676865]\n",
            "0.7372368586915417 0.7393382352941177\n",
            "462 [D loss: 0.078938, acc.: 97.2046%] [G loss: 30.233181]\n",
            "0.7372368586915417 0.7394117647058823\n",
            "463 [D loss: 0.083263, acc.: 96.8628%] [G loss: 29.847979]\n",
            "0.7371423169040716 0.7394117647058823\n",
            "464 [D loss: 0.072566, acc.: 97.2168%] [G loss: 30.332457]\n",
            "0.7371108029749149 0.7394852941176471\n",
            "465 [D loss: 0.080324, acc.: 97.0703%] [G loss: 30.649075]\n",
            "0.7369847472582881 0.7395588235294117\n",
            "466 [D loss: 0.081133, acc.: 97.2900%] [G loss: 30.804100]\n",
            "0.737205344762385 0.7394117647058823\n",
            "467 [D loss: 0.078680, acc.: 96.9238%] [G loss: 30.873650]\n",
            "0.7371423169040716 0.7391176470588235\n",
            "468 [D loss: 0.076962, acc.: 97.1924%] [G loss: 30.614960]\n",
            "0.7371423169040716 0.7394117647058823\n",
            "469 [D loss: 0.076156, acc.: 96.7651%] [G loss: 31.163898]\n",
            "0.7369847472582881 0.7393382352941177\n",
            "470 [D loss: 0.080092, acc.: 96.6675%] [G loss: 31.386490]\n",
            "0.7369217193999748 0.7393382352941177\n",
            "471 [D loss: 0.084786, acc.: 96.8140%] [G loss: 30.960583]\n",
            "0.7369217193999748 0.7392647058823529\n",
            "472 [D loss: 0.074128, acc.: 97.0703%] [G loss: 31.561247]\n",
            "0.7368902054708181 0.7393382352941177\n",
            "473 [D loss: 0.080729, acc.: 96.7163%] [G loss: 30.659538]\n",
            "0.7369217193999748 0.7392647058823529\n",
            "474 [D loss: 0.076987, acc.: 97.0215%] [G loss: 31.343407]\n",
            "0.7370477751166016 0.7393382352941177\n",
            "475 [D loss: 0.078571, acc.: 96.9238%] [G loss: 31.816544]\n",
            "0.7368902054708181 0.7391911764705882\n",
            "476 [D loss: 0.078481, acc.: 97.0215%] [G loss: 32.047977]\n",
            "0.7368902054708181 0.7391911764705882\n",
            "477 [D loss: 0.072043, acc.: 97.0581%] [G loss: 32.572121]\n",
            "0.736795663683348 0.7391176470588235\n",
            "478 [D loss: 0.073620, acc.: 97.5098%] [G loss: 32.368916]\n",
            "0.7368271776125047 0.7388970588235294\n",
            "479 [D loss: 0.087092, acc.: 96.9238%] [G loss: 31.881655]\n",
            "0.7368271776125047 0.7391176470588235\n",
            "480 [D loss: 0.076323, acc.: 97.2412%] [G loss: 31.206528]\n",
            "0.7367326358250347 0.7390441176470588\n",
            "481 [D loss: 0.076785, acc.: 96.8506%] [G loss: 32.542702]\n",
            "0.736795663683348 0.7390441176470588\n",
            "482 [D loss: 0.075441, acc.: 97.5342%] [G loss: 32.289604]\n",
            "0.736795663683348 0.7389705882352942\n",
            "483 [D loss: 0.074474, acc.: 97.3022%] [G loss: 32.642784]\n",
            "0.7368586915416614 0.7388970588235294\n",
            "484 [D loss: 0.080679, acc.: 96.9482%] [G loss: 31.893711]\n",
            "0.736795663683348 0.7388970588235294\n",
            "485 [D loss: 0.082623, acc.: 97.1069%] [G loss: 33.248093]\n",
            "0.7367641497541914 0.7389705882352942\n",
            "486 [D loss: 0.074235, acc.: 97.1191%] [G loss: 32.497494]\n",
            "0.7367641497541914 0.7389705882352942\n",
            "487 [D loss: 0.076065, acc.: 97.6685%] [G loss: 33.366722]\n",
            "0.7367641497541914 0.7389705882352942\n",
            "488 [D loss: 0.069353, acc.: 97.3877%] [G loss: 33.538483]\n",
            "0.736701121895878 0.7388235294117647\n",
            "489 [D loss: 0.070754, acc.: 97.3999%] [G loss: 33.462540]\n",
            "0.7367326358250347 0.7389705882352942\n",
            "490 [D loss: 0.068348, acc.: 97.8882%] [G loss: 32.649010]\n",
            "0.7367641497541914 0.7389705882352942\n",
            "491 [D loss: 0.071080, acc.: 97.1313%] [G loss: 32.455322]\n",
            "0.736606580108408 0.7389705882352942\n",
            "492 [D loss: 0.082833, acc.: 97.6074%] [G loss: 33.235146]\n",
            "0.7366696079667213 0.7389705882352942\n",
            "493 [D loss: 0.071201, acc.: 97.1191%] [G loss: 32.304680]\n",
            "0.7366696079667213 0.7389705882352942\n",
            "494 [D loss: 0.077534, acc.: 97.7539%] [G loss: 32.159904]\n",
            "0.736795663683348 0.7388970588235294\n",
            "495 [D loss: 0.076759, acc.: 96.8018%] [G loss: 33.887848]\n",
            "0.736606580108408 0.7389705882352942\n",
            "496 [D loss: 0.073073, acc.: 97.1069%] [G loss: 32.198429]\n",
            "0.7367326358250347 0.7389705882352942\n",
            "497 [D loss: 0.077653, acc.: 97.0703%] [G loss: 32.052170]\n",
            "0.736701121895878 0.7388970588235294\n",
            "498 [D loss: 0.065584, acc.: 97.4976%] [G loss: 31.926100]\n",
            "0.736701121895878 0.7388235294117647\n",
            "499 [D loss: 0.074697, acc.: 97.0459%] [G loss: 31.924210]\n",
            "\n",
            "\n",
            "---RF SameTrainData\n",
            "\n",
            "Original_Train_TPR: 0.8991239127694441, Adver_Train_TPR: 0.736701121895878\n",
            "\n",
            "Original_Test_TPR: 0.8980882352941176, Adver_Test_TPR: 0.7388235294117647\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "---TPR after the blackbox_detector is retrained (Before retraining MalGAN).\n",
            "\n",
            "Train_TPR: 1.0, Test_TPR: 1.0\n",
            "[0.9077272154292197] [0.9044117647058824] \n",
            "\n",
            "Training epochs.....\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "\n",
            "\n",
            "---RF SameTrainData\n",
            "\n",
            "Original_Train_TPR: 0.9077272154292197, Adver_Train_TPR: 1.0\n",
            "\n",
            "Original_Test_TPR: 0.9044117647058824, Adver_Test_TPR: 1.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nKfyr2IzVclY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "36e2810c-204e-40c4-bcae-c3865efd6096"
      },
      "source": [
        "botgan_MLP = BotGAN(blackbox='MLP')\n",
        "botgan_MLP.train(epochs=500, batch_size=4096)\n",
        "botgan_MLP.retrain_blackbox_detector()\n",
        "botgan_MLP.train(epochs=100, batch_size=4096, is_first=False)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"substitute_detector\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 53)]              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 256)               13824     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 257       \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 1)                 0         \n",
            "=================================================================\n",
            "Total params: 14,081\n",
            "Trainable params: 14,081\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"generator\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, 53)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_3 (InputLayer)            [(None, 10)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 63)           0           input_2[0][0]                    \n",
            "                                                                 input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 256)          16384       concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 53)           13621       dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 53)           0           dense_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "maximum (Maximum)               (None, 53)           0           input_2[0][0]                    \n",
            "                                                                 activation_1[0][0]               \n",
            "==================================================================================================\n",
            "Total params: 30,005\n",
            "Trainable params: 30,005\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[0.9441888314635069] [0.940514705882353] \n",
            "\n",
            "Training epochs.....\n",
            "0.8487961679062146 0.8491911764705883\n",
            "0 [D loss: 0.459081, acc.: 81.7871%] [G loss: 1.475331]\n",
            "0.8784822891718139 0.8825\n",
            "1 [D loss: 0.439162, acc.: 80.8105%] [G loss: 1.632537]\n",
            "0.5855918315895626 0.5899264705882353\n",
            "2 [D loss: 0.379205, acc.: 79.8828%] [G loss: 1.198922]\n",
            "0.7619752930795411 0.7638235294117647\n",
            "3 [D loss: 0.364697, acc.: 83.7891%] [G loss: 1.550770]\n",
            "0.35966847346527164 0.3669117647058823\n",
            "4 [D loss: 0.324916, acc.: 88.0249%] [G loss: 1.778540]\n",
            "0.32402621958905836 0.32419117647058826\n",
            "5 [D loss: 0.316625, acc.: 88.6230%] [G loss: 1.817540]\n",
            "0.41645657380562207 0.41816176470588234\n",
            "6 [D loss: 0.293835, acc.: 88.4521%] [G loss: 1.846041]\n",
            "0.4186940627757469 0.4199264705882353\n",
            "7 [D loss: 0.282624, acc.: 89.9902%] [G loss: 2.107635]\n",
            "0.4156687255767049 0.4168382352941176\n",
            "8 [D loss: 0.274910, acc.: 90.4541%] [G loss: 2.356162]\n",
            "0.36341863103491745 0.3640441176470588\n",
            "9 [D loss: 0.262569, acc.: 90.6494%] [G loss: 2.267997]\n",
            "0.22708937350308836 0.2275\n",
            "10 [D loss: 0.151060, acc.: 95.8618%] [G loss: 1.301566]\n",
            "0.22267742342115215 0.22279411764705884\n",
            "11 [D loss: 0.088506, acc.: 97.4487%] [G loss: 0.860426]\n",
            "0.22819236102357243 0.2300735294117647\n",
            "12 [D loss: 0.079521, acc.: 97.4976%] [G loss: 0.636712]\n",
            "0.2282238749527291 0.2300735294117647\n",
            "13 [D loss: 0.067557, acc.: 97.8516%] [G loss: 0.420832]\n",
            "0.2282238749527291 0.2300735294117647\n",
            "14 [D loss: 0.059085, acc.: 98.0957%] [G loss: 0.308815]\n",
            "0.2282238749527291 0.2300735294117647\n",
            "15 [D loss: 0.065724, acc.: 97.5952%] [G loss: 0.273003]\n",
            "0.2282238749527291 0.2300735294117647\n",
            "16 [D loss: 0.059648, acc.: 97.8027%] [G loss: 0.282067]\n",
            "0.2282238749527291 0.2300735294117647\n",
            "17 [D loss: 0.056190, acc.: 97.7905%] [G loss: 0.244419]\n",
            "0.2282238749527291 0.2300735294117647\n",
            "18 [D loss: 0.057384, acc.: 97.8149%] [G loss: 0.239872]\n",
            "0.2282238749527291 0.23\n",
            "19 [D loss: 0.061247, acc.: 97.6685%] [G loss: 0.234686]\n",
            "0.22768813815706543 0.22941176470588234\n",
            "20 [D loss: 0.056395, acc.: 97.9248%] [G loss: 0.171236]\n",
            "0.22362284129585278 0.22470588235294117\n",
            "21 [D loss: 0.059447, acc.: 97.8027%] [G loss: 0.229339]\n",
            "0.22239379805874196 0.2225\n",
            "22 [D loss: 0.057594, acc.: 97.8149%] [G loss: 0.269391]\n",
            "0.22239379805874196 0.2225735294117647\n",
            "23 [D loss: 0.059660, acc.: 97.7661%] [G loss: 0.150623]\n",
            "0.22214168662548847 0.22220588235294117\n",
            "24 [D loss: 0.057290, acc.: 97.7905%] [G loss: 0.128948]\n",
            "0.21738308332282869 0.21625\n",
            "25 [D loss: 0.057169, acc.: 97.8027%] [G loss: 0.138786]\n",
            "0.17411445859069707 0.1725\n",
            "26 [D loss: 0.052212, acc.: 98.0713%] [G loss: 0.111767]\n",
            "0.07632673641749653 0.07617647058823529\n",
            "27 [D loss: 0.060503, acc.: 97.5342%] [G loss: 0.136588]\n",
            "0.014496407412076138 0.015661764705882354\n",
            "28 [D loss: 0.052922, acc.: 97.7783%] [G loss: 0.085556]\n",
            "0.0054519097441068955 0.006102941176470588\n",
            "29 [D loss: 0.047279, acc.: 98.3643%] [G loss: 0.090124]\n",
            "0.0038762132862725325 0.003970588235294117\n",
            "30 [D loss: 0.055893, acc.: 97.8638%] [G loss: 0.069200]\n",
            "0.003088365057355351 0.0036029411764705883\n",
            "31 [D loss: 0.054862, acc.: 97.8271%] [G loss: 0.133452]\n",
            "0.0025211143325349805 0.0035294117647058825\n",
            "32 [D loss: 0.049705, acc.: 98.0103%] [G loss: 0.133061]\n",
            "0.0022690028992814826 0.003161764705882353\n",
            "33 [D loss: 0.045038, acc.: 98.3032%] [G loss: 0.092318]\n",
            "0.0023950586159082314 0.003014705882352941\n",
            "34 [D loss: 0.050238, acc.: 97.9980%] [G loss: 0.115156]\n",
            "0.0022374889701247953 0.003088235294117647\n",
            "35 [D loss: 0.052064, acc.: 98.2056%] [G loss: 0.073300]\n",
            "0.002205975040968108 0.003014705882352941\n",
            "36 [D loss: 0.048180, acc.: 98.3032%] [G loss: 0.088984]\n",
            "0.002205975040968108 0.003088235294117647\n",
            "37 [D loss: 0.045476, acc.: 98.2544%] [G loss: 0.091999]\n",
            "0.0021429471826547334 0.003088235294117647\n",
            "38 [D loss: 0.051182, acc.: 97.9004%] [G loss: 0.119852]\n",
            "0.0022374889701247953 0.003014705882352941\n",
            "39 [D loss: 0.046324, acc.: 98.3032%] [G loss: 0.081551]\n",
            "0.0021429471826547334 0.003014705882352941\n",
            "40 [D loss: 0.046534, acc.: 98.1567%] [G loss: 0.078797]\n",
            "0.0021429471826547334 0.003014705882352941\n",
            "41 [D loss: 0.046975, acc.: 98.2300%] [G loss: 0.098971]\n",
            "0.0021429471826547334 0.003014705882352941\n",
            "42 [D loss: 0.047977, acc.: 98.0591%] [G loss: 0.094837]\n",
            "0.0021744611118114207 0.003014705882352941\n",
            "43 [D loss: 0.043757, acc.: 98.3398%] [G loss: 0.049671]\n",
            "0.0021429471826547334 0.003014705882352941\n",
            "44 [D loss: 0.048340, acc.: 98.2300%] [G loss: 0.125602]\n",
            "0.0021429471826547334 0.003014705882352941\n",
            "45 [D loss: 0.047117, acc.: 98.3276%] [G loss: 0.107865]\n",
            "0.0021429471826547334 0.003014705882352941\n",
            "46 [D loss: 0.049654, acc.: 98.1812%] [G loss: 0.116256]\n",
            "0.0021429471826547334 0.003014705882352941\n",
            "47 [D loss: 0.048636, acc.: 98.1079%] [G loss: 0.127560]\n",
            "0.0021429471826547334 0.003014705882352941\n",
            "48 [D loss: 0.045416, acc.: 98.1323%] [G loss: 0.097316]\n",
            "0.0021429471826547334 0.003014705882352941\n",
            "49 [D loss: 0.045265, acc.: 98.1934%] [G loss: 0.123663]\n",
            "0.0021429471826547334 0.003014705882352941\n",
            "50 [D loss: 0.046844, acc.: 98.1323%] [G loss: 0.071372]\n",
            "0.0021429471826547334 0.003014705882352941\n",
            "51 [D loss: 0.041118, acc.: 98.3643%] [G loss: 0.114609]\n",
            "0.0021429471826547334 0.003014705882352941\n",
            "52 [D loss: 0.045072, acc.: 98.3643%] [G loss: 0.082048]\n",
            "0.0021744611118114207 0.003014705882352941\n",
            "53 [D loss: 0.046674, acc.: 98.0713%] [G loss: 0.161801]\n",
            "0.0021429471826547334 0.003014705882352941\n",
            "54 [D loss: 0.044312, acc.: 98.3276%] [G loss: 0.119350]\n",
            "0.0021429471826547334 0.003014705882352941\n",
            "55 [D loss: 0.050150, acc.: 97.8516%] [G loss: 0.086466]\n",
            "0.0021429471826547334 0.003014705882352941\n",
            "56 [D loss: 0.041454, acc.: 98.4985%] [G loss: 0.120171]\n",
            "0.0021429471826547334 0.003014705882352941\n",
            "57 [D loss: 0.042606, acc.: 98.2422%] [G loss: 0.051358]\n",
            "0.0021429471826547334 0.003014705882352941\n",
            "58 [D loss: 0.043194, acc.: 98.2788%] [G loss: 0.107960]\n",
            "0.0021429471826547334 0.003014705882352941\n",
            "59 [D loss: 0.041961, acc.: 98.3887%] [G loss: 0.080029]\n",
            "0.0021429471826547334 0.003014705882352941\n",
            "60 [D loss: 0.043401, acc.: 98.2788%] [G loss: 0.061800]\n",
            "0.0021429471826547334 0.003088235294117647\n",
            "61 [D loss: 0.045711, acc.: 98.1567%] [G loss: 0.075123]\n",
            "0.0026156561200050424 0.00375\n",
            "62 [D loss: 0.042753, acc.: 98.3521%] [G loss: 0.083813]\n",
            "0.0145909491995462 0.01647058823529412\n",
            "63 [D loss: 0.045161, acc.: 98.2666%] [G loss: 0.054980]\n",
            "0.05593722425311988 0.05838235294117647\n",
            "64 [D loss: 0.039384, acc.: 98.4131%] [G loss: 0.070181]\n",
            "0.08968864237993193 0.09117647058823529\n",
            "65 [D loss: 0.045688, acc.: 98.1567%] [G loss: 0.057278]\n",
            "0.1053510651708055 0.10720588235294118\n",
            "66 [D loss: 0.044173, acc.: 98.3521%] [G loss: 0.124324]\n",
            "0.14884028740703392 0.15066176470588236\n",
            "67 [D loss: 0.042730, acc.: 98.3765%] [G loss: 0.072649]\n",
            "0.20606958275557796 0.20595588235294118\n",
            "68 [D loss: 0.045132, acc.: 98.3032%] [G loss: 0.064093]\n",
            "0.21375898146980965 0.21455882352941177\n",
            "69 [D loss: 0.046108, acc.: 98.3398%] [G loss: 0.062310]\n",
            "0.21457834362788353 0.21463235294117647\n",
            "70 [D loss: 0.045995, acc.: 98.1567%] [G loss: 0.065028]\n",
            "0.21470439934451027 0.21485294117647058\n",
            "71 [D loss: 0.042798, acc.: 98.3032%] [G loss: 0.068643]\n",
            "0.2148934829194504 0.2151470588235294\n",
            "72 [D loss: 0.040780, acc.: 98.4863%] [G loss: 0.067986]\n",
            "0.21498802470692047 0.21507352941176472\n",
            "73 [D loss: 0.042208, acc.: 98.3643%] [G loss: 0.084091]\n",
            "0.2151455943527039 0.215\n",
            "74 [D loss: 0.044108, acc.: 98.2178%] [G loss: 0.059265]\n",
            "0.21520862221101728 0.2151470588235294\n",
            "75 [D loss: 0.045078, acc.: 98.1934%] [G loss: 0.056258]\n",
            "0.2151455943527039 0.2152205882352941\n",
            "76 [D loss: 0.043689, acc.: 98.4863%] [G loss: 0.023658]\n",
            "0.21520862221101728 0.21529411764705883\n",
            "77 [D loss: 0.040431, acc.: 98.6328%] [G loss: 0.103622]\n",
            "0.2151140804235472 0.21529411764705883\n",
            "78 [D loss: 0.040100, acc.: 98.4497%] [G loss: 0.042475]\n",
            "0.21527165006933063 0.2152205882352941\n",
            "79 [D loss: 0.043746, acc.: 98.3887%] [G loss: 0.084077]\n",
            "0.21520862221101728 0.21529411764705883\n",
            "80 [D loss: 0.039709, acc.: 98.5229%] [G loss: 0.059953]\n",
            "0.21524013614017395 0.21529411764705883\n",
            "81 [D loss: 0.038615, acc.: 98.6084%] [G loss: 0.094616]\n",
            "0.21520862221101728 0.2152205882352941\n",
            "82 [D loss: 0.042767, acc.: 98.5840%] [G loss: 0.029797]\n",
            "0.21524013614017395 0.21507352941176472\n",
            "83 [D loss: 0.038896, acc.: 98.6084%] [G loss: 0.076910]\n",
            "0.21530316399848734 0.2152205882352941\n",
            "84 [D loss: 0.043294, acc.: 98.2300%] [G loss: 0.134489]\n",
            "0.21530316399848734 0.21529411764705883\n",
            "85 [D loss: 0.045475, acc.: 98.2178%] [G loss: 0.083196]\n",
            "0.21530316399848734 0.2152205882352941\n",
            "86 [D loss: 0.044476, acc.: 98.3398%] [G loss: 0.061204]\n",
            "0.2153661918568007 0.21536764705882352\n",
            "87 [D loss: 0.042971, acc.: 98.1934%] [G loss: 0.067125]\n",
            "0.2153977057859574 0.21536764705882352\n",
            "88 [D loss: 0.041473, acc.: 98.4497%] [G loss: 0.063020]\n",
            "0.21542921971511408 0.21558823529411764\n",
            "89 [D loss: 0.042606, acc.: 98.3643%] [G loss: 0.062648]\n",
            "0.21546073364427076 0.21536764705882352\n",
            "90 [D loss: 0.042434, acc.: 98.5352%] [G loss: 0.041734]\n",
            "0.2159334425816211 0.2161764705882353\n",
            "91 [D loss: 0.047351, acc.: 98.3887%] [G loss: 0.116211]\n",
            "0.21621706794403125 0.21661764705882353\n",
            "92 [D loss: 0.042500, acc.: 98.5107%] [G loss: 0.032044]\n",
            "0.21681583259800832 0.2174264705882353\n",
            "93 [D loss: 0.040674, acc.: 98.8037%] [G loss: 0.103954]\n",
            "0.21744611118114207 0.21830882352941178\n",
            "94 [D loss: 0.047470, acc.: 98.2178%] [G loss: 0.073991]\n",
            "0.21864364048909618 0.22051470588235295\n",
            "95 [D loss: 0.043638, acc.: 98.2788%] [G loss: 0.166245]\n",
            "0.21949451657632674 0.22080882352941175\n",
            "96 [D loss: 0.041783, acc.: 98.4131%] [G loss: 0.086690]\n",
            "0.2195890583637968 0.2211764705882353\n",
            "97 [D loss: 0.046956, acc.: 98.2666%] [G loss: 0.104574]\n",
            "0.2193054330013866 0.22176470588235295\n",
            "98 [D loss: 0.040753, acc.: 98.4131%] [G loss: 0.156249]\n",
            "0.22088112945922098 0.22213235294117648\n",
            "99 [D loss: 0.052746, acc.: 98.0713%] [G loss: 0.083555]\n",
            "0.03343627883524518 0.03529411764705882\n",
            "100 [D loss: 0.045515, acc.: 98.5229%] [G loss: 0.074388]\n",
            "0.01229043237110803 0.01301470588235294\n",
            "101 [D loss: 0.124763, acc.: 97.5220%] [G loss: 0.149270]\n",
            "0.1911950081936216 0.19029411764705884\n",
            "102 [D loss: 0.127171, acc.: 95.9595%] [G loss: 0.485428]\n",
            "0.264307323837136 0.2625735294117647\n",
            "103 [D loss: 0.114919, acc.: 97.1069%] [G loss: 0.487612]\n",
            "0.3222614395562839 0.32080882352941176\n",
            "104 [D loss: 0.104323, acc.: 96.8994%] [G loss: 2.456179]\n",
            "0.33672633303920335 0.3397058823529412\n",
            "105 [D loss: 0.123978, acc.: 95.4834%] [G loss: 3.523240]\n",
            "0.3192676162863986 0.31779411764705884\n",
            "106 [D loss: 0.082162, acc.: 97.4609%] [G loss: 3.264385]\n",
            "0.26938106643136267 0.2681617647058824\n",
            "107 [D loss: 0.077367, acc.: 97.4854%] [G loss: 3.377037]\n",
            "0.23175343501827808 0.22919117647058823\n",
            "108 [D loss: 0.062802, acc.: 97.7173%] [G loss: 1.490047]\n",
            "0.2472898020925249 0.2461764705882353\n",
            "109 [D loss: 0.115278, acc.: 95.9717%] [G loss: 2.161269]\n",
            "0.2834362788352452 0.28191176470588236\n",
            "110 [D loss: 0.113918, acc.: 96.7651%] [G loss: 2.238232]\n",
            "0.2833732509769318 0.2817647058823529\n",
            "111 [D loss: 0.126384, acc.: 96.6064%] [G loss: 1.684532]\n",
            "0.2911256775494769 0.2892647058823529\n",
            "112 [D loss: 0.121878, acc.: 96.7896%] [G loss: 1.315588]\n",
            "0.31444598512542543 0.31338235294117645\n",
            "113 [D loss: 0.107634, acc.: 95.7520%] [G loss: 1.682486]\n",
            "0.31624227908735664 0.3145588235294118\n",
            "114 [D loss: 0.099686, acc.: 97.0459%] [G loss: 1.476815]\n",
            "0.3292575318290685 0.3274264705882353\n",
            "115 [D loss: 0.127131, acc.: 96.2769%] [G loss: 1.593954]\n",
            "0.3296987268372621 0.32786764705882354\n",
            "116 [D loss: 0.132155, acc.: 95.9473%] [G loss: 1.402452]\n",
            "0.32973024076641877 0.32794117647058824\n",
            "117 [D loss: 0.110814, acc.: 96.5088%] [G loss: 1.238836]\n",
            "0.3297932686247321 0.32786764705882354\n",
            "118 [D loss: 0.107922, acc.: 96.9116%] [G loss: 1.042034]\n",
            "0.32973024076641877 0.3276470588235294\n",
            "119 [D loss: 0.104204, acc.: 96.5942%] [G loss: 1.024773]\n",
            "0.3296356989789487 0.32735294117647057\n",
            "120 [D loss: 0.094624, acc.: 96.8750%] [G loss: 1.003825]\n",
            "0.329604185049792 0.3272794117647059\n",
            "121 [D loss: 0.090653, acc.: 96.6919%] [G loss: 0.900164]\n",
            "0.3293520736165385 0.3275\n",
            "122 [D loss: 0.098506, acc.: 96.6553%] [G loss: 0.879557]\n",
            "0.329099962183285 0.32735294117647057\n",
            "123 [D loss: 0.094431, acc.: 96.9482%] [G loss: 0.907316]\n",
            "0.3281230303794277 0.32639705882352943\n",
            "124 [D loss: 0.079251, acc.: 97.3755%] [G loss: 0.769698]\n",
            "0.32333291314761126 0.32286764705882354\n",
            "125 [D loss: 0.075648, acc.: 97.4976%] [G loss: 0.859463]\n",
            "0.09063406025463255 0.0888235294117647\n",
            "126 [D loss: 0.083489, acc.: 96.9116%] [G loss: 0.751866]\n",
            "0.06914156056977185 0.06779411764705882\n",
            "127 [D loss: 0.084843, acc.: 96.9971%] [G loss: 0.710053]\n",
            "0.06911004664061515 0.0675735294117647\n",
            "128 [D loss: 0.076573, acc.: 97.2168%] [G loss: 0.680344]\n",
            "0.07024454809025589 0.0686764705882353\n",
            "129 [D loss: 0.090233, acc.: 96.7163%] [G loss: 0.559044]\n",
            "0.0694882137904954 0.06713235294117648\n",
            "130 [D loss: 0.097613, acc.: 96.5576%] [G loss: 0.581522]\n",
            "0.2952224883398462 0.2958823529411765\n",
            "131 [D loss: 0.086282, acc.: 96.8506%] [G loss: 0.657295]\n",
            "0.29380436152779527 0.2947794117647059\n",
            "132 [D loss: 0.080595, acc.: 96.7651%] [G loss: 0.744904]\n",
            "0.2938673893861087 0.2928676470588235\n",
            "133 [D loss: 0.084855, acc.: 96.7773%] [G loss: 0.652687]\n",
            "0.2933001386612883 0.2938235294117647\n",
            "134 [D loss: 0.079660, acc.: 97.0093%] [G loss: 0.684638]\n",
            "0.29314256901550484 0.2938970588235294\n",
            "135 [D loss: 0.079574, acc.: 96.6675%] [G loss: 0.781938]\n",
            "0.2933001386612883 0.29404411764705884\n",
            "136 [D loss: 0.077133, acc.: 97.2534%] [G loss: 0.720237]\n",
            "0.29367830581116855 0.29419117647058823\n",
            "137 [D loss: 0.074919, acc.: 97.2290%] [G loss: 0.737696]\n",
            "0.29484432118996595 0.29514705882352943\n",
            "138 [D loss: 0.082540, acc.: 96.6919%] [G loss: 0.639206]\n",
            "0.2951279465523762 0.29654411764705885\n",
            "139 [D loss: 0.074903, acc.: 97.2046%] [G loss: 0.732801]\n",
            "0.2960418504979201 0.29661764705882354\n",
            "140 [D loss: 0.066634, acc.: 97.3145%] [G loss: 0.545993]\n",
            "0.2960103365687634 0.29713235294117646\n",
            "141 [D loss: 0.081054, acc.: 96.6553%] [G loss: 0.647767]\n",
            "0.29021177360393297 0.2911764705882353\n",
            "142 [D loss: 0.074716, acc.: 96.8628%] [G loss: 0.691407]\n",
            "0.2799382326988529 0.27955882352941175\n",
            "143 [D loss: 0.077835, acc.: 97.1191%] [G loss: 0.460419]\n",
            "0.2797806630530695 0.2792647058823529\n",
            "144 [D loss: 0.070684, acc.: 97.3267%] [G loss: 0.596401]\n",
            "0.2803479137778898 0.2797794117647059\n",
            "145 [D loss: 0.066435, acc.: 97.4121%] [G loss: 0.563301]\n",
            "0.2794340098323459 0.2798529411764706\n",
            "146 [D loss: 0.070562, acc.: 97.2656%] [G loss: 0.630122]\n",
            "0.28006428841547965 0.2799264705882353\n",
            "147 [D loss: 0.066131, acc.: 97.5830%] [G loss: 0.590525]\n",
            "0.280127316273793 0.2797058823529412\n",
            "148 [D loss: 0.067612, acc.: 97.2534%] [G loss: 0.578775]\n",
            "0.27996974662800955 0.2801470588235294\n",
            "149 [D loss: 0.064760, acc.: 97.6318%] [G loss: 0.553586]\n",
            "0.28028488591957645 0.2799264705882353\n",
            "150 [D loss: 0.069828, acc.: 97.6196%] [G loss: 0.670636]\n",
            "0.28100970629018024 0.28088235294117647\n",
            "151 [D loss: 0.088545, acc.: 96.9604%] [G loss: 1.700989]\n",
            "0.28157695701500063 0.2816911764705882\n",
            "152 [D loss: 0.074117, acc.: 97.7295%] [G loss: 2.238557]\n",
            "0.2816084709441573 0.28198529411764706\n",
            "153 [D loss: 0.087609, acc.: 96.9727%] [G loss: 2.341413]\n",
            "0.28570528173452664 0.28544117647058825\n",
            "154 [D loss: 0.091041, acc.: 96.9604%] [G loss: 2.890009]\n",
            "0.2946552376150258 0.2952205882352941\n",
            "155 [D loss: 0.077398, acc.: 97.5342%] [G loss: 2.654444]\n",
            "0.29440312618177233 0.2958088235294118\n",
            "156 [D loss: 0.080357, acc.: 97.2534%] [G loss: 2.496364]\n",
            "0.2868712971133241 0.2903676470588235\n",
            "157 [D loss: 0.106315, acc.: 96.3745%] [G loss: 2.672527]\n",
            "0.28157695701500063 0.28463235294117645\n",
            "158 [D loss: 0.122420, acc.: 95.8618%] [G loss: 2.503438]\n",
            "0.26840413462750534 0.2696323529411765\n",
            "159 [D loss: 0.133094, acc.: 95.6665%] [G loss: 1.927569]\n",
            "0.27974914912391274 0.2799264705882353\n",
            "160 [D loss: 0.123957, acc.: 95.8496%] [G loss: 2.243367]\n",
            "0.27483297617546953 0.275\n",
            "161 [D loss: 0.110308, acc.: 96.3745%] [G loss: 1.852643]\n",
            "0.2866506996092273 0.28801470588235295\n",
            "162 [D loss: 0.107012, acc.: 96.3623%] [G loss: 1.452007]\n",
            "0.2559246186814572 0.2541176470588235\n",
            "163 [D loss: 0.098357, acc.: 96.7773%] [G loss: 0.858983]\n",
            "0.4027795285516198 0.4026470588235294\n",
            "164 [D loss: 0.113367, acc.: 96.2646%] [G loss: 3.057387]\n",
            "0.4720786587671751 0.47066176470588234\n",
            "165 [D loss: 0.093553, acc.: 97.1680%] [G loss: 3.960459]\n",
            "0.46498802470692047 0.4657352941176471\n",
            "166 [D loss: 0.096770, acc.: 97.1802%] [G loss: 3.527360]\n",
            "0.44648934829194503 0.4497058823529412\n",
            "167 [D loss: 0.101079, acc.: 96.5576%] [G loss: 3.363794]\n",
            "0.40489096180511785 0.4047794117647059\n",
            "168 [D loss: 0.111458, acc.: 96.3135%] [G loss: 3.808372]\n",
            "0.33596999873944283 0.3341176470588235\n",
            "169 [D loss: 0.110434, acc.: 96.2036%] [G loss: 3.502530]\n",
            "0.327083070717257 0.3255882352941176\n",
            "170 [D loss: 0.093249, acc.: 96.6797%] [G loss: 3.201173]\n",
            "0.3256649439052061 0.3241176470588235\n",
            "171 [D loss: 0.085284, acc.: 97.3267%] [G loss: 2.781713]\n",
            "0.32430984495146853 0.32294117647058823\n",
            "172 [D loss: 0.099151, acc.: 96.8628%] [G loss: 2.378562]\n",
            "0.32141056346905333 0.3211029411764706\n",
            "173 [D loss: 0.086030, acc.: 97.2168%] [G loss: 2.168242]\n",
            "0.3093092146728854 0.3090441176470588\n",
            "174 [D loss: 0.092811, acc.: 96.8262%] [G loss: 2.388365]\n",
            "0.30410941636203204 0.30411764705882355\n",
            "175 [D loss: 0.080640, acc.: 97.3877%] [G loss: 2.274166]\n",
            "0.3028803731249212 0.30264705882352944\n",
            "176 [D loss: 0.074195, acc.: 97.8516%] [G loss: 2.105309]\n",
            "0.30136770452540024 0.30058823529411766\n",
            "177 [D loss: 0.067949, acc.: 98.0103%] [G loss: 1.992769]\n",
            "0.29979200806756584 0.3013235294117647\n",
            "178 [D loss: 0.072113, acc.: 97.3633%] [G loss: 1.934785]\n",
            "0.2988781041220219 0.2974264705882353\n",
            "179 [D loss: 0.061614, acc.: 97.8149%] [G loss: 1.839320]\n",
            "0.29768057481406784 0.29661764705882354\n",
            "180 [D loss: 0.067221, acc.: 97.6562%] [G loss: 1.812636]\n",
            "0.29723937980587417 0.2963235294117647\n",
            "181 [D loss: 0.067195, acc.: 97.7783%] [G loss: 1.748360]\n",
            "0.2951279465523762 0.29625\n",
            "182 [D loss: 0.066028, acc.: 97.6807%] [G loss: 1.725352]\n",
            "0.2940249590318921 0.29301470588235295\n",
            "183 [D loss: 0.058754, acc.: 97.8760%] [G loss: 1.577067]\n",
            "0.2930165132988781 0.2927205882352941\n",
            "184 [D loss: 0.059556, acc.: 98.0347%] [G loss: 1.680869]\n",
            "0.28888818857935206 0.28852941176470587\n",
            "185 [D loss: 0.064529, acc.: 97.7661%] [G loss: 1.575217]\n",
            "0.28592587923862345 0.28551470588235295\n",
            "186 [D loss: 0.059040, acc.: 97.7417%] [G loss: 1.690808]\n",
            "0.2855161981595865 0.2832352941176471\n",
            "187 [D loss: 0.066321, acc.: 97.7173%] [G loss: 1.553020]\n",
            "0.2836883902684987 0.2823529411764706\n",
            "188 [D loss: 0.056944, acc.: 98.0469%] [G loss: 1.480114]\n",
            "0.28167149880247067 0.28088235294117647\n",
            "189 [D loss: 0.062214, acc.: 98.0957%] [G loss: 1.382096]\n",
            "0.2806000252111433 0.2802205882352941\n",
            "190 [D loss: 0.055030, acc.: 97.9980%] [G loss: 1.361667]\n",
            "0.2790873566116223 0.27705882352941175\n",
            "191 [D loss: 0.048078, acc.: 98.6450%] [G loss: 1.302754]\n",
            "0.27732257657884785 0.27544117647058824\n",
            "192 [D loss: 0.059345, acc.: 98.1689%] [G loss: 1.387905]\n",
            "0.27562082440438673 0.2732352941176471\n",
            "193 [D loss: 0.057843, acc.: 98.2056%] [G loss: 1.364478]\n",
            "0.27306819614269506 0.27198529411764705\n",
            "194 [D loss: 0.050686, acc.: 98.1689%] [G loss: 1.307672]\n",
            "0.27168158325980085 0.26992647058823527\n",
            "195 [D loss: 0.053565, acc.: 98.1445%] [G loss: 1.265645]\n",
            "0.26837262069834866 0.26683823529411765\n",
            "196 [D loss: 0.058606, acc.: 98.2056%] [G loss: 1.247966]\n",
            "0.2628261691667717 0.2614705882352941\n",
            "197 [D loss: 0.053171, acc.: 98.2788%] [G loss: 1.073055]\n",
            "0.25532585402748015 0.2536029411764706\n",
            "198 [D loss: 0.059366, acc.: 97.9736%] [G loss: 1.069893]\n",
            "0.24366570023950587 0.24338235294117647\n",
            "199 [D loss: 0.060893, acc.: 97.9858%] [G loss: 0.950436]\n",
            "0.22935837640236983 0.23029411764705882\n",
            "200 [D loss: 0.071324, acc.: 98.1689%] [G loss: 0.814301]\n",
            "0.22803479137778898 0.2301470588235294\n",
            "201 [D loss: 0.063946, acc.: 98.1445%] [G loss: 0.699661]\n",
            "0.22686877599899155 0.22794117647058823\n",
            "202 [D loss: 0.076239, acc.: 98.0957%] [G loss: 0.643401]\n",
            "0.22507248203706037 0.22566176470588234\n",
            "203 [D loss: 0.066105, acc.: 97.9126%] [G loss: 0.619247]\n",
            "0.2240640363040464 0.22411764705882353\n",
            "204 [D loss: 0.073150, acc.: 97.9248%] [G loss: 0.522804]\n",
            "0.22349678557922603 0.2238235294117647\n",
            "205 [D loss: 0.070158, acc.: 97.8882%] [G loss: 0.531114]\n",
            "0.22343375772091265 0.2238235294117647\n",
            "206 [D loss: 0.067921, acc.: 98.1445%] [G loss: 0.451968]\n",
            "0.22343375772091265 0.2238235294117647\n",
            "207 [D loss: 0.067456, acc.: 98.0591%] [G loss: 0.443406]\n",
            "0.22359132736669607 0.2235294117647059\n",
            "208 [D loss: 0.069088, acc.: 97.8516%] [G loss: 0.332209]\n",
            "0.22346527165006932 0.2236029411764706\n",
            "209 [D loss: 0.070410, acc.: 98.1445%] [G loss: 0.344149]\n",
            "0.22374889701247952 0.2238235294117647\n",
            "210 [D loss: 0.060456, acc.: 98.0713%] [G loss: 0.391899]\n",
            "0.22463128702886676 0.2247794117647059\n",
            "211 [D loss: 0.069807, acc.: 97.9858%] [G loss: 0.310703]\n",
            "0.22935837640236983 0.22963235294117648\n",
            "212 [D loss: 0.074393, acc.: 97.6318%] [G loss: 0.360477]\n",
            "0.23897012479515947 0.23948529411764705\n",
            "213 [D loss: 0.087138, acc.: 97.2290%] [G loss: 0.472839]\n",
            "0.24290936593974538 0.2426470588235294\n",
            "214 [D loss: 0.087001, acc.: 96.7407%] [G loss: 0.602352]\n",
            "0.24300390772721542 0.24316176470588236\n",
            "215 [D loss: 0.096201, acc.: 96.3379%] [G loss: 0.506484]\n",
            "0.2432875330896256 0.24301470588235294\n",
            "216 [D loss: 0.077014, acc.: 97.1680%] [G loss: 0.338803]\n",
            "0.24316147737299887 0.24286764705882352\n",
            "217 [D loss: 0.080345, acc.: 97.1802%] [G loss: 0.325573]\n",
            "0.2430669355855288 0.24316176470588236\n",
            "218 [D loss: 0.079026, acc.: 97.3145%] [G loss: 0.365336]\n",
            "0.2431299634438422 0.24316176470588236\n",
            "219 [D loss: 0.070205, acc.: 97.4854%] [G loss: 0.303010]\n",
            "0.24290936593974538 0.24294117647058824\n",
            "220 [D loss: 0.071135, acc.: 97.2778%] [G loss: 0.321145]\n",
            "0.24322450523131223 0.24308823529411766\n",
            "221 [D loss: 0.079338, acc.: 97.1436%] [G loss: 0.323696]\n",
            "0.2430669355855288 0.24316176470588236\n",
            "222 [D loss: 0.077316, acc.: 97.1924%] [G loss: 0.304017]\n",
            "0.24294087986890206 0.24308823529411766\n",
            "223 [D loss: 0.074991, acc.: 97.1069%] [G loss: 0.260296]\n",
            "0.2433190470187823 0.24323529411764705\n",
            "224 [D loss: 0.084326, acc.: 96.7285%] [G loss: 0.322222]\n",
            "0.24338207487709568 0.24294117647058824\n",
            "225 [D loss: 0.094266, acc.: 96.7529%] [G loss: 0.286235]\n",
            "0.24338207487709568 0.24323529411764705\n",
            "226 [D loss: 0.092974, acc.: 96.5698%] [G loss: 0.256388]\n",
            "0.24347661666456574 0.24330882352941177\n",
            "227 [D loss: 0.092011, acc.: 96.5942%] [G loss: 0.232026]\n",
            "0.24338207487709568 0.24308823529411766\n",
            "228 [D loss: 0.101110, acc.: 96.4722%] [G loss: 0.295062]\n",
            "0.24344510273540906 0.24308823529411766\n",
            "229 [D loss: 0.093107, acc.: 96.5576%] [G loss: 0.229310]\n",
            "0.243350560947939 0.24308823529411766\n",
            "230 [D loss: 0.078961, acc.: 96.8994%] [G loss: 0.297254]\n",
            "0.2435396445228791 0.24316176470588236\n",
            "231 [D loss: 0.089125, acc.: 96.9360%] [G loss: 0.299965]\n",
            "0.24347661666456574 0.24301470588235294\n",
            "232 [D loss: 0.079720, acc.: 97.2656%] [G loss: 0.228063]\n",
            "0.24369721416866255 0.24308823529411766\n",
            "233 [D loss: 0.083212, acc.: 97.0703%] [G loss: 0.212335]\n",
            "0.24347661666456574 0.24323529411764705\n",
            "234 [D loss: 0.086941, acc.: 96.6797%] [G loss: 0.217606]\n",
            "0.24338207487709568 0.24308823529411766\n",
            "235 [D loss: 0.090117, acc.: 96.6675%] [G loss: 0.256601]\n",
            "0.24341358880625236 0.24308823529411766\n",
            "236 [D loss: 0.086325, acc.: 97.1069%] [G loss: 0.275290]\n",
            "0.2433190470187823 0.24316176470588236\n",
            "237 [D loss: 0.082971, acc.: 97.2046%] [G loss: 0.190961]\n",
            "0.24344510273540906 0.24316176470588236\n",
            "238 [D loss: 0.090195, acc.: 96.6675%] [G loss: 0.310773]\n",
            "0.2436026723811925 0.24308823529411766\n",
            "239 [D loss: 0.078478, acc.: 96.9482%] [G loss: 0.257555]\n",
            "0.24338207487709568 0.24316176470588236\n",
            "240 [D loss: 0.080120, acc.: 97.4731%] [G loss: 0.217614]\n",
            "0.24347661666456574 0.24338235294117647\n",
            "241 [D loss: 0.081814, acc.: 97.0215%] [G loss: 0.242992]\n",
            "0.24350813059372242 0.24316176470588236\n",
            "242 [D loss: 0.089315, acc.: 96.8384%] [G loss: 0.213004]\n",
            "0.24350813059372242 0.24316176470588236\n",
            "243 [D loss: 0.090694, acc.: 97.0703%] [G loss: 0.223691]\n",
            "0.24341358880625236 0.24301470588235294\n",
            "244 [D loss: 0.088823, acc.: 96.8628%] [G loss: 0.206237]\n",
            "0.24341358880625236 0.24316176470588236\n",
            "245 [D loss: 0.085669, acc.: 97.2168%] [G loss: 0.264128]\n",
            "0.24322450523131223 0.24279411764705883\n",
            "246 [D loss: 0.076781, acc.: 97.2168%] [G loss: 0.261512]\n",
            "0.243350560947939 0.24323529411764705\n",
            "247 [D loss: 0.075659, acc.: 97.3389%] [G loss: 0.291817]\n",
            "0.24899155426698602 0.24970588235294117\n",
            "248 [D loss: 0.078595, acc.: 97.2900%] [G loss: 0.253797]\n",
            "0.25362410185301903 0.2549264705882353\n",
            "249 [D loss: 0.089894, acc.: 96.9604%] [G loss: 0.306147]\n",
            "0.2492751796293962 0.25073529411764706\n",
            "250 [D loss: 0.093895, acc.: 96.7041%] [G loss: 0.264053]\n",
            "0.23799319299130214 0.23933823529411766\n",
            "251 [D loss: 0.080494, acc.: 97.5952%] [G loss: 0.181725]\n",
            "0.23402243791755956 0.23463235294117646\n",
            "252 [D loss: 0.071771, acc.: 97.8394%] [G loss: 0.148381]\n",
            "0.2385919576452792 0.2398529411764706\n",
            "253 [D loss: 0.070233, acc.: 98.0835%] [G loss: 0.285167]\n",
            "0.26474851884532963 0.26875\n",
            "254 [D loss: 0.132552, acc.: 95.5444%] [G loss: 0.351444]\n",
            "0.26197529307954115 0.26544117647058824\n",
            "255 [D loss: 0.108092, acc.: 96.0571%] [G loss: 0.282836]\n",
            "0.26027354090508004 0.26323529411764707\n",
            "256 [D loss: 0.077652, acc.: 97.5098%] [G loss: 0.204528]\n",
            "0.2793079541157191 0.2836764705882353\n",
            "257 [D loss: 0.125372, acc.: 94.9463%] [G loss: 0.372477]\n",
            "0.2388755830076894 0.24029411764705882\n",
            "258 [D loss: 0.122436, acc.: 96.2036%] [G loss: 0.250196]\n",
            "0.23380184041346275 0.2350735294117647\n",
            "259 [D loss: 0.111283, acc.: 96.7896%] [G loss: 0.204257]\n",
            "0.23383335434261943 0.2351470588235294\n",
            "260 [D loss: 0.080388, acc.: 97.2046%] [G loss: 0.217999]\n",
            "0.23336064540526913 0.23470588235294118\n",
            "261 [D loss: 0.081054, acc.: 97.3389%] [G loss: 0.195731]\n",
            "0.23326610361779906 0.23426470588235293\n",
            "262 [D loss: 0.073761, acc.: 97.5464%] [G loss: 0.157709]\n",
            "0.23307702004285893 0.23441176470588235\n",
            "263 [D loss: 0.071221, acc.: 97.5830%] [G loss: 0.163379]\n",
            "0.23329761754695574 0.23441176470588235\n",
            "264 [D loss: 0.067608, acc.: 97.7539%] [G loss: 0.188633]\n",
            "0.23326610361779906 0.23455882352941176\n",
            "265 [D loss: 0.066250, acc.: 97.8638%] [G loss: 0.152427]\n",
            "0.23332913147611245 0.23433823529411765\n",
            "266 [D loss: 0.069088, acc.: 97.8638%] [G loss: 0.195157]\n",
            "0.23326610361779906 0.23448529411764707\n",
            "267 [D loss: 0.066205, acc.: 97.8516%] [G loss: 0.192627]\n",
            "0.23326610361779906 0.23426470588235293\n",
            "268 [D loss: 0.065576, acc.: 97.8149%] [G loss: 0.193063]\n",
            "0.2332030757594857 0.23455882352941176\n",
            "269 [D loss: 0.068400, acc.: 97.6440%] [G loss: 0.238334]\n",
            "0.23332913147611245 0.23455882352941176\n",
            "270 [D loss: 0.066150, acc.: 97.7173%] [G loss: 0.204824]\n",
            "0.23332913147611245 0.23463235294117646\n",
            "271 [D loss: 0.071803, acc.: 97.6807%] [G loss: 0.188930]\n",
            "0.2334551871927392 0.23448529411764707\n",
            "272 [D loss: 0.059875, acc.: 97.9126%] [G loss: 0.169104]\n",
            "0.23323458968864239 0.23463235294117646\n",
            "273 [D loss: 0.054921, acc.: 98.0835%] [G loss: 0.176332]\n",
            "0.23342367326358252 0.23455882352941176\n",
            "274 [D loss: 0.064218, acc.: 97.8027%] [G loss: 0.210377]\n",
            "0.23332913147611245 0.23463235294117646\n",
            "275 [D loss: 0.063655, acc.: 98.1201%] [G loss: 0.208171]\n",
            "0.23314004790117232 0.23455882352941176\n",
            "276 [D loss: 0.055512, acc.: 98.3398%] [G loss: 0.137278]\n",
            "0.23323458968864239 0.23419117647058824\n",
            "277 [D loss: 0.067126, acc.: 97.6074%] [G loss: 0.158828]\n",
            "0.23323458968864239 0.23433823529411765\n",
            "278 [D loss: 0.068902, acc.: 97.9248%] [G loss: 0.172492]\n",
            "0.23323458968864239 0.23448529411764707\n",
            "279 [D loss: 0.054077, acc.: 98.2910%] [G loss: 0.166264]\n",
            "0.2332030757594857 0.23433823529411765\n",
            "280 [D loss: 0.054922, acc.: 98.1812%] [G loss: 0.156204]\n",
            "0.2332030757594857 0.23441176470588235\n",
            "281 [D loss: 0.055348, acc.: 98.1934%] [G loss: 0.143149]\n",
            "0.23310853397201564 0.23448529411764707\n",
            "282 [D loss: 0.055276, acc.: 97.9492%] [G loss: 0.145847]\n",
            "0.23323458968864239 0.23441176470588235\n",
            "283 [D loss: 0.053621, acc.: 98.2178%] [G loss: 0.149330]\n",
            "0.233171561830329 0.23433823529411765\n",
            "284 [D loss: 0.055984, acc.: 98.1689%] [G loss: 0.179426]\n",
            "0.2333921593344258 0.23441176470588235\n",
            "285 [D loss: 0.055728, acc.: 98.2422%] [G loss: 0.183785]\n",
            "0.23336064540526913 0.23455882352941176\n",
            "286 [D loss: 0.055498, acc.: 98.2178%] [G loss: 0.158105]\n",
            "0.23326610361779906 0.23448529411764707\n",
            "287 [D loss: 0.057595, acc.: 98.3032%] [G loss: 0.165858]\n",
            "0.2333921593344258 0.23441176470588235\n",
            "288 [D loss: 0.062413, acc.: 97.9980%] [G loss: 0.152495]\n",
            "0.23348670112189587 0.23448529411764707\n",
            "289 [D loss: 0.062906, acc.: 98.0103%] [G loss: 0.191133]\n",
            "0.23354972898020926 0.23433823529411765\n",
            "290 [D loss: 0.055042, acc.: 98.2300%] [G loss: 0.164969]\n",
            "0.23332913147611245 0.23463235294117646\n",
            "291 [D loss: 0.058020, acc.: 98.1812%] [G loss: 0.179823]\n",
            "0.23351821505105255 0.23463235294117646\n",
            "292 [D loss: 0.055047, acc.: 98.2544%] [G loss: 0.161734]\n",
            "0.23377032648430607 0.23470588235294118\n",
            "293 [D loss: 0.057639, acc.: 98.0957%] [G loss: 0.159624]\n",
            "0.23427454935081307 0.2350735294117647\n",
            "294 [D loss: 0.068444, acc.: 97.7295%] [G loss: 0.160155]\n",
            "0.23534602294214044 0.23602941176470588\n",
            "295 [D loss: 0.074524, acc.: 97.5708%] [G loss: 0.194878]\n",
            "0.23833984621202572 0.23852941176470588\n",
            "296 [D loss: 0.081861, acc.: 97.2534%] [G loss: 0.225202]\n",
            "0.23950586159082315 0.23926470588235293\n",
            "297 [D loss: 0.079096, acc.: 97.3633%] [G loss: 0.281886]\n",
            "0.23937980587419638 0.23926470588235293\n",
            "298 [D loss: 0.067657, acc.: 97.5830%] [G loss: 0.269054]\n",
            "0.2356296483045506 0.23654411764705882\n",
            "299 [D loss: 0.068885, acc.: 97.5708%] [G loss: 0.201435]\n",
            "0.23424303542165636 0.235\n",
            "300 [D loss: 0.064155, acc.: 98.0713%] [G loss: 0.145881]\n",
            "0.23386486827177613 0.23522058823529413\n",
            "301 [D loss: 0.054323, acc.: 98.3032%] [G loss: 0.158973]\n",
            "0.23380184041346275 0.235\n",
            "302 [D loss: 0.047466, acc.: 98.4253%] [G loss: 0.103999]\n",
            "0.2338963822009328 0.235\n",
            "303 [D loss: 0.051924, acc.: 98.4131%] [G loss: 0.118398]\n",
            "0.2332030757594857 0.2336029411764706\n",
            "304 [D loss: 0.053905, acc.: 98.1445%] [G loss: 0.172197]\n",
            "0.2384343879994958 0.23823529411764705\n",
            "305 [D loss: 0.063377, acc.: 98.1079%] [G loss: 0.200625]\n",
            "0.24719526030505484 0.24808823529411764\n",
            "306 [D loss: 0.069679, acc.: 97.6685%] [G loss: 0.171200]\n",
            "0.24817219210891214 0.2485294117647059\n",
            "307 [D loss: 0.088850, acc.: 97.5830%] [G loss: 0.167315]\n",
            "0.24517836883902686 0.24602941176470589\n",
            "308 [D loss: 0.084264, acc.: 97.6562%] [G loss: 0.151929]\n",
            "0.2413021555527543 0.24183823529411766\n",
            "309 [D loss: 0.059176, acc.: 98.1445%] [G loss: 0.104734]\n",
            "0.24076641875709062 0.24132352941176471\n",
            "310 [D loss: 0.067364, acc.: 97.8760%] [G loss: 0.134193]\n",
            "0.24092398840287407 0.24125\n",
            "311 [D loss: 0.062942, acc.: 98.0957%] [G loss: 0.107937]\n",
            "0.2452413966973402 0.24529411764705883\n",
            "312 [D loss: 0.081176, acc.: 97.6685%] [G loss: 0.185507]\n",
            "0.24792008067565863 0.24875\n",
            "313 [D loss: 0.073252, acc.: 97.5952%] [G loss: 0.142532]\n",
            "0.24908609605445606 0.2509558823529412\n",
            "314 [D loss: 0.081429, acc.: 97.1436%] [G loss: 0.147246]\n",
            "0.258162107651582 0.2605882352941176\n",
            "315 [D loss: 0.065829, acc.: 97.9004%] [G loss: 0.232071]\n",
            "0.29068448254128326 0.2933823529411765\n",
            "316 [D loss: 0.109014, acc.: 96.3379%] [G loss: 0.627565]\n",
            "0.25163872431614775 0.2526470588235294\n",
            "317 [D loss: 0.064169, acc.: 98.2788%] [G loss: 0.297069]\n",
            "0.24769948317156182 0.24860294117647058\n",
            "318 [D loss: 0.050824, acc.: 98.2056%] [G loss: 0.322424]\n",
            "0.24814067817975546 0.2489705882352941\n",
            "319 [D loss: 0.056428, acc.: 98.2178%] [G loss: 0.305241]\n",
            "0.2465019538636077 0.24794117647058825\n",
            "320 [D loss: 0.052533, acc.: 98.3276%] [G loss: 0.190245]\n",
            "0.243350560947939 0.24448529411764705\n",
            "321 [D loss: 0.055946, acc.: 98.2422%] [G loss: 0.241904]\n",
            "0.2386549855035926 0.23904411764705882\n",
            "322 [D loss: 0.053989, acc.: 98.0469%] [G loss: 0.252287]\n",
            "0.23559813437539392 0.23676470588235293\n",
            "323 [D loss: 0.057740, acc.: 98.3154%] [G loss: 0.246371]\n",
            "0.23477877221732005 0.23595588235294118\n",
            "324 [D loss: 0.048381, acc.: 98.3643%] [G loss: 0.186873]\n",
            "0.23430606327996975 0.23558823529411765\n",
            "325 [D loss: 0.046441, acc.: 98.2910%] [G loss: 0.311506]\n",
            "0.23263582503466532 0.23419117647058824\n",
            "326 [D loss: 0.048696, acc.: 98.5474%] [G loss: 0.225103]\n",
            "0.22916929282742973 0.23058823529411765\n",
            "327 [D loss: 0.058160, acc.: 97.7783%] [G loss: 0.534605]\n",
            "0.2337388125551494 0.23529411764705882\n",
            "328 [D loss: 0.055523, acc.: 98.4253%] [G loss: 0.573776]\n",
            "0.23377032648430607 0.2350735294117647\n",
            "329 [D loss: 0.056393, acc.: 98.3276%] [G loss: 0.360386]\n",
            "0.23314004790117232 0.2338235294117647\n",
            "330 [D loss: 0.047733, acc.: 98.1812%] [G loss: 0.389619]\n",
            "0.22863355603176605 0.22911764705882354\n",
            "331 [D loss: 0.053148, acc.: 98.0347%] [G loss: 0.465115]\n",
            "0.2329509643262322 0.23433823529411765\n",
            "332 [D loss: 0.043153, acc.: 98.5474%] [G loss: 0.367242]\n",
            "0.234180007563343 0.2351470588235294\n",
            "333 [D loss: 0.046345, acc.: 98.4985%] [G loss: 0.407030]\n",
            "0.234180007563343 0.23522058823529413\n",
            "334 [D loss: 0.040131, acc.: 98.6084%] [G loss: 0.409407]\n",
            "0.234180007563343 0.2351470588235294\n",
            "335 [D loss: 0.044118, acc.: 98.6206%] [G loss: 0.470367]\n",
            "0.23399092398840288 0.23536764705882354\n",
            "336 [D loss: 0.045580, acc.: 98.5107%] [G loss: 0.410512]\n",
            "0.23421152149249969 0.23544117647058824\n",
            "337 [D loss: 0.043304, acc.: 98.4741%] [G loss: 0.448220]\n",
            "0.23430606327996975 0.235\n",
            "338 [D loss: 0.052503, acc.: 98.4131%] [G loss: 0.466326]\n",
            "0.23411697970502962 0.2350735294117647\n",
            "339 [D loss: 0.043028, acc.: 98.4619%] [G loss: 0.481187]\n",
            "0.234180007563343 0.23529411764705882\n",
            "340 [D loss: 0.042601, acc.: 98.6450%] [G loss: 0.397130]\n",
            "0.2343690911382831 0.23529411764705882\n",
            "341 [D loss: 0.054859, acc.: 98.2422%] [G loss: 0.509939]\n",
            "0.23402243791755956 0.23522058823529413\n",
            "342 [D loss: 0.048671, acc.: 98.4253%] [G loss: 0.710170]\n",
            "0.2344321189965965 0.23551470588235293\n",
            "343 [D loss: 0.059375, acc.: 98.3276%] [G loss: 1.377662]\n",
            "0.2347157443590067 0.23580882352941177\n",
            "344 [D loss: 0.042112, acc.: 98.4253%] [G loss: 1.537664]\n",
            "0.2395688894491365 0.2427205882352941\n",
            "345 [D loss: 0.049430, acc.: 98.3398%] [G loss: 2.066220]\n",
            "0.23997857052817345 0.24294117647058824\n",
            "346 [D loss: 0.054013, acc.: 98.0835%] [G loss: 3.156819]\n",
            "0.2658515063658137 0.2665441176470588\n",
            "347 [D loss: 0.057013, acc.: 98.2300%] [G loss: 1.996363]\n",
            "0.3518530190344132 0.3477205882352941\n",
            "348 [D loss: 0.060772, acc.: 98.3154%] [G loss: 1.273094]\n",
            "0.39127694440942895 0.3890441176470588\n",
            "349 [D loss: 0.085589, acc.: 97.7051%] [G loss: 1.434139]\n",
            "0.2802533719904198 0.2798529411764706\n",
            "350 [D loss: 0.108617, acc.: 96.9238%] [G loss: 1.875597]\n",
            "0.30001260557166265 0.3038235294117647\n",
            "351 [D loss: 0.190375, acc.: 94.0063%] [G loss: 2.796447]\n",
            "0.29667212908105384 0.29970588235294116\n",
            "352 [D loss: 0.179307, acc.: 93.4326%] [G loss: 2.151448]\n",
            "0.2734463632925753 0.27242647058823527\n",
            "353 [D loss: 0.112581, acc.: 96.6553%] [G loss: 1.299032]\n",
            "0.26667086852388755 0.2665441176470588\n",
            "354 [D loss: 0.080767, acc.: 97.2534%] [G loss: 0.799868]\n",
            "0.26597756208244044 0.26580882352941176\n",
            "355 [D loss: 0.078229, acc.: 97.7295%] [G loss: 0.733718]\n",
            "0.2648745745619564 0.26426470588235296\n",
            "356 [D loss: 0.072117, acc.: 97.7295%] [G loss: 0.897087]\n",
            "0.25649186940627755 0.2563970588235294\n",
            "357 [D loss: 0.069201, acc.: 97.8149%] [G loss: 0.842912]\n",
            "0.25601916046892725 0.2559558823529412\n",
            "358 [D loss: 0.073046, acc.: 97.9126%] [G loss: 0.843702]\n",
            "0.25601916046892725 0.2559558823529412\n",
            "359 [D loss: 0.079707, acc.: 97.4121%] [G loss: 0.735117]\n",
            "0.25601916046892725 0.2559558823529412\n",
            "360 [D loss: 0.081445, acc.: 97.4854%] [G loss: 0.756705]\n",
            "0.2559876465397706 0.25588235294117645\n",
            "361 [D loss: 0.082898, acc.: 97.5220%] [G loss: 0.742148]\n",
            "0.25601916046892725 0.2559558823529412\n",
            "362 [D loss: 0.070612, acc.: 97.9004%] [G loss: 0.686459]\n",
            "0.2559876465397706 0.2559558823529412\n",
            "363 [D loss: 0.068559, acc.: 97.6318%] [G loss: 0.618628]\n",
            "0.25601916046892725 0.25588235294117645\n",
            "364 [D loss: 0.066797, acc.: 97.9004%] [G loss: 0.613210]\n",
            "0.25601916046892725 0.25588235294117645\n",
            "365 [D loss: 0.077489, acc.: 97.4976%] [G loss: 0.578396]\n",
            "0.25601916046892725 0.25588235294117645\n",
            "366 [D loss: 0.066697, acc.: 97.9126%] [G loss: 0.518726]\n",
            "0.25601916046892725 0.25588235294117645\n",
            "367 [D loss: 0.073714, acc.: 97.6440%] [G loss: 0.472888]\n",
            "0.25605067439808393 0.25588235294117645\n",
            "368 [D loss: 0.070078, acc.: 97.8271%] [G loss: 0.617286]\n",
            "0.25605067439808393 0.25588235294117645\n",
            "369 [D loss: 0.071578, acc.: 97.8638%] [G loss: 0.510904]\n",
            "0.25601916046892725 0.25588235294117645\n",
            "370 [D loss: 0.064177, acc.: 97.8638%] [G loss: 0.485501]\n",
            "0.25605067439808393 0.25588235294117645\n",
            "371 [D loss: 0.075686, acc.: 97.6685%] [G loss: 0.624570]\n",
            "0.25605067439808393 0.25588235294117645\n",
            "372 [D loss: 0.071029, acc.: 97.7295%] [G loss: 0.492762]\n",
            "0.25601916046892725 0.25588235294117645\n",
            "373 [D loss: 0.077326, acc.: 97.7417%] [G loss: 0.554913]\n",
            "0.25601916046892725 0.25588235294117645\n",
            "374 [D loss: 0.063693, acc.: 97.8271%] [G loss: 0.515176]\n",
            "0.25605067439808393 0.25588235294117645\n",
            "375 [D loss: 0.076045, acc.: 97.5220%] [G loss: 0.453995]\n",
            "0.25608218832724067 0.25588235294117645\n",
            "376 [D loss: 0.066690, acc.: 97.8638%] [G loss: 0.536107]\n",
            "0.25601916046892725 0.25588235294117645\n",
            "377 [D loss: 0.079087, acc.: 97.5220%] [G loss: 0.502077]\n",
            "0.2559876465397706 0.25588235294117645\n",
            "378 [D loss: 0.076655, acc.: 97.4976%] [G loss: 0.535966]\n",
            "0.25601916046892725 0.2559558823529412\n",
            "379 [D loss: 0.067928, acc.: 97.7173%] [G loss: 0.431762]\n",
            "0.2559876465397706 0.25588235294117645\n",
            "380 [D loss: 0.073020, acc.: 97.6074%] [G loss: 0.548388]\n",
            "0.2559876465397706 0.2559558823529412\n",
            "381 [D loss: 0.073968, acc.: 97.6196%] [G loss: 0.471020]\n",
            "0.25601916046892725 0.2559558823529412\n",
            "382 [D loss: 0.068672, acc.: 97.6074%] [G loss: 0.460045]\n",
            "0.25601916046892725 0.2559558823529412\n",
            "383 [D loss: 0.069270, acc.: 97.7417%] [G loss: 0.396419]\n",
            "0.25601916046892725 0.25588235294117645\n",
            "384 [D loss: 0.072281, acc.: 97.6685%] [G loss: 0.410159]\n",
            "0.2559876465397706 0.2560294117647059\n",
            "385 [D loss: 0.076741, acc.: 97.6318%] [G loss: 0.468335]\n",
            "0.2559876465397706 0.2559558823529412\n",
            "386 [D loss: 0.066209, acc.: 97.7905%] [G loss: 0.485091]\n",
            "0.2559876465397706 0.2559558823529412\n",
            "387 [D loss: 0.081635, acc.: 97.4487%] [G loss: 0.445046]\n",
            "0.2559876465397706 0.2559558823529412\n",
            "388 [D loss: 0.058920, acc.: 98.2056%] [G loss: 0.484527]\n",
            "0.25601916046892725 0.2561029411764706\n",
            "389 [D loss: 0.063168, acc.: 97.9736%] [G loss: 0.602726]\n",
            "0.25605067439808393 0.2559558823529412\n",
            "390 [D loss: 0.070002, acc.: 97.7905%] [G loss: 0.427993]\n",
            "0.25601916046892725 0.2561029411764706\n",
            "391 [D loss: 0.075262, acc.: 97.7173%] [G loss: 0.476471]\n",
            "0.25601916046892725 0.2560294117647059\n",
            "392 [D loss: 0.065088, acc.: 97.7783%] [G loss: 0.474022]\n",
            "0.25605067439808393 0.2561029411764706\n",
            "393 [D loss: 0.069403, acc.: 97.6318%] [G loss: 0.457474]\n",
            "0.25601916046892725 0.2560294117647059\n",
            "394 [D loss: 0.061502, acc.: 97.7905%] [G loss: 0.550139]\n",
            "0.25601916046892725 0.2561764705882353\n",
            "395 [D loss: 0.067584, acc.: 98.0103%] [G loss: 0.431435]\n",
            "0.25601916046892725 0.2561029411764706\n",
            "396 [D loss: 0.069374, acc.: 97.6929%] [G loss: 0.465740]\n",
            "0.25605067439808393 0.2561764705882353\n",
            "397 [D loss: 0.065722, acc.: 97.9858%] [G loss: 0.537179]\n",
            "0.25611370225639735 0.2561764705882353\n",
            "398 [D loss: 0.070140, acc.: 97.6685%] [G loss: 0.527943]\n",
            "0.2559876465397706 0.2561029411764706\n",
            "399 [D loss: 0.067504, acc.: 97.7295%] [G loss: 0.487982]\n",
            "0.25601916046892725 0.2561029411764706\n",
            "400 [D loss: 0.071963, acc.: 97.7051%] [G loss: 0.525177]\n",
            "0.2559876465397706 0.2561029411764706\n",
            "401 [D loss: 0.070794, acc.: 97.5220%] [G loss: 0.587700]\n",
            "0.25605067439808393 0.2561029411764706\n",
            "402 [D loss: 0.066349, acc.: 97.8760%] [G loss: 0.509989]\n",
            "0.25608218832724067 0.2561029411764706\n",
            "403 [D loss: 0.076796, acc.: 97.4243%] [G loss: 0.572974]\n",
            "0.25608218832724067 0.2561029411764706\n",
            "404 [D loss: 0.077173, acc.: 97.5098%] [G loss: 0.629311]\n",
            "0.25605067439808393 0.2561029411764706\n",
            "405 [D loss: 0.068901, acc.: 97.7051%] [G loss: 0.537820]\n",
            "0.25608218832724067 0.2561029411764706\n",
            "406 [D loss: 0.063208, acc.: 97.7539%] [G loss: 0.505183]\n",
            "0.256145216185554 0.2561029411764706\n",
            "407 [D loss: 0.067707, acc.: 97.8394%] [G loss: 0.598191]\n",
            "0.256145216185554 0.2561029411764706\n",
            "408 [D loss: 0.065165, acc.: 97.8394%] [G loss: 0.540755]\n",
            "0.256145216185554 0.2561029411764706\n",
            "409 [D loss: 0.056467, acc.: 98.1445%] [G loss: 0.634225]\n",
            "0.25623975797302406 0.2561764705882353\n",
            "410 [D loss: 0.070208, acc.: 97.9614%] [G loss: 0.668071]\n",
            "0.2561767301147107 0.2561029411764706\n",
            "411 [D loss: 0.068214, acc.: 97.9736%] [G loss: 0.623034]\n",
            "0.25623975797302406 0.2561029411764706\n",
            "412 [D loss: 0.071696, acc.: 97.6807%] [G loss: 0.694973]\n",
            "0.2561767301147107 0.2561764705882353\n",
            "413 [D loss: 0.069678, acc.: 97.7661%] [G loss: 0.646178]\n",
            "0.256145216185554 0.2561764705882353\n",
            "414 [D loss: 0.069013, acc.: 97.7173%] [G loss: 0.676733]\n",
            "0.2561767301147107 0.2561764705882353\n",
            "415 [D loss: 0.070582, acc.: 97.8027%] [G loss: 0.566443]\n",
            "0.25627127190218074 0.2561764705882353\n",
            "416 [D loss: 0.070670, acc.: 97.5952%] [G loss: 0.650070]\n",
            "0.25627127190218074 0.2561764705882353\n",
            "417 [D loss: 0.071291, acc.: 97.3389%] [G loss: 0.635904]\n",
            "0.25623975797302406 0.2561764705882353\n",
            "418 [D loss: 0.072892, acc.: 97.8516%] [G loss: 0.722231]\n",
            "0.25623975797302406 0.2561029411764706\n",
            "419 [D loss: 0.066341, acc.: 97.8394%] [G loss: 0.610673]\n",
            "0.25623975797302406 0.2561764705882353\n",
            "420 [D loss: 0.071127, acc.: 97.8271%] [G loss: 0.607011]\n",
            "0.256145216185554 0.25625\n",
            "421 [D loss: 0.072864, acc.: 97.9492%] [G loss: 0.613433]\n",
            "0.25636581368965083 0.25625\n",
            "422 [D loss: 0.070405, acc.: 97.7661%] [G loss: 0.630573]\n",
            "0.2563027858313375 0.2561764705882353\n",
            "423 [D loss: 0.061257, acc.: 98.0957%] [G loss: 0.639660]\n",
            "0.25633429976049416 0.2561764705882353\n",
            "424 [D loss: 0.072412, acc.: 97.8271%] [G loss: 0.637389]\n",
            "0.25627127190218074 0.2561764705882353\n",
            "425 [D loss: 0.061044, acc.: 97.9126%] [G loss: 0.701214]\n",
            "0.2562082440438674 0.2561029411764706\n",
            "426 [D loss: 0.074051, acc.: 97.6929%] [G loss: 0.672185]\n",
            "0.25627127190218074 0.2561764705882353\n",
            "427 [D loss: 0.059002, acc.: 98.0835%] [G loss: 0.605563]\n",
            "0.25633429976049416 0.25625\n",
            "428 [D loss: 0.074048, acc.: 97.7051%] [G loss: 0.678175]\n",
            "0.25623975797302406 0.2561764705882353\n",
            "429 [D loss: 0.074228, acc.: 97.6074%] [G loss: 0.752906]\n",
            "0.2562082440438674 0.2561764705882353\n",
            "430 [D loss: 0.075935, acc.: 97.8516%] [G loss: 0.697624]\n",
            "0.25623975797302406 0.2561764705882353\n",
            "431 [D loss: 0.078824, acc.: 97.7295%] [G loss: 0.755651]\n",
            "0.2561767301147107 0.2561764705882353\n",
            "432 [D loss: 0.061900, acc.: 97.9614%] [G loss: 0.829561]\n",
            "0.2562082440438674 0.2561764705882353\n",
            "433 [D loss: 0.067166, acc.: 98.0103%] [G loss: 0.756343]\n",
            "0.2562082440438674 0.2561764705882353\n",
            "434 [D loss: 0.076775, acc.: 97.6807%] [G loss: 0.838475]\n",
            "0.25623975797302406 0.2561764705882353\n",
            "435 [D loss: 0.074284, acc.: 97.5220%] [G loss: 0.915249]\n",
            "0.25608218832724067 0.25625\n",
            "436 [D loss: 0.066984, acc.: 98.0835%] [G loss: 0.838927]\n",
            "0.25605067439808393 0.2561029411764706\n",
            "437 [D loss: 0.075490, acc.: 97.7417%] [G loss: 0.893241]\n",
            "0.25611370225639735 0.2561029411764706\n",
            "438 [D loss: 0.072110, acc.: 97.7417%] [G loss: 0.809713]\n",
            "0.256145216185554 0.2561029411764706\n",
            "439 [D loss: 0.080860, acc.: 97.5464%] [G loss: 0.854929]\n",
            "0.25608218832724067 0.2561029411764706\n",
            "440 [D loss: 0.072501, acc.: 97.7417%] [G loss: 0.871109]\n",
            "0.25605067439808393 0.2560294117647059\n",
            "441 [D loss: 0.072465, acc.: 97.9736%] [G loss: 0.886021]\n",
            "0.25605067439808393 0.2560294117647059\n",
            "442 [D loss: 0.076302, acc.: 97.4854%] [G loss: 0.858209]\n",
            "0.25605067439808393 0.2560294117647059\n",
            "443 [D loss: 0.079355, acc.: 97.5342%] [G loss: 1.025279]\n",
            "0.25601916046892725 0.2559558823529412\n",
            "444 [D loss: 0.075875, acc.: 97.4976%] [G loss: 0.900677]\n",
            "0.25601916046892725 0.2561029411764706\n",
            "445 [D loss: 0.072027, acc.: 97.8027%] [G loss: 0.952891]\n",
            "0.25601916046892725 0.2560294117647059\n",
            "446 [D loss: 0.069191, acc.: 97.5098%] [G loss: 1.042988]\n",
            "0.2559561326106139 0.2559558823529412\n",
            "447 [D loss: 0.068072, acc.: 97.8149%] [G loss: 1.110874]\n",
            "0.2559876465397706 0.2560294117647059\n",
            "448 [D loss: 0.067506, acc.: 97.8149%] [G loss: 1.036436]\n",
            "0.25601916046892725 0.2559558823529412\n",
            "449 [D loss: 0.070616, acc.: 97.7783%] [G loss: 1.187343]\n",
            "0.25601916046892725 0.2560294117647059\n",
            "450 [D loss: 0.069913, acc.: 97.7173%] [G loss: 1.162012]\n",
            "0.25605067439808393 0.2560294117647059\n",
            "451 [D loss: 0.079603, acc.: 97.3633%] [G loss: 1.327100]\n",
            "0.25605067439808393 0.2559558823529412\n",
            "452 [D loss: 0.070052, acc.: 97.6929%] [G loss: 1.404318]\n",
            "0.25601916046892725 0.2560294117647059\n",
            "453 [D loss: 0.072103, acc.: 97.7051%] [G loss: 1.289985]\n",
            "0.25608218832724067 0.2559558823529412\n",
            "454 [D loss: 0.075932, acc.: 97.6318%] [G loss: 1.229065]\n",
            "0.25605067439808393 0.2560294117647059\n",
            "455 [D loss: 0.073856, acc.: 97.6318%] [G loss: 1.421636]\n",
            "0.25601916046892725 0.2561029411764706\n",
            "456 [D loss: 0.064064, acc.: 97.6807%] [G loss: 1.383522]\n",
            "0.25601916046892725 0.2560294117647059\n",
            "457 [D loss: 0.077147, acc.: 97.5342%] [G loss: 1.603257]\n",
            "0.25605067439808393 0.2560294117647059\n",
            "458 [D loss: 0.075765, acc.: 97.4609%] [G loss: 1.514236]\n",
            "0.2581305937224253 0.25933823529411765\n",
            "459 [D loss: 0.080261, acc.: 97.8149%] [G loss: 0.974051]\n",
            "0.2309340728602042 0.2311764705882353\n",
            "460 [D loss: 0.075343, acc.: 97.2412%] [G loss: 1.033572]\n",
            "0.03157695701500063 0.030147058823529412\n",
            "461 [D loss: 0.082001, acc.: 97.2290%] [G loss: 0.411230]\n",
            "0.03148241522753057 0.030220588235294117\n",
            "462 [D loss: 0.087448, acc.: 97.0825%] [G loss: 0.489200]\n",
            "0.03129333165259045 0.03\n",
            "463 [D loss: 0.082893, acc.: 97.3145%] [G loss: 0.468970]\n",
            "0.031324845581747134 0.03\n",
            "464 [D loss: 0.084481, acc.: 97.3267%] [G loss: 0.585925]\n",
            "0.03135635951090382 0.030073529411764707\n",
            "465 [D loss: 0.084656, acc.: 97.0825%] [G loss: 0.671036]\n",
            "0.03129333165259045 0.03\n",
            "466 [D loss: 0.080756, acc.: 97.1069%] [G loss: 0.714411]\n",
            "0.03135635951090382 0.03\n",
            "467 [D loss: 0.082439, acc.: 97.2168%] [G loss: 0.918279]\n",
            "0.031324845581747134 0.03\n",
            "468 [D loss: 0.074647, acc.: 97.2168%] [G loss: 0.775480]\n",
            "0.03129333165259045 0.030073529411764707\n",
            "469 [D loss: 0.087030, acc.: 97.1191%] [G loss: 1.042435]\n",
            "0.031230303794277072 0.029926470588235294\n",
            "470 [D loss: 0.088584, acc.: 97.1069%] [G loss: 1.065162]\n",
            "0.03110424807765032 0.03\n",
            "471 [D loss: 0.082645, acc.: 97.4243%] [G loss: 1.029716]\n",
            "0.03110424807765032 0.03\n",
            "472 [D loss: 0.074491, acc.: 97.6440%] [G loss: 1.273716]\n",
            "0.03110424807765032 0.029926470588235294\n",
            "473 [D loss: 0.075318, acc.: 97.5708%] [G loss: 1.406733]\n",
            "0.031041220219336946 0.029926470588235294\n",
            "474 [D loss: 0.068483, acc.: 97.6685%] [G loss: 1.119935]\n",
            "0.031072734148493635 0.02985294117647059\n",
            "475 [D loss: 0.083549, acc.: 97.4243%] [G loss: 1.314147]\n",
            "0.03110424807765032 0.029926470588235294\n",
            "476 [D loss: 0.067070, acc.: 97.6929%] [G loss: 1.373579]\n",
            "0.031041220219336946 0.02985294117647059\n",
            "477 [D loss: 0.073874, acc.: 97.5830%] [G loss: 1.065573]\n",
            "0.03100970629018026 0.02985294117647059\n",
            "478 [D loss: 0.057556, acc.: 97.6807%] [G loss: 1.245670]\n",
            "0.031072734148493635 0.029926470588235294\n",
            "479 [D loss: 0.070358, acc.: 97.1558%] [G loss: 1.164974]\n",
            "0.031072734148493635 0.02985294117647059\n",
            "480 [D loss: 0.072518, acc.: 97.6318%] [G loss: 1.187036]\n",
            "0.031041220219336946 0.02977941176470588\n",
            "481 [D loss: 0.069963, acc.: 97.9126%] [G loss: 0.951103]\n",
            "0.03100970629018026 0.02985294117647059\n",
            "482 [D loss: 0.074711, acc.: 97.4365%] [G loss: 1.049840]\n",
            "0.03100970629018026 0.02977941176470588\n",
            "483 [D loss: 0.062303, acc.: 97.9004%] [G loss: 1.049653]\n",
            "0.031041220219336946 0.02977941176470588\n",
            "484 [D loss: 0.075055, acc.: 97.4731%] [G loss: 1.011064]\n",
            "0.030978192361023574 0.02985294117647059\n",
            "485 [D loss: 0.065190, acc.: 97.7417%] [G loss: 1.137486]\n",
            "0.031041220219336946 0.02977941176470588\n",
            "486 [D loss: 0.068283, acc.: 97.9492%] [G loss: 1.075240]\n",
            "0.03100970629018026 0.02977941176470588\n",
            "487 [D loss: 0.072287, acc.: 97.5220%] [G loss: 1.046344]\n",
            "0.031041220219336946 0.02985294117647059\n",
            "488 [D loss: 0.071622, acc.: 97.5952%] [G loss: 1.074263]\n",
            "0.03100970629018026 0.02985294117647059\n",
            "489 [D loss: 0.064596, acc.: 97.3999%] [G loss: 0.951350]\n",
            "0.031041220219336946 0.02985294117647059\n",
            "490 [D loss: 0.058782, acc.: 97.7539%] [G loss: 0.968740]\n",
            "0.031041220219336946 0.02977941176470588\n",
            "491 [D loss: 0.071110, acc.: 97.5098%] [G loss: 1.039685]\n",
            "0.031041220219336946 0.02977941176470588\n",
            "492 [D loss: 0.065415, acc.: 97.3877%] [G loss: 1.000077]\n",
            "0.031041220219336946 0.02985294117647059\n",
            "493 [D loss: 0.067882, acc.: 97.7661%] [G loss: 1.052713]\n",
            "0.031041220219336946 0.02985294117647059\n",
            "494 [D loss: 0.067389, acc.: 97.6074%] [G loss: 1.062308]\n",
            "0.031041220219336946 0.02977941176470588\n",
            "495 [D loss: 0.065002, acc.: 97.7051%] [G loss: 1.050326]\n",
            "0.031041220219336946 0.02985294117647059\n",
            "496 [D loss: 0.060762, acc.: 97.9248%] [G loss: 0.996774]\n",
            "0.031072734148493635 0.02985294117647059\n",
            "497 [D loss: 0.067760, acc.: 97.8638%] [G loss: 1.039283]\n",
            "0.031041220219336946 0.02985294117647059\n",
            "498 [D loss: 0.067171, acc.: 97.6440%] [G loss: 1.060428]\n",
            "0.031072734148493635 0.02985294117647059\n",
            "499 [D loss: 0.066796, acc.: 97.6929%] [G loss: 0.916818]\n",
            "\n",
            "\n",
            "---MLP SameTrainData\n",
            "\n",
            "Original_Train_TPR: 0.9441888314635069, Adver_Train_TPR: 0.031072734148493635\n",
            "\n",
            "Original_Test_TPR: 0.940514705882353, Adver_Test_TPR: 0.02985294117647059\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "---TPR after the blackbox_detector is retrained (Before retraining MalGAN).\n",
            "\n",
            "Train_TPR: 1.0, Test_TPR: 1.0\n",
            "[0.9413210639102483] [0.9393382352941176] \n",
            "\n",
            "Training epochs.....\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "0.9999684860708433 0.9999264705882352\n",
            "0.9997794024959031 0.9997058823529412\n",
            "0.9996533467792764 0.9996323529411765\n",
            "0.9946111181142064 0.9932352941176471\n",
            "0.99476868775999 0.9934558823529411\n",
            "0.99486322954746 0.9934558823529411\n",
            "0.9945480902558931 0.9930882352941176\n",
            "0.994264464893483 0.9925735294117647\n",
            "0.9936972141686625 0.9923529411764705\n",
            "0.9921215177108282 0.9903676470588235\n",
            "0.9915227530568511 0.9888970588235294\n",
            "0.9902306819614269 0.9873529411764705\n",
            "0.9829824782553889 0.9805147058823529\n",
            "0.9574246817093155 0.9546323529411764\n",
            "0.9491995461994202 0.9461029411764705\n",
            "0.9484432118996596 0.9454411764705882\n",
            "0.9484747258288163 0.9452205882352941\n",
            "0.948096558678936 0.9453676470588235\n",
            "0.9476868775998991 0.9447794117647059\n",
            "0.8443527038951216 0.8427941176470588\n",
            "0.8328501197529308 0.8314705882352941\n",
            "0.8948065044749779 0.89125\n",
            "0.9157947812933317 0.9116176470588235\n",
            "0.915857809151645 0.9118382352941177\n",
            "0.9091768561704273 0.9056617647058823\n",
            "0.9042921971511408 0.9011029411764706\n",
            "0.8996281356359511 0.8971323529411764\n",
            "0.8916235976301525 0.8905147058823529\n",
            "0.8678305811168536 0.8647058823529412\n",
            "0.7400731123156435 0.7393382352941177\n",
            "0.7440753813185428 0.7442647058823529\n",
            "0.7436657002395058 0.7438235294117647\n",
            "0.7429723937980588 0.7441176470588236\n",
            "0.742436657002395 0.7430882352941176\n",
            "0.7413651834110677 0.7419117647058824\n",
            "0.7400731123156435 0.7411029411764706\n",
            "0.7388755830076894 0.7384558823529411\n",
            "0.7369532333291314 0.7359558823529412\n",
            "0.7344636329257532 0.7333823529411765\n",
            "0.731658893230808 0.7294117647058823\n",
            "0.7358187318794908 0.7342647058823529\n",
            "0.7344636329257532 0.7347058823529412\n",
            "0.7280978192361024 0.7268382352941176\n",
            "0.7234337577209127 0.7222794117647059\n",
            "0.7109857557040212 0.7086029411764706\n",
            "0.703643010210513 0.700735294117647\n",
            "0.6989474347661666 0.6961764705882353\n",
            "0.6932118996596496 0.6893382352941176\n",
            "0.6861842934577083 0.6808823529411765\n",
            "0.6812050926509517 0.6764705882352942\n",
            "0.6775179629396193 0.6726470588235294\n",
            "0.6758792386234715 0.6709558823529411\n",
            "0.6754695575444346 0.669485294117647\n",
            "0.6738938610866003 0.6684558823529412\n",
            "0.6727278457078029 0.6674264705882353\n",
            "0.6713412328249087 0.6661764705882353\n",
            "0.6707109542417748 0.6651470588235294\n",
            "0.6700806756586412 0.6647794117647059\n",
            "0.6678431866885163 0.6615441176470588\n",
            "0.6663935459473087 0.6603676470588236\n",
            "0.6660468927265851 0.6593382352941176\n",
            "0.6656056977183915 0.65875\n",
            "0.6652275305685112 0.6586029411764706\n",
            "0.6649439052061011 0.6586764705882353\n",
            "0.6645972519853776 0.6580882352941176\n",
            "0.6640930291188706 0.6580147058823529\n",
            "0.6638724316147737 0.6575735294117647\n",
            "0.6633997226774234 0.6572058823529412\n",
            "0.6630530694566998 0.6570588235294118\n",
            "0.6627379301651329 0.6566911764705883\n",
            "0.662328249086096 0.65625\n",
            "0.6614458590697088 0.6555882352941177\n",
            "0.6604689272658515 0.6546323529411765\n",
            "0.6589877725954872 0.6534558823529412\n",
            "0.6583890079415101 0.6530147058823529\n",
            "0.6568448254128325 0.6506617647058823\n",
            "0.6183348039833606 0.6089705882352942\n",
            "0.6099205848985252 0.5998529411764706\n",
            "0.5962435396445229 0.5859558823529412\n",
            "0.5929976049413841 0.5824264705882353\n",
            "0.5927770074372872 0.5811764705882353\n",
            "0.592808521366444 0.5819852941176471\n",
            "0.5920206731375268 0.5814705882352941\n",
            "0.5909807134753561 0.5802205882352941\n",
            "0.5916109920584899 0.5810294117647059\n",
            "0.5918315895625866 0.5813970588235294\n",
            "0.5919576452792135 0.5816911764705882\n",
            "0.5920837009958402 0.5816911764705882\n",
            "0.5921467288541535 0.5813970588235294\n",
            "0.5924618681457204 0.5818382352941176\n",
            "0.5923673263582504 0.5819117647058824\n",
            "0.5926509517206605 0.5818382352941176\n",
            "0.5926509517206605 0.5820588235294117\n",
            "0.592808521366444 0.5818382352941176\n",
            "0.5927770074372872 0.5820588235294117\n",
            "0.592808521366444 0.5819852941176471\n",
            "0.5929345770830707 0.5819852941176471\n",
            "\n",
            "\n",
            "---MLP SameTrainData\n",
            "\n",
            "Original_Train_TPR: 0.9413210639102483, Adver_Train_TPR: 0.5929345770830707\n",
            "\n",
            "Original_Test_TPR: 0.9393382352941176, Adver_Test_TPR: 0.5819852941176471\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A590JtPheVPQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6ba282e9-a1af-4364-e057-9e0fb389f89f"
      },
      "source": [
        "botgan_LR = BotGAN(blackbox='LR')\n",
        "botgan_LR.train(epochs=500, batch_size=4096)\n",
        "botgan_LR.retrain_blackbox_detector()\n",
        "botgan_LR.train(epochs=100, batch_size=4096, is_first=False)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"substitute_detector\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 53)]              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 256)               13824     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 257       \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 1)                 0         \n",
            "=================================================================\n",
            "Total params: 14,081\n",
            "Trainable params: 14,081\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"generator\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, 53)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_3 (InputLayer)            [(None, 10)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 63)           0           input_2[0][0]                    \n",
            "                                                                 input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 256)          16384       concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 53)           13621       dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 53)           0           dense_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "maximum (Maximum)               (None, 53)           0           input_2[0][0]                    \n",
            "                                                                 activation_1[0][0]               \n",
            "==================================================================================================\n",
            "Total params: 30,005\n",
            "Trainable params: 30,005\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[0.9208685238875584] [0.92] \n",
            "\n",
            "Training epochs.....\n",
            "0.0717257027606202 0.06816176470588235\n",
            "0 [D loss: 0.413007, acc.: 88.3423%] [G loss: 0.031979]\n",
            "0.0919576452792134 0.08948529411764707\n",
            "1 [D loss: 0.329775, acc.: 89.6240%] [G loss: 0.238380]\n",
            "0.05237615025841422 0.049852941176470586\n",
            "2 [D loss: 0.309988, acc.: 89.3433%] [G loss: 0.112922]\n",
            "0.0043489222236228415 0.0041911764705882355\n",
            "3 [D loss: 0.200758, acc.: 93.4570%] [G loss: 0.137913]\n",
            "0.00025211143325349803 0.00022058823529411765\n",
            "4 [D loss: 0.159813, acc.: 94.7266%] [G loss: 0.036419]\n",
            "0.00018908357494012352 0.00014705882352941175\n",
            "5 [D loss: 0.152901, acc.: 94.5190%] [G loss: 0.034910]\n",
            "0.00018908357494012352 0.00014705882352941175\n",
            "6 [D loss: 0.129753, acc.: 95.0195%] [G loss: 0.016246]\n",
            "3.1513929156687254e-05 0.0\n",
            "7 [D loss: 0.131096, acc.: 94.5801%] [G loss: 0.041220]\n",
            "3.1513929156687254e-05 0.0\n",
            "8 [D loss: 0.117651, acc.: 95.2393%] [G loss: 0.043824]\n",
            "3.1513929156687254e-05 0.0\n",
            "9 [D loss: 0.118494, acc.: 94.9097%] [G loss: 0.033404]\n",
            "3.1513929156687254e-05 0.0\n",
            "10 [D loss: 0.122406, acc.: 94.3726%] [G loss: 0.038381]\n",
            "3.1513929156687254e-05 0.0\n",
            "11 [D loss: 0.113403, acc.: 94.9951%] [G loss: 0.026706]\n",
            "3.1513929156687254e-05 0.0\n",
            "12 [D loss: 0.109890, acc.: 94.9951%] [G loss: 0.020857]\n",
            "3.1513929156687254e-05 0.0\n",
            "13 [D loss: 0.101547, acc.: 95.5566%] [G loss: 0.061275]\n",
            "3.1513929156687254e-05 0.0\n",
            "14 [D loss: 0.091953, acc.: 96.5698%] [G loss: 0.008208]\n",
            "3.1513929156687254e-05 0.0\n",
            "15 [D loss: 0.089089, acc.: 96.2280%] [G loss: 0.025848]\n",
            "3.1513929156687254e-05 0.0\n",
            "16 [D loss: 0.092908, acc.: 96.2280%] [G loss: 0.024827]\n",
            "3.1513929156687254e-05 0.0\n",
            "17 [D loss: 0.092837, acc.: 96.1670%] [G loss: 0.039736]\n",
            "3.1513929156687254e-05 0.0\n",
            "18 [D loss: 0.087777, acc.: 96.3379%] [G loss: 0.024644]\n",
            "3.1513929156687254e-05 0.0\n",
            "19 [D loss: 0.079620, acc.: 97.0581%] [G loss: 0.108094]\n",
            "3.1513929156687254e-05 0.0\n",
            "20 [D loss: 0.084231, acc.: 96.7163%] [G loss: 0.082290]\n",
            "3.1513929156687254e-05 0.0\n",
            "21 [D loss: 0.080117, acc.: 96.5698%] [G loss: 0.037115]\n",
            "3.1513929156687254e-05 0.0\n",
            "22 [D loss: 0.077788, acc.: 96.8262%] [G loss: 0.005335]\n",
            "3.1513929156687254e-05 0.0\n",
            "23 [D loss: 0.076609, acc.: 97.0337%] [G loss: 0.045264]\n",
            "3.1513929156687254e-05 0.0\n",
            "24 [D loss: 0.076389, acc.: 96.8872%] [G loss: 0.092316]\n",
            "0.0 0.0\n",
            "25 [D loss: 0.077361, acc.: 96.9238%] [G loss: 0.034900]\n",
            "0.0 0.0\n",
            "26 [D loss: 0.071189, acc.: 97.3877%] [G loss: 0.098603]\n",
            "0.0 0.0\n",
            "27 [D loss: 0.066711, acc.: 97.4243%] [G loss: 0.087456]\n",
            "0.0 0.0\n",
            "28 [D loss: 0.065847, acc.: 97.3633%] [G loss: 0.073073]\n",
            "0.0 0.0\n",
            "29 [D loss: 0.067496, acc.: 97.3389%] [G loss: 0.027704]\n",
            "0.0 0.0\n",
            "30 [D loss: 0.061485, acc.: 97.5952%] [G loss: 0.039722]\n",
            "0.0 0.0\n",
            "31 [D loss: 0.066796, acc.: 97.3999%] [G loss: 0.072307]\n",
            "0.0 0.0\n",
            "32 [D loss: 0.058804, acc.: 97.6196%] [G loss: 0.031491]\n",
            "0.0 0.0\n",
            "33 [D loss: 0.064286, acc.: 97.6562%] [G loss: 0.067181]\n",
            "0.0 0.0\n",
            "34 [D loss: 0.064522, acc.: 97.3267%] [G loss: 0.125120]\n",
            "0.0 0.0\n",
            "35 [D loss: 0.054557, acc.: 97.9980%] [G loss: 0.071283]\n",
            "0.0 0.0\n",
            "36 [D loss: 0.058968, acc.: 97.7051%] [G loss: 0.031300]\n",
            "0.0 0.0\n",
            "37 [D loss: 0.063018, acc.: 97.3511%] [G loss: 0.039955]\n",
            "0.0 0.0\n",
            "38 [D loss: 0.056795, acc.: 97.8516%] [G loss: 0.096807]\n",
            "0.0 0.0\n",
            "39 [D loss: 0.060988, acc.: 97.4854%] [G loss: 0.029287]\n",
            "0.0 0.0\n",
            "40 [D loss: 0.055855, acc.: 97.7539%] [G loss: 0.165997]\n",
            "0.0 0.0\n",
            "41 [D loss: 0.055759, acc.: 97.8271%] [G loss: 0.103519]\n",
            "0.0 0.0\n",
            "42 [D loss: 0.053702, acc.: 97.9492%] [G loss: 0.116672]\n",
            "0.0 0.0\n",
            "43 [D loss: 0.053752, acc.: 98.1445%] [G loss: 0.047905]\n",
            "0.0 0.0\n",
            "44 [D loss: 0.052777, acc.: 98.0347%] [G loss: 0.044149]\n",
            "0.0 0.0\n",
            "45 [D loss: 0.050683, acc.: 98.0591%] [G loss: 0.132007]\n",
            "0.0 0.0\n",
            "46 [D loss: 0.053424, acc.: 97.8271%] [G loss: 0.171882]\n",
            "0.0 0.0\n",
            "47 [D loss: 0.057020, acc.: 97.7783%] [G loss: 0.088482]\n",
            "0.0 0.0\n",
            "48 [D loss: 0.057221, acc.: 97.9370%] [G loss: 0.058840]\n",
            "0.0 0.0\n",
            "49 [D loss: 0.050301, acc.: 98.1812%] [G loss: 0.185855]\n",
            "0.0 0.0\n",
            "50 [D loss: 0.052965, acc.: 97.9126%] [G loss: 0.068747]\n",
            "0.0 0.0\n",
            "51 [D loss: 0.048455, acc.: 97.9736%] [G loss: 0.135651]\n",
            "0.0 0.0\n",
            "52 [D loss: 0.051748, acc.: 97.9614%] [G loss: 0.170210]\n",
            "0.0 0.0\n",
            "53 [D loss: 0.051301, acc.: 97.8882%] [G loss: 0.025904]\n",
            "0.0 0.0\n",
            "54 [D loss: 0.048352, acc.: 98.0591%] [G loss: 0.067087]\n",
            "0.0 0.0\n",
            "55 [D loss: 0.047325, acc.: 98.0347%] [G loss: 0.099300]\n",
            "0.0 0.0\n",
            "56 [D loss: 0.051213, acc.: 97.8882%] [G loss: 0.046911]\n",
            "0.0 0.0\n",
            "57 [D loss: 0.044481, acc.: 98.1934%] [G loss: 0.054182]\n",
            "0.0 0.0\n",
            "58 [D loss: 0.049739, acc.: 97.8638%] [G loss: 0.056739]\n",
            "0.0 0.0\n",
            "59 [D loss: 0.046435, acc.: 97.9248%] [G loss: 0.139179]\n",
            "0.0 0.0\n",
            "60 [D loss: 0.047285, acc.: 98.2422%] [G loss: 0.123686]\n",
            "0.0 0.0\n",
            "61 [D loss: 0.047053, acc.: 98.1934%] [G loss: 0.000003]\n",
            "0.0 0.0\n",
            "62 [D loss: 0.047769, acc.: 98.1079%] [G loss: 0.241544]\n",
            "0.0 0.0\n",
            "63 [D loss: 0.048003, acc.: 98.2422%] [G loss: 0.299073]\n",
            "0.0 0.0\n",
            "64 [D loss: 0.047221, acc.: 97.9370%] [G loss: 0.120092]\n",
            "0.0 0.0\n",
            "65 [D loss: 0.042445, acc.: 98.2544%] [G loss: 0.117733]\n",
            "0.0 0.0\n",
            "66 [D loss: 0.045064, acc.: 98.1201%] [G loss: 0.191614]\n",
            "0.0 0.0\n",
            "67 [D loss: 0.044776, acc.: 98.2788%] [G loss: 0.172182]\n",
            "0.0 0.0\n",
            "68 [D loss: 0.042996, acc.: 98.3032%] [G loss: 0.107215]\n",
            "0.0 0.0\n",
            "69 [D loss: 0.039876, acc.: 98.3521%] [G loss: 0.114904]\n",
            "0.0 0.0\n",
            "70 [D loss: 0.043221, acc.: 98.2056%] [G loss: 0.092612]\n",
            "0.0 0.0\n",
            "71 [D loss: 0.046706, acc.: 98.1445%] [G loss: 0.118603]\n",
            "0.0 0.0\n",
            "72 [D loss: 0.041996, acc.: 98.4863%] [G loss: 0.074080]\n",
            "0.0 0.0\n",
            "73 [D loss: 0.043046, acc.: 98.3276%] [G loss: 0.167206]\n",
            "0.0 0.0\n",
            "74 [D loss: 0.040391, acc.: 98.3887%] [G loss: 0.095156]\n",
            "0.0 0.0\n",
            "75 [D loss: 0.040540, acc.: 98.4985%] [G loss: 0.193280]\n",
            "0.0 0.0\n",
            "76 [D loss: 0.038566, acc.: 98.4741%] [G loss: 0.118593]\n",
            "0.0 0.0\n",
            "77 [D loss: 0.037570, acc.: 98.5474%] [G loss: 0.065613]\n",
            "0.0 0.0\n",
            "78 [D loss: 0.037161, acc.: 98.5107%] [G loss: 0.108058]\n",
            "0.0 0.0\n",
            "79 [D loss: 0.040484, acc.: 98.4131%] [G loss: 0.203579]\n",
            "0.0 0.0\n",
            "80 [D loss: 0.041171, acc.: 98.3765%] [G loss: 0.228730]\n",
            "0.0 0.0\n",
            "81 [D loss: 0.040128, acc.: 98.3765%] [G loss: 0.041223]\n",
            "0.0 0.0\n",
            "82 [D loss: 0.041136, acc.: 98.5718%] [G loss: 0.174856]\n",
            "0.0 0.0\n",
            "83 [D loss: 0.039389, acc.: 98.5718%] [G loss: 0.166989]\n",
            "0.0 0.0\n",
            "84 [D loss: 0.038575, acc.: 98.5352%] [G loss: 0.106923]\n",
            "0.0 0.0\n",
            "85 [D loss: 0.037377, acc.: 98.6450%] [G loss: 0.086294]\n",
            "0.0 0.0\n",
            "86 [D loss: 0.034954, acc.: 98.7183%] [G loss: 0.165281]\n",
            "0.0 0.0\n",
            "87 [D loss: 0.037467, acc.: 98.5718%] [G loss: 0.110219]\n",
            "0.0 0.0\n",
            "88 [D loss: 0.037080, acc.: 98.5352%] [G loss: 0.118976]\n",
            "0.0 0.0\n",
            "89 [D loss: 0.038258, acc.: 98.7305%] [G loss: 0.077531]\n",
            "0.0 0.0\n",
            "90 [D loss: 0.037968, acc.: 98.5229%] [G loss: 0.042460]\n",
            "0.0 0.0\n",
            "91 [D loss: 0.033897, acc.: 98.8403%] [G loss: 0.304210]\n",
            "0.0 0.0\n",
            "92 [D loss: 0.035310, acc.: 98.7427%] [G loss: 0.163924]\n",
            "0.0 0.0\n",
            "93 [D loss: 0.039952, acc.: 98.6450%] [G loss: 0.007782]\n",
            "0.0 0.0\n",
            "94 [D loss: 0.031956, acc.: 98.8159%] [G loss: 0.090611]\n",
            "0.0 0.0\n",
            "95 [D loss: 0.036290, acc.: 98.6328%] [G loss: 0.205423]\n",
            "0.0 0.0\n",
            "96 [D loss: 0.035237, acc.: 98.7671%] [G loss: 0.143849]\n",
            "0.0 0.0\n",
            "97 [D loss: 0.037712, acc.: 98.5474%] [G loss: 0.101308]\n",
            "0.0 0.0\n",
            "98 [D loss: 0.034838, acc.: 98.6450%] [G loss: 0.057862]\n",
            "0.0 0.0\n",
            "99 [D loss: 0.034399, acc.: 98.7427%] [G loss: 0.013320]\n",
            "0.0 0.0\n",
            "100 [D loss: 0.037414, acc.: 98.6206%] [G loss: 0.065429]\n",
            "0.0 0.0\n",
            "101 [D loss: 0.034260, acc.: 98.6816%] [G loss: 0.125660]\n",
            "0.0 0.0\n",
            "102 [D loss: 0.032454, acc.: 98.6816%] [G loss: 0.072084]\n",
            "0.0 0.0\n",
            "103 [D loss: 0.036941, acc.: 98.4619%] [G loss: 0.151404]\n",
            "0.0 0.0\n",
            "104 [D loss: 0.029150, acc.: 99.0234%] [G loss: 0.162977]\n",
            "0.0 0.0\n",
            "105 [D loss: 0.031846, acc.: 98.7549%] [G loss: 0.128742]\n",
            "0.0 0.0\n",
            "106 [D loss: 0.031262, acc.: 98.7793%] [G loss: 0.095091]\n",
            "0.0 0.0\n",
            "107 [D loss: 0.030552, acc.: 99.0234%] [G loss: 0.019572]\n",
            "0.0 0.0\n",
            "108 [D loss: 0.030688, acc.: 98.9502%] [G loss: 0.060274]\n",
            "0.0 0.0\n",
            "109 [D loss: 0.032254, acc.: 98.7549%] [G loss: 0.048548]\n",
            "0.0 0.0\n",
            "110 [D loss: 0.030259, acc.: 98.9380%] [G loss: 0.014734]\n",
            "0.0 0.0\n",
            "111 [D loss: 0.030819, acc.: 98.9136%] [G loss: 0.107524]\n",
            "0.0 0.0\n",
            "112 [D loss: 0.031778, acc.: 99.0112%] [G loss: 0.034340]\n",
            "0.0 0.0\n",
            "113 [D loss: 0.033260, acc.: 98.7549%] [G loss: 0.080713]\n",
            "0.0 0.0\n",
            "114 [D loss: 0.029055, acc.: 98.8770%] [G loss: 0.085484]\n",
            "0.0 0.0\n",
            "115 [D loss: 0.032940, acc.: 98.7549%] [G loss: 0.082172]\n",
            "0.0 0.0\n",
            "116 [D loss: 0.031938, acc.: 99.0112%] [G loss: 0.102193]\n",
            "0.0 0.0\n",
            "117 [D loss: 0.029183, acc.: 99.0234%] [G loss: 0.084690]\n",
            "0.0 0.0\n",
            "118 [D loss: 0.030555, acc.: 98.9868%] [G loss: 0.089501]\n",
            "0.0 0.0\n",
            "119 [D loss: 0.028666, acc.: 99.0479%] [G loss: 0.098039]\n",
            "0.0 0.0\n",
            "120 [D loss: 0.029044, acc.: 99.1089%] [G loss: 0.114582]\n",
            "0.0 0.0\n",
            "121 [D loss: 0.031739, acc.: 99.0845%] [G loss: 0.042858]\n",
            "0.0 0.0\n",
            "122 [D loss: 0.033097, acc.: 98.8525%] [G loss: 0.091719]\n",
            "0.0 0.0\n",
            "123 [D loss: 0.035378, acc.: 98.7305%] [G loss: 0.040317]\n",
            "0.0 0.0\n",
            "124 [D loss: 0.032065, acc.: 98.7915%] [G loss: 0.065835]\n",
            "0.0 0.0\n",
            "125 [D loss: 0.031639, acc.: 98.9136%] [G loss: 0.103629]\n",
            "0.0 0.0\n",
            "126 [D loss: 0.030074, acc.: 98.8403%] [G loss: 0.119910]\n",
            "0.0 0.0\n",
            "127 [D loss: 0.032837, acc.: 98.8403%] [G loss: 0.082575]\n",
            "0.0 0.0\n",
            "128 [D loss: 0.033976, acc.: 98.9380%] [G loss: 0.091392]\n",
            "0.0 0.0\n",
            "129 [D loss: 0.030039, acc.: 99.0356%] [G loss: 0.037402]\n",
            "0.0 0.0\n",
            "130 [D loss: 0.033703, acc.: 98.9868%] [G loss: 0.155689]\n",
            "0.0 0.0\n",
            "131 [D loss: 0.030479, acc.: 98.9624%] [G loss: 0.074426]\n",
            "0.0 0.0\n",
            "132 [D loss: 0.027928, acc.: 99.1577%] [G loss: 0.054950]\n",
            "0.0 0.0\n",
            "133 [D loss: 0.027999, acc.: 98.9624%] [G loss: 0.111474]\n",
            "0.0 0.0\n",
            "134 [D loss: 0.032858, acc.: 98.9990%] [G loss: 0.081548]\n",
            "0.0 0.0\n",
            "135 [D loss: 0.028781, acc.: 99.3042%] [G loss: 0.053947]\n",
            "0.0 0.0\n",
            "136 [D loss: 0.030184, acc.: 99.0479%] [G loss: 0.014317]\n",
            "0.0 0.0\n",
            "137 [D loss: 0.027703, acc.: 99.2065%] [G loss: 0.076948]\n",
            "0.0 0.0\n",
            "138 [D loss: 0.033026, acc.: 99.0601%] [G loss: 0.083092]\n",
            "0.0 0.0\n",
            "139 [D loss: 0.031579, acc.: 98.8159%] [G loss: 0.074297]\n",
            "0.0 0.0\n",
            "140 [D loss: 0.025627, acc.: 99.2920%] [G loss: 0.061187]\n",
            "0.0 0.0\n",
            "141 [D loss: 0.029408, acc.: 99.2310%] [G loss: 0.088949]\n",
            "0.0 0.0\n",
            "142 [D loss: 0.026823, acc.: 99.2676%] [G loss: 0.035638]\n",
            "0.0 0.0\n",
            "143 [D loss: 0.028891, acc.: 99.1455%] [G loss: 0.046638]\n",
            "0.0 0.0\n",
            "144 [D loss: 0.034046, acc.: 98.8281%] [G loss: 0.048018]\n",
            "0.0 0.0\n",
            "145 [D loss: 0.026433, acc.: 99.0967%] [G loss: 0.084820]\n",
            "0.0 0.0\n",
            "146 [D loss: 0.027268, acc.: 99.0723%] [G loss: 0.064280]\n",
            "0.0 0.0\n",
            "147 [D loss: 0.031946, acc.: 99.0356%] [G loss: 0.033259]\n",
            "0.0 0.0\n",
            "148 [D loss: 0.028935, acc.: 99.0356%] [G loss: 0.035493]\n",
            "0.0 0.0\n",
            "149 [D loss: 0.026723, acc.: 99.1821%] [G loss: 0.078556]\n",
            "0.0 0.0\n",
            "150 [D loss: 0.026841, acc.: 99.3164%] [G loss: 0.092996]\n",
            "0.0 0.0\n",
            "151 [D loss: 0.028172, acc.: 99.1333%] [G loss: 0.095163]\n",
            "0.0 0.0\n",
            "152 [D loss: 0.026530, acc.: 99.1089%] [G loss: 0.005317]\n",
            "0.0 0.0\n",
            "153 [D loss: 0.026960, acc.: 99.2065%] [G loss: 0.019262]\n",
            "0.0 0.0\n",
            "154 [D loss: 0.028075, acc.: 99.1821%] [G loss: 0.036254]\n",
            "0.0 0.0\n",
            "155 [D loss: 0.022892, acc.: 99.4141%] [G loss: 0.003181]\n",
            "0.0 0.0\n",
            "156 [D loss: 0.024175, acc.: 99.3530%] [G loss: 0.008997]\n",
            "0.0 0.0\n",
            "157 [D loss: 0.026243, acc.: 99.1089%] [G loss: 0.117098]\n",
            "0.0 0.0\n",
            "158 [D loss: 0.027586, acc.: 99.0845%] [G loss: 0.083483]\n",
            "0.0 0.0\n",
            "159 [D loss: 0.027065, acc.: 98.9868%] [G loss: 0.040528]\n",
            "0.0 0.0\n",
            "160 [D loss: 0.029688, acc.: 99.0479%] [G loss: 0.050560]\n",
            "0.0 0.0\n",
            "161 [D loss: 0.028612, acc.: 99.1333%] [G loss: 0.077121]\n",
            "0.0 0.0\n",
            "162 [D loss: 0.026646, acc.: 99.1333%] [G loss: 0.047320]\n",
            "0.0 0.0\n",
            "163 [D loss: 0.025067, acc.: 99.3042%] [G loss: 0.088925]\n",
            "0.0 0.0\n",
            "164 [D loss: 0.029617, acc.: 98.8159%] [G loss: 0.022105]\n",
            "0.0 0.0\n",
            "165 [D loss: 0.028036, acc.: 99.1943%] [G loss: 0.034310]\n",
            "0.0 0.0\n",
            "166 [D loss: 0.026923, acc.: 99.0356%] [G loss: 0.024336]\n",
            "0.0 0.0\n",
            "167 [D loss: 0.029031, acc.: 99.1455%] [G loss: 0.024768]\n",
            "0.0 0.0\n",
            "168 [D loss: 0.027159, acc.: 99.1577%] [G loss: 0.064952]\n",
            "0.0 0.0\n",
            "169 [D loss: 0.027255, acc.: 99.1821%] [G loss: 0.090807]\n",
            "0.0 0.0\n",
            "170 [D loss: 0.030049, acc.: 99.0845%] [G loss: 0.040365]\n",
            "0.0 0.0\n",
            "171 [D loss: 0.022490, acc.: 99.4385%] [G loss: 0.080981]\n",
            "0.0 0.0\n",
            "172 [D loss: 0.025875, acc.: 99.1577%] [G loss: 0.162868]\n",
            "0.0 0.0\n",
            "173 [D loss: 0.023590, acc.: 99.1455%] [G loss: 0.127935]\n",
            "0.0 0.0\n",
            "174 [D loss: 0.025014, acc.: 99.2798%] [G loss: 0.090586]\n",
            "0.0 0.0\n",
            "175 [D loss: 0.026138, acc.: 99.2798%] [G loss: 0.070436]\n",
            "0.0 0.0\n",
            "176 [D loss: 0.025650, acc.: 99.1821%] [G loss: 0.088563]\n",
            "0.0 0.0\n",
            "177 [D loss: 0.026420, acc.: 99.2065%] [G loss: 0.097679]\n",
            "0.0 0.0\n",
            "178 [D loss: 0.025292, acc.: 99.3286%] [G loss: 0.128074]\n",
            "0.0 0.0\n",
            "179 [D loss: 0.026456, acc.: 99.1699%] [G loss: 0.029988]\n",
            "0.0 0.0\n",
            "180 [D loss: 0.024414, acc.: 99.1943%] [G loss: 0.034576]\n",
            "0.0 0.0\n",
            "181 [D loss: 0.023298, acc.: 99.3408%] [G loss: 0.013978]\n",
            "0.0 0.0\n",
            "182 [D loss: 0.023781, acc.: 99.2798%] [G loss: 0.041755]\n",
            "0.0 0.0\n",
            "183 [D loss: 0.025624, acc.: 99.4141%] [G loss: 0.129848]\n",
            "0.0 0.0\n",
            "184 [D loss: 0.025737, acc.: 99.1577%] [G loss: 0.024053]\n",
            "0.0 0.0\n",
            "185 [D loss: 0.028166, acc.: 99.1333%] [G loss: 0.000000]\n",
            "0.0 0.0\n",
            "186 [D loss: 0.026995, acc.: 99.1211%] [G loss: 0.074260]\n",
            "0.0 0.0\n",
            "187 [D loss: 0.023885, acc.: 99.3286%] [G loss: 0.170570]\n",
            "0.0 0.0\n",
            "188 [D loss: 0.023302, acc.: 99.1577%] [G loss: 0.051658]\n",
            "0.0 0.0\n",
            "189 [D loss: 0.024216, acc.: 99.4019%] [G loss: 0.037028]\n",
            "0.0 0.0\n",
            "190 [D loss: 0.024345, acc.: 99.2676%] [G loss: 0.112639]\n",
            "0.0 0.0\n",
            "191 [D loss: 0.026785, acc.: 99.2310%] [G loss: 0.027244]\n",
            "0.0 0.0\n",
            "192 [D loss: 0.024190, acc.: 99.3164%] [G loss: 0.070351]\n",
            "0.0 0.0\n",
            "193 [D loss: 0.025934, acc.: 99.0356%] [G loss: 0.029544]\n",
            "0.0 0.0\n",
            "194 [D loss: 0.021980, acc.: 99.3408%] [G loss: 0.049397]\n",
            "0.0 0.0\n",
            "195 [D loss: 0.028097, acc.: 99.1821%] [G loss: 0.046088]\n",
            "0.0 0.0\n",
            "196 [D loss: 0.027747, acc.: 99.0112%] [G loss: 0.030181]\n",
            "0.0 0.0\n",
            "197 [D loss: 0.025605, acc.: 99.2310%] [G loss: 0.092003]\n",
            "0.0 0.0\n",
            "198 [D loss: 0.025687, acc.: 99.3652%] [G loss: 0.033533]\n",
            "0.0 0.0\n",
            "199 [D loss: 0.024919, acc.: 99.3408%] [G loss: 0.065417]\n",
            "0.0 0.0\n",
            "200 [D loss: 0.026095, acc.: 99.1699%] [G loss: 0.001083]\n",
            "0.0 0.0\n",
            "201 [D loss: 0.024767, acc.: 99.2798%] [G loss: 0.077541]\n",
            "0.0 0.0\n",
            "202 [D loss: 0.025973, acc.: 99.1943%] [G loss: 0.046421]\n",
            "0.0 0.0\n",
            "203 [D loss: 0.025803, acc.: 99.2432%] [G loss: 0.107468]\n",
            "0.0 0.0\n",
            "204 [D loss: 0.024024, acc.: 99.2188%] [G loss: 0.111588]\n",
            "0.0 0.0\n",
            "205 [D loss: 0.022553, acc.: 99.1699%] [G loss: 0.027786]\n",
            "0.0 0.0\n",
            "206 [D loss: 0.029436, acc.: 99.1089%] [G loss: 0.013601]\n",
            "0.0 0.0\n",
            "207 [D loss: 0.024402, acc.: 99.2310%] [G loss: 0.043374]\n",
            "0.0 0.0\n",
            "208 [D loss: 0.028566, acc.: 99.1943%] [G loss: 0.037334]\n",
            "0.0 0.0\n",
            "209 [D loss: 0.024852, acc.: 99.1211%] [G loss: 0.061768]\n",
            "0.0 0.0\n",
            "210 [D loss: 0.023688, acc.: 99.3774%] [G loss: 0.034904]\n",
            "0.0 0.0\n",
            "211 [D loss: 0.024310, acc.: 99.2310%] [G loss: 0.103059]\n",
            "0.0 0.0\n",
            "212 [D loss: 0.022651, acc.: 99.3164%] [G loss: 0.060982]\n",
            "0.0 0.0\n",
            "213 [D loss: 0.025014, acc.: 99.3164%] [G loss: 0.005829]\n",
            "0.0 0.0\n",
            "214 [D loss: 0.025767, acc.: 99.2798%] [G loss: 0.040987]\n",
            "0.0 0.0\n",
            "215 [D loss: 0.026716, acc.: 99.0723%] [G loss: 0.117571]\n",
            "0.0 0.0\n",
            "216 [D loss: 0.027873, acc.: 99.2065%] [G loss: 0.083254]\n",
            "0.0 0.0\n",
            "217 [D loss: 0.021368, acc.: 99.4263%] [G loss: 0.054018]\n",
            "0.0 0.0\n",
            "218 [D loss: 0.024889, acc.: 99.4019%] [G loss: 0.027614]\n",
            "0.0 0.0\n",
            "219 [D loss: 0.022672, acc.: 99.3408%] [G loss: 0.009856]\n",
            "0.0 0.0\n",
            "220 [D loss: 0.028195, acc.: 99.2798%] [G loss: 0.027343]\n",
            "0.0 0.0\n",
            "221 [D loss: 0.024466, acc.: 99.2920%] [G loss: 0.051647]\n",
            "0.0 0.0\n",
            "222 [D loss: 0.029582, acc.: 99.0234%] [G loss: 0.153350]\n",
            "0.0 0.0\n",
            "223 [D loss: 0.027423, acc.: 99.0845%] [G loss: 0.054975]\n",
            "0.0 0.0\n",
            "224 [D loss: 0.025365, acc.: 99.2310%] [G loss: 0.054692]\n",
            "0.0 0.0\n",
            "225 [D loss: 0.022605, acc.: 99.2920%] [G loss: 0.051949]\n",
            "0.0 0.0\n",
            "226 [D loss: 0.029779, acc.: 99.3530%] [G loss: 0.022806]\n",
            "0.0 0.0\n",
            "227 [D loss: 0.028458, acc.: 99.2065%] [G loss: 0.004962]\n",
            "0.0 0.0\n",
            "228 [D loss: 0.025461, acc.: 99.1211%] [G loss: 0.033357]\n",
            "0.0 0.0\n",
            "229 [D loss: 0.025286, acc.: 99.4385%] [G loss: 0.022129]\n",
            "0.0 0.0\n",
            "230 [D loss: 0.030611, acc.: 99.1089%] [G loss: 0.033229]\n",
            "0.0 0.0\n",
            "231 [D loss: 0.029346, acc.: 99.1699%] [G loss: 0.037377]\n",
            "0.0 0.0\n",
            "232 [D loss: 0.028587, acc.: 99.0845%] [G loss: 0.069593]\n",
            "0.0 0.0\n",
            "233 [D loss: 0.035393, acc.: 99.0112%] [G loss: 0.027518]\n",
            "0.0 0.0\n",
            "234 [D loss: 0.031537, acc.: 99.1943%] [G loss: 0.047068]\n",
            "0.0 0.0\n",
            "235 [D loss: 0.034719, acc.: 99.1089%] [G loss: 0.007666]\n",
            "0.0 0.0\n",
            "236 [D loss: 0.033555, acc.: 98.9746%] [G loss: 0.025460]\n",
            "0.0 0.0\n",
            "237 [D loss: 0.033790, acc.: 98.9868%] [G loss: 0.050950]\n",
            "0.0 0.0\n",
            "238 [D loss: 0.032728, acc.: 99.1943%] [G loss: 0.021148]\n",
            "0.0 0.0\n",
            "239 [D loss: 0.028637, acc.: 99.1943%] [G loss: 0.082727]\n",
            "0.0 0.0\n",
            "240 [D loss: 0.027319, acc.: 99.0845%] [G loss: 0.031155]\n",
            "0.0 0.0\n",
            "241 [D loss: 0.028648, acc.: 99.1333%] [G loss: 0.113313]\n",
            "0.0 0.0\n",
            "242 [D loss: 0.026733, acc.: 99.2065%] [G loss: 0.101868]\n",
            "0.0 0.0\n",
            "243 [D loss: 0.030853, acc.: 99.0967%] [G loss: 0.076097]\n",
            "0.0 0.0\n",
            "244 [D loss: 0.026385, acc.: 99.2065%] [G loss: 0.085701]\n",
            "0.0 0.0\n",
            "245 [D loss: 0.025877, acc.: 99.1943%] [G loss: 0.082194]\n",
            "0.0 0.0\n",
            "246 [D loss: 0.032560, acc.: 98.9624%] [G loss: 0.100275]\n",
            "0.0 0.0\n",
            "247 [D loss: 0.033440, acc.: 98.9136%] [G loss: 0.033402]\n",
            "0.0 0.0\n",
            "248 [D loss: 0.023010, acc.: 99.3896%] [G loss: 0.005709]\n",
            "0.0 0.0\n",
            "249 [D loss: 0.027684, acc.: 99.2798%] [G loss: 0.073420]\n",
            "0.0 0.0\n",
            "250 [D loss: 0.028688, acc.: 99.1211%] [G loss: 0.042123]\n",
            "0.0 0.0\n",
            "251 [D loss: 0.032733, acc.: 99.0234%] [G loss: 0.002680]\n",
            "0.0 0.0\n",
            "252 [D loss: 0.032101, acc.: 99.0112%] [G loss: 0.063152]\n",
            "0.0 0.0\n",
            "253 [D loss: 0.026157, acc.: 99.2188%] [G loss: 0.078473]\n",
            "0.0 0.0\n",
            "254 [D loss: 0.034672, acc.: 99.0356%] [G loss: 0.099556]\n",
            "0.0 0.0\n",
            "255 [D loss: 0.028182, acc.: 99.0234%] [G loss: 0.080380]\n",
            "0.0 0.0\n",
            "256 [D loss: 0.025851, acc.: 99.1333%] [G loss: 0.065701]\n",
            "0.0 0.0\n",
            "257 [D loss: 0.025272, acc.: 99.3286%] [G loss: 0.020222]\n",
            "0.0 0.0\n",
            "258 [D loss: 0.039899, acc.: 98.9014%] [G loss: 0.069427]\n",
            "0.0 0.0\n",
            "259 [D loss: 0.028222, acc.: 99.1943%] [G loss: 0.059753]\n",
            "0.0 0.0\n",
            "260 [D loss: 0.030981, acc.: 99.0967%] [G loss: 0.039802]\n",
            "0.0 0.0\n",
            "261 [D loss: 0.032616, acc.: 99.1211%] [G loss: 0.057497]\n",
            "0.0 0.0\n",
            "262 [D loss: 0.028170, acc.: 99.1943%] [G loss: 0.097004]\n",
            "0.0 0.0\n",
            "263 [D loss: 0.028390, acc.: 99.1455%] [G loss: 0.014384]\n",
            "0.0 0.0\n",
            "264 [D loss: 0.025635, acc.: 99.4263%] [G loss: 0.079240]\n",
            "0.0 0.0\n",
            "265 [D loss: 0.025964, acc.: 99.2188%] [G loss: 0.097902]\n",
            "0.0 0.0\n",
            "266 [D loss: 0.020150, acc.: 99.3530%] [G loss: 0.049369]\n",
            "0.0 0.0\n",
            "267 [D loss: 0.029349, acc.: 99.0845%] [G loss: 0.040567]\n",
            "0.0 0.0\n",
            "268 [D loss: 0.031191, acc.: 98.9746%] [G loss: 0.032899]\n",
            "0.0 0.0\n",
            "269 [D loss: 0.027403, acc.: 99.1089%] [G loss: 0.093226]\n",
            "0.0 0.0\n",
            "270 [D loss: 0.024889, acc.: 99.1333%] [G loss: 0.013126]\n",
            "0.0 0.0\n",
            "271 [D loss: 0.024167, acc.: 99.3530%] [G loss: 0.099862]\n",
            "0.0 0.0\n",
            "272 [D loss: 0.024307, acc.: 99.2920%] [G loss: 0.081660]\n",
            "0.0 0.0\n",
            "273 [D loss: 0.025326, acc.: 99.1821%] [G loss: 0.032012]\n",
            "0.0 0.0\n",
            "274 [D loss: 0.026162, acc.: 99.2798%] [G loss: 0.017049]\n",
            "0.0 0.0\n",
            "275 [D loss: 0.028757, acc.: 99.2432%] [G loss: 0.011525]\n",
            "0.0 0.0\n",
            "276 [D loss: 0.028648, acc.: 99.0601%] [G loss: 0.089559]\n",
            "0.0 0.0\n",
            "277 [D loss: 0.028440, acc.: 99.2065%] [G loss: 0.072477]\n",
            "0.0 0.0\n",
            "278 [D loss: 0.024723, acc.: 99.2065%] [G loss: 0.071705]\n",
            "0.0 0.0\n",
            "279 [D loss: 0.025651, acc.: 99.3042%] [G loss: 0.052483]\n",
            "0.0 0.0\n",
            "280 [D loss: 0.027825, acc.: 99.2676%] [G loss: 0.050171]\n",
            "0.0 0.0\n",
            "281 [D loss: 0.024687, acc.: 99.2798%] [G loss: 0.013021]\n",
            "0.0 0.0\n",
            "282 [D loss: 0.031398, acc.: 99.0356%] [G loss: 0.062225]\n",
            "0.0 0.0\n",
            "283 [D loss: 0.026118, acc.: 99.1943%] [G loss: 0.073617]\n",
            "0.0 0.0\n",
            "284 [D loss: 0.023327, acc.: 99.2188%] [G loss: 0.042512]\n",
            "0.0 0.0\n",
            "285 [D loss: 0.023984, acc.: 99.2676%] [G loss: 0.068092]\n",
            "0.0 0.0\n",
            "286 [D loss: 0.027346, acc.: 99.0967%] [G loss: 0.107626]\n",
            "0.0 0.0\n",
            "287 [D loss: 0.024690, acc.: 99.2554%] [G loss: 0.045051]\n",
            "0.0 0.0\n",
            "288 [D loss: 0.026268, acc.: 99.0234%] [G loss: 0.032847]\n",
            "0.0 0.0\n",
            "289 [D loss: 0.025982, acc.: 99.1577%] [G loss: 0.013609]\n",
            "0.0 0.0\n",
            "290 [D loss: 0.025114, acc.: 99.2432%] [G loss: 0.028655]\n",
            "0.0 0.0\n",
            "291 [D loss: 0.023096, acc.: 99.3408%] [G loss: 0.034714]\n",
            "0.0 0.0\n",
            "292 [D loss: 0.027993, acc.: 99.1699%] [G loss: 0.077433]\n",
            "0.0 0.0\n",
            "293 [D loss: 0.029655, acc.: 99.1089%] [G loss: 0.000000]\n",
            "0.0 0.0\n",
            "294 [D loss: 0.023070, acc.: 99.2676%] [G loss: 0.063455]\n",
            "0.0 0.0\n",
            "295 [D loss: 0.026391, acc.: 99.1577%] [G loss: 0.024879]\n",
            "0.0 0.0\n",
            "296 [D loss: 0.026140, acc.: 99.2188%] [G loss: 0.118067]\n",
            "0.0 0.0\n",
            "297 [D loss: 0.024841, acc.: 99.0967%] [G loss: 0.058408]\n",
            "0.0 0.0\n",
            "298 [D loss: 0.028509, acc.: 99.1577%] [G loss: 0.040091]\n",
            "0.0 0.0\n",
            "299 [D loss: 0.025096, acc.: 99.4751%] [G loss: 0.014340]\n",
            "0.0 0.0\n",
            "300 [D loss: 0.022351, acc.: 99.3042%] [G loss: 0.106250]\n",
            "0.0 0.0\n",
            "301 [D loss: 0.026916, acc.: 99.1699%] [G loss: 0.114605]\n",
            "0.0 0.0\n",
            "302 [D loss: 0.023649, acc.: 99.3774%] [G loss: 0.056553]\n",
            "0.0 0.0\n",
            "303 [D loss: 0.039629, acc.: 98.9868%] [G loss: 0.106740]\n",
            "0.0 0.0\n",
            "304 [D loss: 0.031067, acc.: 98.9624%] [G loss: 0.053838]\n",
            "0.0 0.0\n",
            "305 [D loss: 0.031549, acc.: 98.9258%] [G loss: 0.055680]\n",
            "0.0 0.0\n",
            "306 [D loss: 0.034601, acc.: 99.1333%] [G loss: 0.101433]\n",
            "0.0 0.0\n",
            "307 [D loss: 0.033131, acc.: 98.8770%] [G loss: 0.029924]\n",
            "0.0 0.0\n",
            "308 [D loss: 0.044081, acc.: 99.1333%] [G loss: 0.084584]\n",
            "0.0 0.0\n",
            "309 [D loss: 0.034585, acc.: 99.1211%] [G loss: 0.039442]\n",
            "0.0 0.0\n",
            "310 [D loss: 0.044322, acc.: 99.0479%] [G loss: 0.030229]\n",
            "0.0 0.0\n",
            "311 [D loss: 0.045081, acc.: 99.0845%] [G loss: 0.201805]\n",
            "0.0 0.0\n",
            "312 [D loss: 0.034722, acc.: 99.0845%] [G loss: 0.117067]\n",
            "0.0 0.0\n",
            "313 [D loss: 0.037246, acc.: 98.9746%] [G loss: 0.111098]\n",
            "0.0 0.0\n",
            "314 [D loss: 0.044693, acc.: 98.9014%] [G loss: 0.198322]\n",
            "0.0 0.0\n",
            "315 [D loss: 0.044542, acc.: 98.8892%] [G loss: 0.155028]\n",
            "0.0 0.0\n",
            "316 [D loss: 0.046960, acc.: 98.9746%] [G loss: 0.125840]\n",
            "0.0 0.0\n",
            "317 [D loss: 0.049659, acc.: 98.9624%] [G loss: 0.183816]\n",
            "0.0 0.0\n",
            "318 [D loss: 0.038989, acc.: 98.9014%] [G loss: 0.024237]\n",
            "0.0 0.0\n",
            "319 [D loss: 0.035414, acc.: 99.0479%] [G loss: 0.056163]\n",
            "0.0 0.0\n",
            "320 [D loss: 0.039418, acc.: 98.8159%] [G loss: 0.225126]\n",
            "0.0 0.0\n",
            "321 [D loss: 0.041470, acc.: 99.0479%] [G loss: 0.149653]\n",
            "0.0 0.0\n",
            "322 [D loss: 0.043347, acc.: 98.9380%] [G loss: 0.038196]\n",
            "0.0 0.0\n",
            "323 [D loss: 0.036580, acc.: 98.9868%] [G loss: 0.183792]\n",
            "0.0 0.0\n",
            "324 [D loss: 0.044221, acc.: 99.0112%] [G loss: 0.091087]\n",
            "0.0 0.0\n",
            "325 [D loss: 0.048079, acc.: 98.6694%] [G loss: 0.073266]\n",
            "0.0 0.0\n",
            "326 [D loss: 0.039773, acc.: 98.9990%] [G loss: 0.218684]\n",
            "0.0 0.0\n",
            "327 [D loss: 0.035980, acc.: 99.0356%] [G loss: 0.236318]\n",
            "0.0 0.0\n",
            "328 [D loss: 0.038149, acc.: 99.1455%] [G loss: 0.124035]\n",
            "0.0 0.0\n",
            "329 [D loss: 0.035956, acc.: 98.9746%] [G loss: 0.215373]\n",
            "0.0 0.0\n",
            "330 [D loss: 0.030796, acc.: 99.2065%] [G loss: 0.120405]\n",
            "0.0 0.0\n",
            "331 [D loss: 0.034687, acc.: 99.0967%] [G loss: 0.061960]\n",
            "0.0 0.0\n",
            "332 [D loss: 0.034920, acc.: 99.2432%] [G loss: 0.139928]\n",
            "0.0 0.0\n",
            "333 [D loss: 0.033122, acc.: 98.9258%] [G loss: 0.033964]\n",
            "0.0 0.0\n",
            "334 [D loss: 0.027298, acc.: 99.1211%] [G loss: 0.045387]\n",
            "0.0 0.0\n",
            "335 [D loss: 0.042240, acc.: 98.8770%] [G loss: 0.036154]\n",
            "0.0 0.0\n",
            "336 [D loss: 0.045885, acc.: 98.9136%] [G loss: 0.045201]\n",
            "0.0 0.0\n",
            "337 [D loss: 0.048089, acc.: 98.7915%] [G loss: 0.006840]\n",
            "0.0 0.0\n",
            "338 [D loss: 0.035707, acc.: 99.1333%] [G loss: 0.023602]\n",
            "0.0 0.0\n",
            "339 [D loss: 0.035479, acc.: 98.8403%] [G loss: 0.089376]\n",
            "0.0 0.0\n",
            "340 [D loss: 0.030804, acc.: 99.1943%] [G loss: 0.046944]\n",
            "0.0 0.0\n",
            "341 [D loss: 0.042180, acc.: 98.9380%] [G loss: 0.063311]\n",
            "0.0 0.0\n",
            "342 [D loss: 0.041568, acc.: 98.7183%] [G loss: 0.047427]\n",
            "0.0 0.0\n",
            "343 [D loss: 0.044514, acc.: 98.6816%] [G loss: 0.080359]\n",
            "0.0 0.0\n",
            "344 [D loss: 0.040902, acc.: 98.8037%] [G loss: 0.095153]\n",
            "0.0 0.0\n",
            "345 [D loss: 0.040221, acc.: 98.9624%] [G loss: 0.114573]\n",
            "0.0 0.0\n",
            "346 [D loss: 0.035183, acc.: 98.9990%] [G loss: 0.030124]\n",
            "0.0 0.0\n",
            "347 [D loss: 0.039422, acc.: 98.9746%] [G loss: 0.047963]\n",
            "0.0 0.0\n",
            "348 [D loss: 0.036182, acc.: 99.0723%] [G loss: 0.020672]\n",
            "0.0 0.0\n",
            "349 [D loss: 0.038572, acc.: 99.0356%] [G loss: 0.064913]\n",
            "0.0 0.0\n",
            "350 [D loss: 0.043309, acc.: 98.5962%] [G loss: 0.070029]\n",
            "0.0 0.0\n",
            "351 [D loss: 0.035421, acc.: 99.1577%] [G loss: 0.170355]\n",
            "0.0 0.0\n",
            "352 [D loss: 0.032945, acc.: 98.9502%] [G loss: 0.027104]\n",
            "0.0 0.0\n",
            "353 [D loss: 0.034252, acc.: 99.0479%] [G loss: 0.077922]\n",
            "0.0 0.0\n",
            "354 [D loss: 0.035404, acc.: 99.0601%] [G loss: 0.065111]\n",
            "0.0 0.0\n",
            "355 [D loss: 0.029260, acc.: 99.0967%] [G loss: 0.091902]\n",
            "0.0 0.0\n",
            "356 [D loss: 0.034697, acc.: 99.1455%] [G loss: 0.089130]\n",
            "3.1513929156687254e-05 0.0\n",
            "357 [D loss: 0.046540, acc.: 98.8525%] [G loss: 0.124364]\n",
            "0.0 0.0\n",
            "358 [D loss: 0.045780, acc.: 98.9258%] [G loss: 0.115610]\n",
            "0.0 0.0\n",
            "359 [D loss: 0.046506, acc.: 99.0356%] [G loss: 0.090552]\n",
            "0.0 0.0\n",
            "360 [D loss: 0.045796, acc.: 99.0234%] [G loss: 0.147497]\n",
            "0.0 0.0\n",
            "361 [D loss: 0.048842, acc.: 98.9258%] [G loss: 0.090136]\n",
            "0.0 0.0\n",
            "362 [D loss: 0.042407, acc.: 98.8770%] [G loss: 0.080471]\n",
            "0.0 0.0\n",
            "363 [D loss: 0.039727, acc.: 99.1211%] [G loss: 0.091061]\n",
            "0.0 0.0\n",
            "364 [D loss: 0.043402, acc.: 98.9014%] [G loss: 0.080420]\n",
            "0.0 0.0\n",
            "365 [D loss: 0.034646, acc.: 99.0234%] [G loss: 0.073506]\n",
            "0.0 0.0\n",
            "366 [D loss: 0.036421, acc.: 99.0479%] [G loss: 0.085571]\n",
            "0.0 0.0\n",
            "367 [D loss: 0.035878, acc.: 99.1211%] [G loss: 0.068075]\n",
            "0.0 0.0\n",
            "368 [D loss: 0.038578, acc.: 98.9136%] [G loss: 0.075810]\n",
            "0.0 0.0\n",
            "369 [D loss: 0.035567, acc.: 99.0845%] [G loss: 0.000559]\n",
            "0.0 0.0\n",
            "370 [D loss: 0.032256, acc.: 99.2065%] [G loss: 0.015469]\n",
            "0.0 0.0\n",
            "371 [D loss: 0.036994, acc.: 99.0723%] [G loss: 0.014857]\n",
            "0.0 0.0\n",
            "372 [D loss: 0.035289, acc.: 98.9624%] [G loss: 0.168166]\n",
            "0.0 0.0\n",
            "373 [D loss: 0.033385, acc.: 99.0356%] [G loss: 0.016010]\n",
            "0.0 0.0\n",
            "374 [D loss: 0.034575, acc.: 98.8892%] [G loss: 0.051183]\n",
            "0.0 0.0\n",
            "375 [D loss: 0.034788, acc.: 98.9746%] [G loss: 0.016290]\n",
            "0.0 0.0\n",
            "376 [D loss: 0.036423, acc.: 99.0601%] [G loss: 0.037713]\n",
            "0.0 0.0\n",
            "377 [D loss: 0.032272, acc.: 99.1943%] [G loss: 0.074884]\n",
            "0.0 0.0\n",
            "378 [D loss: 0.031699, acc.: 99.0234%] [G loss: 0.017400]\n",
            "0.0 0.0\n",
            "379 [D loss: 0.029943, acc.: 99.1211%] [G loss: 0.171514]\n",
            "0.0 0.0\n",
            "380 [D loss: 0.035902, acc.: 98.7671%] [G loss: 0.073368]\n",
            "0.0 0.0\n",
            "381 [D loss: 0.038366, acc.: 98.9014%] [G loss: 0.072972]\n",
            "0.0 0.0\n",
            "382 [D loss: 0.031386, acc.: 98.9624%] [G loss: 0.093098]\n",
            "0.0 0.0\n",
            "383 [D loss: 0.032421, acc.: 98.8892%] [G loss: 0.097431]\n",
            "0.0 0.0\n",
            "384 [D loss: 0.029131, acc.: 99.1089%] [G loss: 0.068086]\n",
            "0.0 0.0\n",
            "385 [D loss: 0.032849, acc.: 98.9502%] [G loss: 0.015928]\n",
            "0.0 0.0\n",
            "386 [D loss: 0.034915, acc.: 99.0479%] [G loss: 0.057921]\n",
            "0.0 0.0\n",
            "387 [D loss: 0.031347, acc.: 99.0356%] [G loss: 0.099762]\n",
            "0.0 0.0\n",
            "388 [D loss: 0.034671, acc.: 98.9502%] [G loss: 0.060295]\n",
            "0.0 0.0\n",
            "389 [D loss: 0.034709, acc.: 98.9380%] [G loss: 0.049796]\n",
            "0.0 0.0\n",
            "390 [D loss: 0.035534, acc.: 98.8403%] [G loss: 0.093193]\n",
            "0.0 0.0\n",
            "391 [D loss: 0.035444, acc.: 99.1821%] [G loss: 0.011752]\n",
            "0.0 0.0\n",
            "392 [D loss: 0.037164, acc.: 98.9868%] [G loss: 0.077461]\n",
            "0.0 0.0\n",
            "393 [D loss: 0.039866, acc.: 98.8647%] [G loss: 0.087235]\n",
            "0.0 0.0\n",
            "394 [D loss: 0.027309, acc.: 99.3286%] [G loss: 0.147219]\n",
            "0.0 0.0\n",
            "395 [D loss: 0.029593, acc.: 99.1577%] [G loss: 0.073041]\n",
            "0.0 0.0\n",
            "396 [D loss: 0.027935, acc.: 99.0967%] [G loss: 0.056672]\n",
            "0.0 0.0\n",
            "397 [D loss: 0.038288, acc.: 98.9380%] [G loss: 0.208009]\n",
            "0.0 0.0\n",
            "398 [D loss: 0.035495, acc.: 99.1577%] [G loss: 0.122718]\n",
            "0.0 0.0\n",
            "399 [D loss: 0.033140, acc.: 99.1699%] [G loss: 0.077837]\n",
            "0.0 0.0\n",
            "400 [D loss: 0.037280, acc.: 99.0723%] [G loss: 0.023005]\n",
            "0.0 0.0\n",
            "401 [D loss: 0.033699, acc.: 99.1333%] [G loss: 0.180044]\n",
            "0.0 0.0\n",
            "402 [D loss: 0.029703, acc.: 99.1333%] [G loss: 0.059677]\n",
            "0.0 0.0\n",
            "403 [D loss: 0.032144, acc.: 99.1821%] [G loss: 0.195623]\n",
            "0.0 0.0\n",
            "404 [D loss: 0.037572, acc.: 98.9746%] [G loss: 0.084786]\n",
            "0.0 0.0\n",
            "405 [D loss: 0.031296, acc.: 99.2065%] [G loss: 0.030815]\n",
            "0.0 0.0\n",
            "406 [D loss: 0.033347, acc.: 99.1089%] [G loss: 0.271704]\n",
            "0.0 0.0\n",
            "407 [D loss: 0.029808, acc.: 99.1943%] [G loss: 0.107765]\n",
            "0.0 0.0\n",
            "408 [D loss: 0.030200, acc.: 99.1821%] [G loss: 0.065834]\n",
            "0.0 0.0\n",
            "409 [D loss: 0.032464, acc.: 99.1089%] [G loss: 0.092263]\n",
            "0.0 0.0\n",
            "410 [D loss: 0.025939, acc.: 99.0845%] [G loss: 0.087190]\n",
            "0.0 0.0\n",
            "411 [D loss: 0.030848, acc.: 98.8403%] [G loss: 0.055422]\n",
            "0.0 0.0\n",
            "412 [D loss: 0.029384, acc.: 99.0845%] [G loss: 0.172852]\n",
            "0.0 0.0\n",
            "413 [D loss: 0.030397, acc.: 99.2065%] [G loss: 0.087311]\n",
            "0.0 0.0\n",
            "414 [D loss: 0.030903, acc.: 98.9868%] [G loss: 0.057410]\n",
            "0.0 0.0\n",
            "415 [D loss: 0.032713, acc.: 98.9990%] [G loss: 0.093722]\n",
            "0.0 0.0\n",
            "416 [D loss: 0.027478, acc.: 99.1333%] [G loss: 0.058003]\n",
            "0.0 0.0\n",
            "417 [D loss: 0.034486, acc.: 99.1089%] [G loss: 0.098785]\n",
            "0.0 0.0\n",
            "418 [D loss: 0.026089, acc.: 99.1821%] [G loss: 0.089307]\n",
            "0.0 0.0\n",
            "419 [D loss: 0.032956, acc.: 99.1577%] [G loss: 0.100874]\n",
            "0.0 0.0\n",
            "420 [D loss: 0.032650, acc.: 99.0112%] [G loss: 0.107600]\n",
            "0.0 0.0\n",
            "421 [D loss: 0.034442, acc.: 99.1821%] [G loss: 0.121103]\n",
            "0.0 0.0\n",
            "422 [D loss: 0.026100, acc.: 99.2065%] [G loss: 0.081555]\n",
            "0.0 0.0\n",
            "423 [D loss: 0.032682, acc.: 99.0967%] [G loss: 0.279700]\n",
            "0.0 0.0\n",
            "424 [D loss: 0.030926, acc.: 99.1333%] [G loss: 0.221558]\n",
            "0.0 0.0\n",
            "425 [D loss: 0.028299, acc.: 99.1577%] [G loss: 0.088992]\n",
            "0.0 0.0\n",
            "426 [D loss: 0.029183, acc.: 98.9014%] [G loss: 0.307569]\n",
            "0.0 0.0\n",
            "427 [D loss: 0.030515, acc.: 99.2188%] [G loss: 0.045560]\n",
            "0.0 0.0\n",
            "428 [D loss: 0.026048, acc.: 99.1455%] [G loss: 0.104635]\n",
            "0.0 0.0\n",
            "429 [D loss: 0.032931, acc.: 99.0112%] [G loss: 0.023828]\n",
            "0.0 0.0\n",
            "430 [D loss: 0.031902, acc.: 99.0723%] [G loss: 0.158600]\n",
            "0.0 0.0\n",
            "431 [D loss: 0.027471, acc.: 99.2188%] [G loss: 0.018072]\n",
            "0.0 0.0\n",
            "432 [D loss: 0.027827, acc.: 99.2065%] [G loss: 0.022048]\n",
            "0.0 0.0\n",
            "433 [D loss: 0.027234, acc.: 99.0112%] [G loss: 0.090528]\n",
            "0.0 0.0\n",
            "434 [D loss: 0.032745, acc.: 98.9868%] [G loss: 0.022396]\n",
            "0.0 0.0\n",
            "435 [D loss: 0.029046, acc.: 98.9990%] [G loss: 0.001751]\n",
            "0.0 0.0\n",
            "436 [D loss: 0.029585, acc.: 98.9746%] [G loss: 0.022931]\n",
            "0.0 0.0\n",
            "437 [D loss: 0.031248, acc.: 99.0967%] [G loss: 0.109288]\n",
            "0.0 0.0\n",
            "438 [D loss: 0.027187, acc.: 99.2065%] [G loss: 0.120755]\n",
            "0.0 0.0\n",
            "439 [D loss: 0.026310, acc.: 99.0845%] [G loss: 0.144357]\n",
            "0.0 0.0\n",
            "440 [D loss: 0.027477, acc.: 99.2310%] [G loss: 0.035970]\n",
            "0.0 0.0\n",
            "441 [D loss: 0.032832, acc.: 99.1333%] [G loss: 0.078087]\n",
            "0.0 0.0\n",
            "442 [D loss: 0.024263, acc.: 99.2798%] [G loss: 0.139895]\n",
            "0.0 0.0\n",
            "443 [D loss: 0.028484, acc.: 99.0723%] [G loss: 0.069616]\n",
            "0.0 0.0\n",
            "444 [D loss: 0.027108, acc.: 99.1455%] [G loss: 0.142857]\n",
            "0.0 0.0\n",
            "445 [D loss: 0.028501, acc.: 99.1577%] [G loss: 0.067648]\n",
            "0.0 0.0\n",
            "446 [D loss: 0.030637, acc.: 99.1089%] [G loss: 0.129674]\n",
            "0.0 0.0\n",
            "447 [D loss: 0.024136, acc.: 99.1333%] [G loss: 0.000011]\n",
            "0.0 0.0\n",
            "448 [D loss: 0.026169, acc.: 99.1577%] [G loss: 0.174151]\n",
            "0.0 0.0\n",
            "449 [D loss: 0.033212, acc.: 98.9746%] [G loss: 0.070522]\n",
            "0.0 0.0\n",
            "450 [D loss: 0.020395, acc.: 99.3896%] [G loss: 0.090771]\n",
            "0.0 0.0\n",
            "451 [D loss: 0.029071, acc.: 99.0601%] [G loss: 0.154651]\n",
            "0.0 0.0\n",
            "452 [D loss: 0.023027, acc.: 99.2798%] [G loss: 0.105274]\n",
            "0.0 0.0\n",
            "453 [D loss: 0.027327, acc.: 99.1089%] [G loss: 0.034368]\n",
            "0.0 0.0\n",
            "454 [D loss: 0.031631, acc.: 99.1699%] [G loss: 0.081177]\n",
            "0.0 0.0\n",
            "455 [D loss: 0.025048, acc.: 99.2432%] [G loss: 0.100341]\n",
            "0.0 0.0\n",
            "456 [D loss: 0.033814, acc.: 98.9502%] [G loss: 0.148762]\n",
            "0.0 0.0\n",
            "457 [D loss: 0.030832, acc.: 99.1333%] [G loss: 0.118720]\n",
            "0.0 0.0\n",
            "458 [D loss: 0.025440, acc.: 99.1577%] [G loss: 0.162321]\n",
            "0.0 0.0\n",
            "459 [D loss: 0.030591, acc.: 99.1821%] [G loss: 0.175960]\n",
            "0.0 0.0\n",
            "460 [D loss: 0.031219, acc.: 98.9380%] [G loss: 0.054304]\n",
            "0.0 0.0\n",
            "461 [D loss: 0.039174, acc.: 98.9502%] [G loss: 0.064314]\n",
            "0.0 0.0\n",
            "462 [D loss: 0.031083, acc.: 99.0845%] [G loss: 0.047673]\n",
            "0.0 0.0\n",
            "463 [D loss: 0.036141, acc.: 99.1333%] [G loss: 0.002647]\n",
            "0.0 0.0\n",
            "464 [D loss: 0.033365, acc.: 99.1455%] [G loss: 0.116048]\n",
            "0.0 0.0\n",
            "465 [D loss: 0.028397, acc.: 99.0967%] [G loss: 0.152040]\n",
            "0.0 0.0\n",
            "466 [D loss: 0.030229, acc.: 99.1089%] [G loss: 0.080164]\n",
            "0.0 0.0\n",
            "467 [D loss: 0.031183, acc.: 99.2188%] [G loss: 0.162651]\n",
            "0.0 0.0\n",
            "468 [D loss: 0.025360, acc.: 99.2432%] [G loss: 0.069743]\n",
            "0.0 0.0\n",
            "469 [D loss: 0.031209, acc.: 98.9624%] [G loss: 0.149708]\n",
            "0.0 0.0\n",
            "470 [D loss: 0.031555, acc.: 99.0723%] [G loss: 0.025237]\n",
            "0.0 0.0\n",
            "471 [D loss: 0.030175, acc.: 99.1333%] [G loss: 0.279403]\n",
            "0.0 0.0\n",
            "472 [D loss: 0.036380, acc.: 98.9990%] [G loss: 0.072155]\n",
            "0.0 0.0\n",
            "473 [D loss: 0.045991, acc.: 98.8403%] [G loss: 0.003617]\n",
            "0.0 0.0\n",
            "474 [D loss: 0.049798, acc.: 98.9258%] [G loss: 0.025862]\n",
            "0.0 0.0\n",
            "475 [D loss: 0.045548, acc.: 98.9258%] [G loss: 0.222695]\n",
            "0.0 0.0\n",
            "476 [D loss: 0.047295, acc.: 98.9380%] [G loss: 0.199355]\n",
            "0.0 0.0\n",
            "477 [D loss: 0.032353, acc.: 99.1333%] [G loss: 0.084151]\n",
            "0.0 0.0\n",
            "478 [D loss: 0.031471, acc.: 99.0723%] [G loss: 0.047574]\n",
            "0.0 0.0\n",
            "479 [D loss: 0.038385, acc.: 99.0234%] [G loss: 0.093381]\n",
            "0.0 0.0\n",
            "480 [D loss: 0.032747, acc.: 99.1699%] [G loss: 0.114064]\n",
            "0.0 0.0\n",
            "481 [D loss: 0.032846, acc.: 99.0723%] [G loss: 0.116746]\n",
            "0.0 0.0\n",
            "482 [D loss: 0.039365, acc.: 99.1943%] [G loss: 0.088991]\n",
            "0.0 0.0\n",
            "483 [D loss: 0.031929, acc.: 99.1699%] [G loss: 0.075574]\n",
            "0.0 0.0\n",
            "484 [D loss: 0.026636, acc.: 99.2432%] [G loss: 0.015115]\n",
            "0.0 0.0\n",
            "485 [D loss: 0.021217, acc.: 99.4629%] [G loss: 0.110774]\n",
            "0.0 0.0\n",
            "486 [D loss: 0.026742, acc.: 99.2676%] [G loss: 0.000000]\n",
            "0.0 0.0\n",
            "487 [D loss: 0.028794, acc.: 99.3652%] [G loss: 0.136403]\n",
            "0.0 0.0\n",
            "488 [D loss: 0.030630, acc.: 99.2432%] [G loss: 0.001478]\n",
            "0.0 0.0\n",
            "489 [D loss: 0.031762, acc.: 99.1333%] [G loss: 0.043497]\n",
            "0.0 0.0\n",
            "490 [D loss: 0.031643, acc.: 99.3164%] [G loss: 0.101949]\n",
            "0.0 0.0\n",
            "491 [D loss: 0.023085, acc.: 99.2432%] [G loss: 0.126965]\n",
            "0.0 0.0\n",
            "492 [D loss: 0.022510, acc.: 99.4019%] [G loss: 0.056320]\n",
            "0.0 0.0\n",
            "493 [D loss: 0.022067, acc.: 99.2432%] [G loss: 0.017703]\n",
            "0.0 0.0\n",
            "494 [D loss: 0.030037, acc.: 99.3530%] [G loss: 0.063814]\n",
            "0.0 0.0\n",
            "495 [D loss: 0.020018, acc.: 99.3774%] [G loss: 0.074621]\n",
            "0.0 0.0\n",
            "496 [D loss: 0.022991, acc.: 99.2310%] [G loss: 0.075667]\n",
            "0.0 0.0\n",
            "497 [D loss: 0.033803, acc.: 99.0234%] [G loss: 0.152212]\n",
            "0.0 0.0\n",
            "498 [D loss: 0.033142, acc.: 99.2310%] [G loss: 0.090066]\n",
            "0.0 0.0\n",
            "499 [D loss: 0.038377, acc.: 99.2676%] [G loss: 0.067815]\n",
            "\n",
            "\n",
            "---LR SameTrainData\n",
            "\n",
            "Original_Train_TPR: 0.9208685238875584, Adver_Train_TPR: 0.0\n",
            "\n",
            "Original_Test_TPR: 0.92, Adver_Test_TPR: 0.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "---TPR after the blackbox_detector is retrained (Before retraining MalGAN).\n",
            "\n",
            "Train_TPR: 1.0, Test_TPR: 1.0\n",
            "[0.921404260683222] [0.9211029411764706] \n",
            "\n",
            "Training epochs.....\n",
            "0.9928778520105886 0.9935294117647059\n",
            "0.9869217193999748 0.9877941176470588\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "0.999495777133493 0.9998529411764706\n",
            "0.9984558174713223 0.9983823529411765\n",
            "0.994453548468423 0.9952205882352941\n",
            "0.9944220345392664 0.995\n",
            "0.9943905206101097 0.995\n",
            "0.9943905206101097 0.995\n",
            "0.9943905206101097 0.995\n",
            "0.9943905206101097 0.995\n",
            "0.9943905206101097 0.9949264705882352\n",
            "0.9943905206101097 0.9949264705882352\n",
            "0.9943905206101097 0.9949264705882352\n",
            "0.9943905206101097 0.995\n",
            "0.9943905206101097 0.995\n",
            "0.9943905206101097 0.9949264705882352\n",
            "0.9943905206101097 0.9949264705882352\n",
            "0.9943905206101097 0.9949264705882352\n",
            "0.9943905206101097 0.9949264705882352\n",
            "0.994359006680953 0.9949264705882352\n",
            "0.9943905206101097 0.9949264705882352\n",
            "0.9943905206101097 0.995\n",
            "0.9943905206101097 0.9949264705882352\n",
            "0.9943905206101097 0.9948529411764706\n",
            "0.9943905206101097 0.9949264705882352\n",
            "0.9943905206101097 0.995\n",
            "0.9943905206101097 0.9949264705882352\n",
            "0.9943905206101097 0.995\n",
            "0.9943905206101097 0.9949264705882352\n",
            "0.9943905206101097 0.9949264705882352\n",
            "0.9943905206101097 0.9949264705882352\n",
            "0.9943905206101097 0.9948529411764706\n",
            "0.9943905206101097 0.9949264705882352\n",
            "0.9943905206101097 0.9949264705882352\n",
            "0.994359006680953 0.9949264705882352\n",
            "0.9943905206101097 0.9949264705882352\n",
            "0.994359006680953 0.9948529411764706\n",
            "0.994264464893483 0.9949264705882352\n",
            "0.9942959788226396 0.9948529411764706\n",
            "0.994264464893483 0.9947058823529412\n",
            "0.9942329509643262 0.9947794117647059\n",
            "0.994264464893483 0.9947794117647059\n",
            "0.9941384091768561 0.9946323529411765\n",
            "0.9941384091768561 0.9947058823529412\n",
            "0.9941384091768561 0.9944852941176471\n",
            "0.9941068952476995 0.9945588235294117\n",
            "0.9941384091768561 0.9947058823529412\n",
            "0.9940123534602294 0.9944117647058823\n",
            "0.993854783814446 0.9939705882352942\n",
            "0.9936972141686625 0.99375\n",
            "0.9932560191604689 0.9932352941176471\n",
            "0.9928778520105886 0.993014705882353\n",
            "0.9921530316399849 0.9922058823529412\n",
            "0.9884974158578091 0.98875\n",
            "0.9469620572292954 0.9429411764705883\n",
            "0.8498046136392285 0.8502205882352941\n",
            "0.513298878104122 0.5057352941176471\n",
            "0.2638346148997857 0.26551470588235293\n",
            "0.07676793142569016 0.07235294117647059\n",
            "0.021744611118114206 0.02073529411764706\n",
            "0.01767931425690155 0.017205882352941175\n",
            "0.015347283499306693 0.014264705882352941\n",
            "0.012605571662674902 0.012279411764705882\n",
            "0.010368082692550106 0.01036764705882353\n",
            "0.009832345896886424 0.009411764705882352\n",
            "0.009265095172066053 0.008970588235294117\n",
            "0.008918441951342494 0.00875\n",
            "0.00872935837640237 0.008161764705882353\n",
            "0.008445733013992185 0.00823529411764706\n",
            "0.008351191226522123 0.008161764705882353\n",
            "0.008319677297365435 0.007941176470588234\n",
            "0.008193621580738686 0.008088235294117648\n",
            "0.008193621580738686 0.007794117647058824\n",
            "0.008130593722425312 0.00786764705882353\n",
            "0.008130593722425312 0.008014705882352941\n",
            "0.008288163368208748 0.007794117647058824\n",
            "0.008256649439052062 0.00786764705882353\n",
            "0.008067565864111937 0.007794117647058824\n",
            "0.008036051934955251 0.007941176470588234\n",
            "0.008067565864111937 0.00786764705882353\n",
            "0.008067565864111937 0.007647058823529412\n",
            "0.008130593722425312 0.0075735294117647055\n",
            "0.008036051934955251 0.0075\n",
            "0.008099079793268625 0.007647058823529412\n",
            "0.008067565864111937 0.0075735294117647055\n",
            "0.008067565864111937 0.0075\n",
            "0.008004538005798563 0.0075\n",
            "0.008067565864111937 0.007426470588235294\n",
            "0.007973024076641876 0.0075\n",
            "0.008004538005798563 0.0075735294117647055\n",
            "0.007973024076641876 0.007426470588235294\n",
            "0.007941510147485188 0.007426470588235294\n",
            "0.007973024076641876 0.0075\n",
            "0.007973024076641876 0.007426470588235294\n",
            "0.007909996218328502 0.007426470588235294\n",
            "0.008036051934955251 0.007426470588235294\n",
            "0.007909996218328502 0.007426470588235294\n",
            "\n",
            "\n",
            "---LR SameTrainData\n",
            "\n",
            "Original_Train_TPR: 0.921404260683222, Adver_Train_TPR: 0.007909996218328502\n",
            "\n",
            "Original_Test_TPR: 0.9211029411764706, Adver_Test_TPR: 0.007426470588235294\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXxU9b3/8ddnJvskZGcNCCiiKEskLIoLirW4XKioFWqvcLViqXbR1v609gq1ta1Xb6ve1vbivlDBcquiolYRXNAqq8giCjFIWJNAAtmX+fz+OEOIkIQkMJycmc/TRx6Zc+bMOe+vR/OZs32/oqoYY4yJXj63AxhjjHGXFQJjjIlyVgiMMSbKWSEwxpgoZ4XAGGOiXIzbAdorKytL+/bt63YMY4zxlBUrVhSranZz73muEPTt25fly5e7HcMYYzxFRLa09J6dGjLGmChnhcAYY6KcFQJjjIlynrtGYIxxV11dHYWFhVRXV7sdxTQjISGBnJwcYmNj2/wZKwTGmHYpLCwkJSWFvn37IiJuxzFNqColJSUUFhbSr1+/Nn8ubKeGRORxEdktImtbeF9E5CER2SQia0TkjHBlMcYcO9XV1WRmZloR6IREhMzMzHYfrYXzGsGTwPhW3r8YGBD6mQ78JYxZjDHHkBWBzqsj+yZsp4ZU9V0R6dvKIhOBp9XpB/tfIpImIj1UdUe4Mh3Ja8/dzR8/epBq6pt9/29fDCHHnw6JiTzZYxdrU6rokdSVwQPPJe+C75KR1uM4JzbGmKPn5jWCXsDWJtOFoXmHFQIRmY5z1ECfPn2OesM7dnzBP997gnFjryOn60nOzIceIvahWSy6Rgm2cJxU++H7sNd5/dLV8GI6UAt8+gp8+nP6VyWSQSIXVXTnnpKhIEJhTCVTui+FFor0A0XDGV6TCcBfUj/nuZQCfCrIIR/oWZ/InF1jGqe/2fNtKn1fL1gCiAozygYwubwvAG8n7uTXGc2enQPg5R1jSdZYUOXWrBWsjN+DAkHRr63zgqpuzNwzBIDCmEqu7fYBCijq/Bbn96FtejjUJiDULhrb1qs+kWebtOmynouplAZ8yMH1ht67seykI7bpwLpf3nk+SRIHItyasYzVsSUIgg/wIfgRRIVza7rz//Y7bdrmr+B7Ge87OfHhEwnlgCDKb8tHMaTeadMzCZ+zIKGgsf0NKMHQTy9N5n8rLgCfD/x+fpb4LvUCsRKDX3zE+Pwk+ONJjEnkvMRTyQsMgLg4tvj2sVy3kxJIp0tKFgOHjiO92wkt7rdoVlJSwrhx4wDYuXMnfr+f7GzngdmPP/6YuLi4Fj+7fPlynn76aR566KFWt3HWWWfxwQcfHHXWyspKbrjhBtasWYOqkpaWxuuvv05ycnKLn/ntb3/LL37xi6Pednt44mKxqs4GZgPk5eUd9Ug6tz5wMXOTNiPrf8eldX35Q+loBjw8lwuBN/Q7xA4bddjhlQYb6DnnRKgNQmUl03ctZfT+L9hasYOVlZtZ1aWS/MQq8qnipE174P/WA1CdAe//qOUsZYtfhy+d15svgvfOan65E/cAcwoapz+8A/bHN7/sZe/vhg+WArD7dFhyZcvbb3h+HtQ4r1dPhXdauL7UI383zP8UgKoMWNzGNuVfBO+30KaTSvham965A8pbaNMl7+9qc5vq5j3X2KZVU2FJC21KyS+E+c5T6pUZ8Horbbp13leNbfrkIpjfQpsGlAB/Wt84/ddfQMWhN28EgVq475VXyAv9rfngdPhO0zZ9CIP2JXBW/In84NJfkTvmipbDRZnMzExWr14NwKxZs0hOTuZnP/tZ4/v19fXExDT/py0vL4+8vLwjbuNYFAGABx98kG7duvHpp87/Oxs3bjzi3TzRVgi2Ab2bTOeE5oXde1oAgD8IC2MK+NHrBQyIi4PHH+fCa65p0zouZgoXN5mu217I5+/+g8qqfaSfkASXdwOgV7CWd6vzW1zP4Jk54A8A8IO63fxbfQlBDq91ib3i4JmTGqdfr/6chiajy2njP9D/e9kwIwuA8+vLeLuuhX+tqgRmDwR8IMJ/126hNFiJD2n8R0PfdLN7p8DEnFCbanirepPzDVwk9G374PJDZvb+Wpsm1O9pzNi0bYe26ZWqDdRrkCDBJgmcbZz4va4H21RXytu12w4eZYmgGmq/Kkl/PRnwQzDIH2q2sEcrUIGgKkENOt/eNUivC9JhfB9QpafWsrDmcyejBgkGGwhqAz58CDDkp/3B53yL+/e6QkbW73TaruAXH37xIwqJXWLgoZOhoQGCQe6vfp/KYA0NGqRe66lvqKc6WEN1Qw0jRvSGQdlQW0sfKWTS3vXs0xr2SjVrU6pY36Wa9axj6T+uYd2ZlyM+e+ynJdOmTSMhIYFVq1YxZswYJk+ezI9//GOqq6tJTEzkiSeeYODAgSxZsoT777+fV155hVmzZvHVV1+Rn5/PV199xU9+8hN+9CPn20BycjLl5eUsWbKEWbNmkZWVxdq1axk+fDjPPvssIsLChQu59dZbCQQCjBkzhvz8fF555ZWv5dqxYwcnnHDwyG7gwIGNr5999lkeeughamtrGTVqFA8//DB33nknVVVVDBs2jNNOO405c+Ycn3+Bqhq2H6AvsLaF9y4FXsP533k08HFb1jl8+HA9GoX5nyiz0NTb0eKlb+rDPz1P77i2lwbfeeeo1mvMsVRdWqIfvvA/evb0GJ05Fq39+F9uR2q0fv36gxMQnp82mjlzpt533306depUvfTSS7W+vl5VVcvKyrSurk5VVd98802dNGmSqqouXrxYL7300sbPnnnmmVpdXa1FRUWakZGhtbW1qqoaCAQal+/SpYtu3bpVGxoadPTo0free+9pVVWV5uTkaH5+vqqqTp48uXG9Ta1atUqzs7N19OjReuedd+rnn3/e+O/wsssua9zejBkz9Kmnnvrato/G1/ZRCLBcW/i7GrYjAhF5DhgLZIlIITATiA0Vn78CC4FLgE1AJfAf4crS1LKl8wAYUZlG5lkXMuOsC4/HZo1pl/jUDEZ/62beW7IJljwIz/4NRoxyO1andtVVV+H3+wEoKytj6tSpfPHFF4gIdXV1zX7m0ksvJT4+nvj4eLp27cquXbvIycn52jIjR45snDds2DAKCgpITk6mf//+jffqT5kyhdmzZx+2/mHDhpGfn88///lP3nrrLUaMGMGHH37IokWLWLFiBSNGjACgqqqKrl27HrN/F+0VzruGphzhfQVuCtf2W9J74y5mrIIhQ0Yc700b037XXgsPPgh/+xvcfz+042nR46LJ6Um3BQKBxtf/+Z//yfnnn88LL7xAQUEBY8eObfYz8fEHL0r5/X7q6w+/Y7Aty7QmOTmZSZMmMWnSJHw+HwsXLiQuLo6pU6fyu9/9rl3rCpeoO+k4/OOtPPwqfH/4jW5HMebIcnP5csQA7h1YzMYXHnE7jWeUlZXRq1cvAJ588sljvv6BAweSn59PQUEBAPPmzWt2uaVLl7J3r3OrYW1tLevXr+eEE05g3LhxzJ8/n927dwOwZ88etmxxeomOjY1t8QgmXKKrEASD8PHHzuuRI93NYkxbiPC7Cenc/g2Ys+R/3E7jGT//+c+54447yM3Nbfc3+LZITEzk4YcfZvz48QwfPpyUlBRSU1MPW27z5s2cd955DB48mNzcXPLy8rjiiisYNGgQv/nNb7jooosYMmQI3/jGN9ixw7lzfvr06QwZMoRr2njjyrEg2okO7doiLy9POzowzfbV77L42vM4syab/p/tAns60njAmx89x0Wvf4dTimH9rGIkM9PVPBs2bODUU091NUNnUF5eTnJyMqrKTTfdxIABA7jlllvcjgU0v49EZIWqNnvvbFQdEby19Fm+ewXcdkmMFQHjGeePuIrMulg+y4K1f3vA7Tgm5JFHHmm8zbOsrIwbb/Tu6eaoKgQfb/0XACMzh7qcxJi2i/HFMCnzbAD+vuJpl9OYA2655RZWr17N+vXrmTNnDklJSW5H6rDoKgQ1mwEYOchuGTXectV5MwBYECjsVHfqmMgQNYWgpryM1SmViMLwc652O44x7TJ60DcB2JARpH7b1iMsbUz7RE0h+OT9+dT54dR98XTJzjnyB4zpRFISunDu3i58czPsW7fS7TgmwkRNIfh4zWsAjPQffe+lxrjhnfKrWPAcZGw6Ll1ymSgSNYWgaOtGYhtgZM8j9zxoTKd0yinO788+czeHy84//3zeeOONr8174IEHmDFjRoufGTt2LAduO7/kkksoLS09bJlZs2Zx//33t7rtF198kfXrD/Yue9ddd/HWW2+1J36zKisrueaaaxg8eDCnn346Z599NuXl5a1+5re//e1Rb/eAqCkEvyrLZf+DSVx7zg/djmJMx5xyCqUJ8EVBdJ8amjJlCnPnzv3avLlz5zJlSqu92jRauHAhaWlpHdr2oYXg7rvv5sILj/7mk6bdVa9du5bHHnusTd1VHytRUwh4+mni9+wjcIZ13GW8aVl2Hem3w9V9l7kdxVVXXnklr776KrW1tQAUFBSwfft2zjnnHGbMmEFeXh6nnXYaM2fObPbzffv2pbi4GIB77rmHk08+mbPPPpuNGzc2LvPII48wYsQIhg4dyhVXXEFlZSUffPABCxYs4LbbbmPYsGFs3ryZadOmMX/+fAAWLVpEbm4ugwcP5rrrrqOmpqZxezNnzuSMM85g8ODBfNbMEd2OHTsau8QApwuLA30cPfvss4wcOZJhw4Zx44030tDQwO23397YXfWxeAI5egoBgN/vjBxljAedfPp5AGxIraOh7PBTG26RX0mLP7NXHOyRc/aK2a0u21YZGRmMHDmS115zrvvNnTuXb3/724gI99xzD8uXL2fNmjW88847rFmzpsX1rFixgrlz57J69WoWLlzIsmUHC+ykSZNYtmwZn3zyCaeeeiqPPfYYZ511FhMmTOC+++5j9erVnHjiiY3LV1dXM23aNObNm8enn35KfX09f/nLwWHYs7KyWLlyJTNmzGj29NN1113Hvffey5lnnskvf/lLvvjiC8B5QnjevHksXbqU1atX4/f7mTNnDr///e9JTExk9erVx2TMAvuraIxHpAYy6FUZQ3UsFKxe4nYcVzU9PdT0tNDzzz/PGWecQW5uLuvWrfvaaZxDvffee1x++eUkJSXRpUsXJkyY0Pje2rVrOeeccxg8eDBz5sxh3bp1rebZuHEj/fr14+STTwZg6tSpvPvuu43vT5o0CYDhw4c3dlTX1IHuqm+77Tb27NnDiBEj2LBhw9e6qx42bBiLFi0iP7/lga46yhNDVRpjHIOCGWxjN+s/e5cTz/uW23EA0Jlte8Bt+vDpTB8+/Zhsc+LEidxyyy2sXLmSyspKhg8fzpdffsn999/PsmXLSE9PZ9q0aVRXV3do/dOmTePFF19k6NChPPnkkyxZsuSo8h44zdNaN9ZudldtRwTGeMigpL4ArN+22t0gLktOTub888/nuuuuazwa2LdvH4FAgNTUVHbt2tV46qgl5557Li+++CJVVVXs37+fl19+ufG9/fv306NHD+rq6r526iUlJYX9+/cftq6BAwdSUFDApk2bAHjmmWc477zz2twet7urtkJgjIcM6j4YgPVlm11O4r4pU6bwySefNBaCoUOHkpubyymnnMJ3vvMdxowZ0+rnzzjjDK6++mqGDh3KxRdf3DhaGMCvf/1rRo0axZgxYzjlwG27wOTJk7nvvvvIzc1l8+aD+yAhIYEnnniCq666isGDB+Pz+fj+97/f5ra43V11VHVDbYzXLX3rcc5eej3D9ySw/MEqVzJYN9Sdn3VDbUwEGzb8Mt54Bl56th7CMOCKiU5WCIzxkEB6Vy6q60OvPfXw5ZduxzERwgqBMV5z4Jz1hg2uRfDaKeVo0pF9Y4XAGI95Y3Ai37kCnl579A8SdURCQgIlJSVWDDohVaWkpISEhIR2fc6eIzDGY/J7JvJcCsTvXcm1Lmw/JyeHwsJCioqKXNi6OZKEhARyctrX1b4VAmM85rT+o+GTuayr3+HK9mNjY+nXr58r2zbhYaeGjPGYvic5dwBuj+3YU7PGHMoKgTEeE0jrCkCFP+hyEhMprBAY4zGBtGwAKmLtYq05NqwQGOMx8Uld8Aehzg+1Va2PYmVMW9jFYmM8Rnw+vlkQA/X11O0vJS4x2e1IxuOsEBjjQa++1RW2b4d73U5iIoGdGjLGi5JDRwFHGODcmLYIayEQkfEislFENonI7c2830dEFovIKhFZIyKXhDOPMZGiIjWRnclQU7bH7SgmAoStEIiIH/gzcDEwCJgiIoMOWeyXwPOqmgtMBh4OVx5jIsn4MV/S42fw0U7rkt0cvXAeEYwENqlqvqrWAnOBiYcso0CX0OtUYHsY8xgTMZKJA6CiYq/LSUwkCGch6AVsbTJdGJrX1CzguyJSCCwEftjcikRkuogsF5Hl1r+JMRAQZwzc8spSl5OYSOD2xeIpwJOqmgNcAjwjIodlUtXZqpqnqnnZ2dnHPaQxnU3A7/QuWVFV5nISEwnCWQi2Ab2bTOeE5jV1PfA8gKp+CCQAWWHMZExESPYnAVBRdfhA6sa0VzgLwTJggIj0E5E4nIvBCw5Z5itgHICInIpTCOzcjzFHEIhJBKC81gqBOXphKwSqWg/cDLwBbMC5O2idiNwtIhNCi/0UuEFEPgGeA6apjXZhzBEF4gIAVNTacwTm6IX1yWJVXYhzEbjpvLuavF4PjAlnBmMi0VWBkQx5dDGDxvd3O4qJANbFhDEeNKjLiQz6DBgT53YUEwHcvmvIGNMR1sWEOYbsiMAYD9ocu5+550Cf+I38u9thjOfZEYExHrRZSvnlOHg6bYvbUUwEsEJgjAcFktMBqKDW5SQmElghMMaDkpMzAKjw1bucxEQCKwTGeFCgi/MAfrkVAnMMWCEwxoMCqU4hqPAHXU5iIoEVAmM8KDm1KwAVMfYgvjl6VgiM8aCk5HQyKiGzCrTWLhibo2OFwBgP8vtjKPnfVAoeAKmsdDuO8TgrBMZ4VcDpeM6eLjZHywqBMV5l3UyYY8QKgTEe9c0Ld9D1Nli3c43bUYzHWSEwxqNK46EoAPv3FbsdxXicFQJjPCpALADlFXtdTmK8zgqBMR4VkHgAKipLXU5ivM4KgTEelexLAKCisszlJMbrrBAY41GNA9hX73M5ifE6KwTGeNSBQlBRs9/lJMbrbIQyYzzq4rjTyFy0gjPPznY7ivE4OyIwxqPGp+Ry1zswujzN7SjG46wQGONV1sWEOUbs1JAxHrU9oY7lA6Fb/RZGuR3GeJodERjjUe8G85k4Bf6Qus7tKMbjrBAY41GBJOfaQLnWuJzEeJ0VAmM8qnEAe+pcTmK8zgqBMR4VCBWCcrFCYI6OFQJjPCqQkglAha/e5STG66wQGONRyanOg2QV/qDLSYzXWSEwxqMCqVkAlMdYITBHJ6yFQETGi8hGEdkkIre3sMy3RWS9iKwTkb+FM48xkSQjrQfb/ujjyweAOrtOYDoubA+UiYgf+DPwDaAQWCYiC1R1fZNlBgB3AGNUda+IdA1XHmMijc/npycpUFMGFRWQZl1NmI4J5xHBSGCTquarai0wF5h4yDI3AH9W1b0Aqro7jHmMiTzWzYQ5BsJZCHoBW5tMF4bmNXUycLKILBWRf4nI+OZWJCLTRWS5iCwvKioKU1xjvOc/xpUz7lrYXbzF7SjGw9y+WBwDDADGAlOAR0TksONbVZ2tqnmqmpedbV3uGnPA0m41vN0fSst2uR3FeFg4C8E2oHeT6ZzQvKYKgQWqWqeqXwKf4xQGY0wbBNS5zFe+v8TlJMbLwlkIlgEDRKSfiMQBk4EFhyzzIs7RACKShXOqKD+MmYyJKAHiAKio2OtyEuNlYSsEqloP3Ay8AWwAnlfVdSJyt4hMCC32BlAiIuuBxcBtqmpfbYxpo+TGQlDqchLjZWEdj0BVFwILD5l3V5PXCtwa+jHGtFPAlwBAeaUVAtNxbl8sNsYchYDfKQQV1ftcTmK8zAqBMR42yteHK9dBTk2821GMh1khMMbDbko8l7//HcZVdnc7ivEwKwTGeNmBJ4srKtzNYTzNBq83xsMqkmLZnQaJlbuxYwLTUe0+IhARn4hcE44wxpj2eTq4kv4/gV8lLXM7ivGwFguBiHQRkTtE5E8icpE4fojzwNe3j19EY0xLAgldACgPVrmcxHhZa6eGngH2Ah8C3wN+AQjwLVVdfRyyGWOOIDmQDkBFsMblJMbLWisE/VV1MICIPArsAPqoavVxSWaMOaJAqBCUU+tyEuNlrV0jaBzySFUbgEIrAsZ0LoHk0BGB2AhlpuNaOyIYKiL7cE4HASQ2mVZV7RL2dMaYViWnZAJQIfUuJzFe1mIhUFX/8QxijGm/QJozPke5v8HlJMbLWiwEIpIAfB84CVgDPB7qUdQY00nk9DiF156FjGqF/w6Cz54RNe3X2qmhp3CuE7wHXAKcBvz4eIQyxrRNYmIK43cmO2MWl5dDFztja9qvtUIwqMldQ48BHx+fSMaYdklLc4pAaakVAtMhbb1ryE4JGdNJ/dfIOn50Mewt2up2FONRrR0RDAvdJQTOnUJ215AxndCjJ5bxRQB+UPQl6YxxO47xoNYKwSeqmnvckhhjOiRdE4BqSkt3uB3FeFRrp4b0uKUwxnRYmjijlJXuK3I5ifGq1o4IuopIi2MJq+ofwpDHGNNOaX5nTILS/VYITMe0Vgj8QDIHnyw2xnRCabEpAOytKHE5ifGq1grBDlW9+7glMcZ0SHp8GtRDafVet6MYj2rtGoEdCRjjATlJ3RlYDMmV1s2E6ZjWCsG445bCGNNhN/e6nM/+BD/c1svtKMajWiwEqrrneAYxxnRQaqrzu7TU3RzGs6yHKmO8Li0NgGCZFQLTMVYIjPG4VbqdlDtg9KhP3Y5iPMoKgTEel5SWTXk87I2xLsFMx1ghMMbj0rP7AFAa1wBqHQKY9rNCYIzHpaZ2A6A0HrSqyuU0xousEBjjcfEx8STWQb0fKoq3ux3HeFBYC4GIjBeRjSKySURub2W5K0RERSQvnHmMiVTpdc4Q46XFhS4nMV4UtkIgIn7gz8DFwCBgiogMama5FJwhMD8KVxZjIl1aQxwAe0usEJj2C+cRwUhgk6rmq2otMBeY2MxyvwbuBarDmMWYiHbHjhP568vQvbq17sOMaV44C0EvoOnYeYWheY1E5Aygt6q+2tqKRGS6iCwXkeVFRdbVrjGH+m7dqdy4ArIrrYsw036uXSwWER/wB+CnR1pWVWerap6q5mVnZ4c/nDFeE3q62LqZMB0RzkKwDejdZDonNO+AFOB0YImIFACjgQV2wdiY9luVUcOjZ8DKPevcjmI8KJyFYBkwQET6iUgcMBlYcOBNVS1T1SxV7auqfYF/ARNUdXkYMxkTkf6R9BU3TIBXKle7HcV4UNgKgarWAzcDbwAbgOdVdZ2I3C0iE8K1XWOiUVpiOgClNWUuJzFeFNZbDFR1IbDwkHl3tbDs2HBmMSaSpSVnQiXsrd/vdhTjQfZksTERIC05C4DShkqXkxgvskJgTARIT+0OQCnW15BpPysExkSAtPQeAJRKrctJjBdZITAmAqRl9ASgSmxMAtN+9jy6MRGgb+/BVP8a4hPi4Y9upzFeY0cExkQAX0oX4tUHFRVQV+d2HOMxVgiMiQQikJrqvC6zZwlM+1ghMCZCXDmxhkE3wVfbN7gdxXiMFQJjIsSmdGVDNpQUf+V2FOMxVgiMiRBp6gxOU7p3p8tJjNdYITAmQqRJIgCl+3a7nMR4jRUCYyJEmj8AwN79VghM+1ghMCZCpMekAFBaucflJMZrrBAYEyHS4p3bR0ur97qcxHiNFQJjIsSowEB+8DGMKE91O4rxGOtiwpgIMT5rNOMXzoasDLejGI+xIwJjIoUNYG86yI4IjIkQlSkJfNoL0K2McjuM8RQrBMZEiE0x+xh9A5y2bwNr3Q5jPMVODRkTIdIzewFQ6rfeR037WCEwJkKkZfcGYE9cg8tJjNdYITAmQiRn9SKuHqpiobLSuqI2bWeFwJgIITExZFU7/0uXbN/kchrjJVYIjIkgWfWxABRZITDtYIXAmAiSHXR6IC0u2uJyEuMlVgiMiSB/LRrFpgfhvNqebkcxHmLPERgTQU5K7Qd7gRJ7uti0nR0RGBNJsrOd38XF7uYwnmKFwJgI8m5aGZOvhAfL33I7ivEQKwTGRJAdyTDvdHg/aBeLTduFtRCIyHgR2Sgim0Tk9mbev1VE1ovIGhFZJCInhDOPMZEuKzMHgOJguctJjJeErRCIiB/4M3AxMAiYIiKDDllsFZCnqkOA+cB/hSuPMdEgO7svAMW+KneDGE8J5xHBSGCTquarai0wF5jYdAFVXayqlaHJfwE5YcxjTMTL6nEiAEWx1vGcabtwFoJewNYm04WheS25HngtjHmMiXiZvQYAUJwQRBus8znTNp3iYrGIfBfIA+5r4f3pIrJcRJYXFRUd33DGeEh8UgopNdDgg7JddsHYtE04C8E2oHeT6ZzQvK8RkQuBO4EJqlrT3IpUdbaq5qlqXvaB+6SNMc365s4AEz6D2t073I5iPCKchWAZMEBE+olIHDAZWNB0ARHJBf4XpwjsDmMWY6LG3z8bwktzoev+oNtRjEeErRCoaj1wM/AGsAF4XlXXicjdIjIhtNh9QDLwdxFZLSILWlidMaatDhw122lU00Zh7WtIVRcCCw+Zd1eT1xeGc/vGRKPa7AxKkiFhVwHpbocxntApLhYbY46dX/RYT8+fwaPF/3Q7ivEIKwTGRJispCwAiiqt4znTNlYIjIkwWV26A1Bcs9flJMYrrBAYE2Gy0p3nNosb9rmcxHiFFQJjIkx2ttN3YxGVR1jSGIcVAmMiTFb3/gAU+5t9PtOYw1ghMCbCZPU8CYDiuAZQdTmN8QIrBMZEmPSMXvzfC3G8NBfYv9/tOMYDbPB6YyKMT3xMKu0BW7Y4Txd36eJ2JNPJ2RGBMZHIupkw7WCFwJgI9LdT6vjZRbDhq5VuRzEeYKeGjIlA83vs5YWTYPTutZzqdhjT6dkRgTERKDs2DYDiffjr7qkAAAsXSURBVDtdTmK8wAqBMREoKzETgKJyG+bDHJkVAmMiUFZKVwCKq/e4nMR4gRUCYyJQVmpPAIrrylxOYrzACoExESgr0xkuvEjLXU5ivMAKgTERqHv3E+lTCtn7GtyOYjzAbh81JgLlDhzLlgeAAPCUgojbkUwnZkcExkSilBTIzISKCti0ye00ppOzQmBMJBKBCy+kJBGKF853O43p5KwQGBOh7j2zga63wV/WPul2FNPJWSEwJkKdOuISgj54xbcJamyQGtMyKwTGRKhxed8mvkFY1iPIrsUvux3HdGJWCIyJUIG4ABdoX1TgtXcfdzuO6cSsEBgTwS47+TIAXin+wOUkpjOzQmBMBLv0opsAeCOrjNptX7mcxnRWVgiMiWAndBvI6ZXJVMTBqlcfczuO6aSsEBgT4Z7u+n123Qej3rEHy0zzrBAYE+FyL72e7ErgpZd49tYLWTnnfup37XA7lulErK8hYyLdwIEwahSln3zEtV0WoZsWkbjhNoaU+MmtzWJIcn/69x7CyCGXkJ57JmRlWd9EUUZUNXwrFxkPPAj4gUdV9feHvB8PPA0MB0qAq1W1oLV15uXl6fLly8MT2JhIVV/PtvcX8ot3Z/J+5WfkJ1Yftsg/n4Zv5ANpaTx2QRpv9qkn3ZdEmi+JFH8SCbGJxMcm0jM+k8uThkNcHMTG8nLNGhL9CcTHJIDfTzDGB/4YxOfj5MQcusdngghFdaUU1pYQFBp/YnwxxPpiiBU/pwb6gs8HInxeuZWKhiqCGsSnEBMU/KE/VekxKfSIzwSfjyppoKB2t7M+gjTgLCSq+MTHSUk5JPoTQJXimr2U11cigE98iM+PiIAIMSp0i8sAQFXZWrMbQRAJ/YT+QYTUuBSSfPGgSmVDNfsaKlDxoQIaDBIkCIAPH72SujmhRdhTW0a9NqCqjcscWC4pJoGUmACIUKf1lNbug6BCMOgUZZ+P+Jh4unTtDX36dOg/ARFZoap5zb0XtiMCEfEDfwa+ARQCy0Rkgaqub7LY9cBeVT1JRCYD9wJXhyuTMVErJoZeYyfw1NgJAJRUFLN6/SJWbVjMhu1r+HLfFgac0BWKNkNpKe9oKfPSmlmPwojNcPkjTwHQIDBhZsubffQluH6V83p+HvzgsuaX8weh/u6D01fOgE+7Nb/sjGXw8KvO609y4Mzvtbz9VX+FYaFhm38+EZ7IbX650Vvhw9C19HofnHBXy+ts2qbHR8IPL2l+uUPbdP73YU335pdt2qaVvWD0DYcvc/VamOu/GubObTlcB4Xz1NBIYJOq5gOIyFxgItC0EEwEZoVezwf+JCKi4TxMMcaQGchi3IirGTfikO9dqrB7N7esfJXxW1dRVlNGaU0Z+2rLqamvprq+mpyMBLgpF+rqqK+t4t8qFlNJHdXSgAQVUedHge4DToDMLFAlPXsnw8q34FPwqSCq1ItS51Pn+/GYXGf7wSAD9XN8+6rxqXPk0OCD+tDZqu5ZXeG8EyAYJCGxjIHln+NT8KvgU0BAcT6XdMpJ0DvBaXPqVvpU7SEIqDj5DvyhyYxLgpEDQ6fEGuhdtYYg6nzLb7IcKIFeOeBzjnICPYvpWlOIKM6RhgoHTqr5Fcg93WkTkB7zBVk11Y3LCAfXnZyWAUN7gCoxqZVk1XwZWuLgdlMCqdC1Y0cDRxK2U0MiciUwXlW/F5r+d2CUqt7cZJm1oWUKQ9ObQ8sUH7Ku6cB0gD59+gzfsmVLWDIbY0ykau3UkCfuGlLV2aqap6p52dnZbscxxpiIEs5CsA3o3WQ6JzSv2WVEJAZIxblobIwx5jgJZyFYBgwQkX4iEgdMBhYcsswCYGro9ZXA23Z9wBhjjq+wXSxW1XoRuRl4A+f20cdVdZ2I3A0sV9UFwGPAMyKyCdiDUyyMMcYcR2F9oExVFwILD5l3V5PX1cBV4cxgjDGmdZ64WGyMMSZ8rBAYY0yUs0JgjDFRLqx9DYWDiBQBHX2iLAsoPuJSkcXaHB2szdHhaNp8gqo2+yCW5wrB0RCR5S09WReprM3RwdocHcLVZjs1ZIwxUc4KgTHGRLloKwSz3Q7gAmtzdLA2R4ewtDmqrhEYY4w5XLQdERhjjDmEFQJjjIlyUVMIRGS8iGwUkU0icrvbecJBRHqLyGIRWS8i60Tkx6H5GSLypoh8Efqd7nbWY0lE/CKySkReCU33E5GPQvt6Xqj324ghImkiMl9EPhORDSJyZhTs41tC/02vFZHnRCQh0vaziDwuIrtDA3YdmNfsfhXHQ6G2rxGRM45m21FRCJqMn3wxMAiYIiKD3E0VFvXAT1V1EDAauCnUztuBRao6AFgUmo4kPwY2NJm+F/ijqp4E7MUZGzuSPAi8rqqnAENx2h6x+1hEegE/AvJU9XSc3owPjHEeSfv5SWD8IfNa2q8XAwNCP9OBvxzNhqOiENBk/GRVrQUOjJ8cUVR1h6quDL3ej/MHohdOW58KLfYU8C13Eh57IpIDXAo8GpoW4AKcMbAh8tqbCpyL04U7qlqrqqVE8D4OiQESQwNYJQE7iLD9rKrv4nTH31RL+3Ui8LQ6/gWkiUiPjm47WgpBL2Brk+nC0LyIJSJ9gVzgI6Cbqu4IvbUT6OZSrHB4APg5OOOfA5lAqarWh6YjbV/3A4qAJ0Knwx4VkQARvI9VdRtwP/AVTgEoA1YQ2fv5gJb26zH9mxYthSCqiEgy8H/AT1R1X9P3QiPARcQ9wyJyGbBbVVe4neU4igHOAP6iqrlABYecBoqkfQwQOi8+EacI9gQCHH4KJeKFc79GSyFoy/jJEUFEYnGKwBxV/Udo9q4Dh42h37vdyneMjQEmiEgBzum+C3DOn6eFTiFA5O3rQqBQVT8KTc/HKQyRuo8BLgS+VNUiVa0D/oGz7yN5Px/Q0n49pn/ToqUQtGX8ZM8LnR9/DNigqn9o8lbTsaGnAi8d72zhoKp3qGqOqvbF2advq+o1wGKcMbAhgtoLoKo7ga0iMjA0axywngjdxyFfAaNFJCn03/iBNkfsfm6ipf26ALg2dPfQaKCsySmk9lPVqPgBLgE+BzYDd7qdJ0xtPBvn0HENsDr0cwnOefNFwBfAW0CG21nD0PaxwCuh1/2Bj4FNwN+BeLfzHeO2DgOWh/bzi0B6pO9j4FfAZ8Ba4BkgPtL2M/AczjWQOpwjv+tb2q+A4NwJuRn4FOeOqg5v27qYMMaYKBctp4aMMca0wAqBMcZEOSsExhgT5awQGGNMlLNCYIwxUc4KgTGHEJEGEVnd5OeYdeAmIn2b9i5pTGcQc+RFjIk6Vao6zO0QxhwvdkRgTBuJSIGI/JeIfCoiH4vISaH5fUXk7VC/8ItEpE9ofjcReUFEPgn9nBValV9EHgn1r/9PEUl0rVHGYIXAmOYkHnJq6Oom75Wp6mDgTzg9nwL8D/CUqg4B5gAPheY/BLyjqkNx+gNaF5o/APizqp4GlAJXhLk9xrTKniw25hAiUq6qyc3MLwAuUNX8UOd+O1U1U0SKgR6qWheav0NVs0SkCMhR1Zom6+gLvKnOQCOIyP8DYlX1N+FvmTHNsyMCY9pHW3jdHjVNXjdg1+qMy6wQGNM+Vzf5/WHo9Qc4vZ8CXAO8F3q9CJgBjeMqpx6vkMa0h30TMeZwiSKyusn066p64BbSdBFZg/Otfkpo3g9xRgy7DWf0sP8Izf8xMFtErsf55j8Dp3dJYzoVu0ZgTBuFrhHkqWqx21mMOZbs1JAxxkQ5OyIwxpgoZ0cExhgT5awQGGNMlLNCYIwxUc4KgTHGRDkrBMYYE+X+P/4Onq/xDqrsAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AFTYNGVDe2eV"
      },
      "source": [
        "botgan_SVM = BotGAN(blackbox='SVM')\n",
        "botgan_SVM.train(epochs=100, batch_size=4096)\n",
        "botgan_SVM.retrain_blackbox_detector()\n",
        "botgan_SVM.train(epochs=30, batch_size=4096, is_first=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "qqqFFRp0hvGP",
        "outputId": "1ef6e059-e17e-470c-f00d-1bbb3e1f1c93"
      },
      "source": [
        "botgan_GBC = BotGAN(blackbox='GBC')\n",
        "botgan_GBC.train(epochs=500, batch_size=4096)\n",
        "botgan_GBC.retrain_blackbox_detector()\n",
        "botgan_GBC.train(epochs=100, batch_size=4096, is_first=False)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"substitute_detector\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 53)]              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 256)               13824     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 257       \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 1)                 0         \n",
            "=================================================================\n",
            "Total params: 14,081\n",
            "Trainable params: 14,081\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"generator\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, 53)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_3 (InputLayer)            [(None, 10)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 63)           0           input_2[0][0]                    \n",
            "                                                                 input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 256)          16384       concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 53)           13621       dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 53)           0           dense_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "maximum (Maximum)               (None, 53)           0           input_2[0][0]                    \n",
            "                                                                 activation_1[0][0]               \n",
            "==================================================================================================\n",
            "Total params: 30,005\n",
            "Trainable params: 30,005\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "[0.9429913021555527] [0.9435294117647058] \n",
            "\n",
            "Training epochs.....\n",
            "0.7113954367830582 0.7108823529411765\n",
            "0 [D loss: 0.497810, acc.: 83.5449%] [G loss: 1.179526]\n",
            "0.7291062649691163 0.7294117647058823\n",
            "1 [D loss: 0.456284, acc.: 85.4248%] [G loss: 1.125699]\n",
            "0.7042417748644901 0.7052941176470588\n",
            "2 [D loss: 0.373383, acc.: 86.9751%] [G loss: 0.696524]\n",
            "0.673925375015757 0.675514705882353\n",
            "3 [D loss: 0.302099, acc.: 89.4653%] [G loss: 0.638010]\n",
            "0.6630530694566998 0.6654411764705882\n",
            "4 [D loss: 0.264758, acc.: 91.3330%] [G loss: 0.679742]\n",
            "0.6597756208244044 0.6619117647058823\n",
            "5 [D loss: 0.227511, acc.: 92.4194%] [G loss: 0.859386]\n",
            "0.6583259800831968 0.6607352941176471\n",
            "6 [D loss: 0.210596, acc.: 92.3340%] [G loss: 0.980322]\n",
            "0.6575381318542796 0.6599264705882353\n",
            "7 [D loss: 0.199653, acc.: 92.2974%] [G loss: 0.977101]\n",
            "0.6568763393419892 0.6585294117647059\n",
            "8 [D loss: 0.190529, acc.: 92.2607%] [G loss: 1.041115]\n",
            "0.6568448254128325 0.6583823529411764\n",
            "9 [D loss: 0.180469, acc.: 92.0654%] [G loss: 1.291412]\n",
            "0.6569393672003025 0.6585294117647059\n",
            "10 [D loss: 0.165048, acc.: 92.8711%] [G loss: 1.223742]\n",
            "0.6605634690533215 0.6618382352941177\n",
            "11 [D loss: 0.352142, acc.: 85.4004%] [G loss: 3.144669]\n",
            "0.663840917685617 0.6648529411764705\n",
            "12 [D loss: 0.271489, acc.: 90.6128%] [G loss: 4.117347]\n",
            "0.664345140552124 0.6658823529411765\n",
            "13 [D loss: 0.238260, acc.: 92.1631%] [G loss: 4.245347]\n",
            "0.6639669734022438 0.6652205882352941\n",
            "14 [D loss: 0.252980, acc.: 91.4795%] [G loss: 4.386099]\n",
            "0.6636203201815203 0.6645588235294118\n",
            "15 [D loss: 0.231298, acc.: 92.4072%] [G loss: 4.593129]\n",
            "0.660626496911635 0.6617647058823529\n",
            "16 [D loss: 0.235630, acc.: 90.8447%] [G loss: 5.164553]\n",
            "0.6556157821757217 0.6565441176470588\n",
            "17 [D loss: 0.210124, acc.: 93.4204%] [G loss: 4.195764]\n",
            "0.6570969368460859 0.6588235294117647\n",
            "18 [D loss: 0.213763, acc.: 91.5161%] [G loss: 3.221902]\n",
            "0.6656687255767049 0.6674264705882353\n",
            "19 [D loss: 0.165214, acc.: 94.1895%] [G loss: 2.548128]\n",
            "0.6733266103617799 0.6752205882352941\n",
            "20 [D loss: 0.161675, acc.: 94.9707%] [G loss: 3.120215]\n",
            "0.6746817093155174 0.6763235294117647\n",
            "21 [D loss: 0.168855, acc.: 93.5547%] [G loss: 3.285295]\n",
            "0.6727908735661162 0.6744117647058824\n",
            "22 [D loss: 0.154282, acc.: 95.0073%] [G loss: 3.473278]\n",
            "0.6721290810538257 0.674264705882353\n",
            "23 [D loss: 0.155827, acc.: 94.8853%] [G loss: 3.460418]\n",
            "0.6715933442581621 0.6733823529411764\n",
            "24 [D loss: 0.165453, acc.: 94.3359%] [G loss: 3.322065]\n",
            "0.6692297995714106 0.6716911764705882\n",
            "25 [D loss: 0.158420, acc.: 93.3105%] [G loss: 3.472928]\n",
            "0.6670868523887559 0.6693382352941176\n",
            "26 [D loss: 0.147799, acc.: 95.2148%] [G loss: 3.603085]\n",
            "0.6651960166393546 0.6675735294117647\n",
            "27 [D loss: 0.137971, acc.: 95.2271%] [G loss: 3.430270]\n",
            "0.6631791251733266 0.6645588235294118\n",
            "28 [D loss: 0.150540, acc.: 94.6411%] [G loss: 3.415450]\n",
            "0.6609731501323585 0.6627941176470589\n",
            "29 [D loss: 0.137521, acc.: 95.1050%] [G loss: 3.136429]\n",
            "0.6596810790369343 0.6625\n",
            "30 [D loss: 0.154291, acc.: 94.9463%] [G loss: 3.294215]\n",
            "0.6589247447371739 0.6613235294117648\n",
            "31 [D loss: 0.150925, acc.: 94.6411%] [G loss: 3.228694]\n",
            "0.6582629522248834 0.6607352941176471\n",
            "32 [D loss: 0.148625, acc.: 94.7021%] [G loss: 3.261617]\n",
            "0.6579793268624732 0.6602941176470588\n",
            "33 [D loss: 0.143167, acc.: 94.9097%] [G loss: 3.103003]\n",
            "0.6575066179251229 0.6599264705882353\n",
            "34 [D loss: 0.137070, acc.: 95.2026%] [G loss: 3.101489]\n",
            "0.6574435900668095 0.6596323529411765\n",
            "35 [D loss: 0.157373, acc.: 94.4946%] [G loss: 2.946816]\n",
            "0.6574435900668095 0.6594852941176471\n",
            "36 [D loss: 0.154980, acc.: 94.0308%] [G loss: 2.907734]\n",
            "0.6573175343501828 0.6595588235294118\n",
            "37 [D loss: 0.150774, acc.: 94.2993%] [G loss: 2.725157]\n",
            "0.6572545064918695 0.6594852941176471\n",
            "38 [D loss: 0.144573, acc.: 94.7754%] [G loss: 2.733518]\n",
            "0.6572860204210261 0.6594117647058824\n",
            "39 [D loss: 0.140309, acc.: 95.0073%] [G loss: 2.865084]\n",
            "0.657191478633556 0.6594117647058824\n",
            "40 [D loss: 0.136070, acc.: 94.9097%] [G loss: 2.775577]\n",
            "0.657191478633556 0.6594117647058824\n",
            "41 [D loss: 0.129882, acc.: 95.1538%] [G loss: 2.802167]\n",
            "0.6572229925627128 0.6593382352941176\n",
            "42 [D loss: 0.130314, acc.: 95.3491%] [G loss: 2.939436]\n",
            "0.6571599647043993 0.6594117647058824\n",
            "43 [D loss: 0.129286, acc.: 95.1904%] [G loss: 2.867718]\n",
            "0.6572229925627128 0.6594117647058824\n",
            "44 [D loss: 0.138369, acc.: 95.0684%] [G loss: 2.730489]\n",
            "0.6571599647043993 0.6593382352941176\n",
            "45 [D loss: 0.126036, acc.: 95.5078%] [G loss: 2.887142]\n",
            "0.6572229925627128 0.6594117647058824\n",
            "46 [D loss: 0.116204, acc.: 95.8496%] [G loss: 3.073544]\n",
            "0.6571599647043993 0.659264705882353\n",
            "47 [D loss: 0.118125, acc.: 95.5933%] [G loss: 3.247341]\n",
            "0.657191478633556 0.6594117647058824\n",
            "48 [D loss: 0.114216, acc.: 96.0938%] [G loss: 3.292741]\n",
            "0.6571599647043993 0.6594117647058824\n",
            "49 [D loss: 0.115970, acc.: 95.5200%] [G loss: 3.076397]\n",
            "0.6572545064918695 0.659264705882353\n",
            "50 [D loss: 0.114690, acc.: 95.7520%] [G loss: 3.186031]\n",
            "0.6572229925627128 0.659264705882353\n",
            "51 [D loss: 0.123901, acc.: 95.2148%] [G loss: 3.275366]\n",
            "0.6571284507752426 0.659264705882353\n",
            "52 [D loss: 0.121679, acc.: 95.6909%] [G loss: 3.041274]\n",
            "0.6571599647043993 0.6591911764705882\n",
            "53 [D loss: 0.119391, acc.: 95.3491%] [G loss: 3.516945]\n",
            "0.6570339089877726 0.6591911764705882\n",
            "54 [D loss: 0.107297, acc.: 95.9229%] [G loss: 3.550573]\n",
            "0.6571284507752426 0.6591911764705882\n",
            "55 [D loss: 0.116600, acc.: 95.4102%] [G loss: 4.103853]\n",
            "0.6570969368460859 0.6591176470588235\n",
            "56 [D loss: 0.107868, acc.: 95.5566%] [G loss: 3.858075]\n",
            "0.6574435900668095 0.6595588235294118\n",
            "57 [D loss: 0.250704, acc.: 90.2710%] [G loss: 8.203561]\n",
            "0.6570654229169293 0.6591911764705882\n",
            "58 [D loss: 0.124108, acc.: 94.8853%] [G loss: 2.797865]\n",
            "0.6570969368460859 0.6591911764705882\n",
            "59 [D loss: 0.118499, acc.: 95.5933%] [G loss: 4.638702]\n",
            "0.6570969368460859 0.6591911764705882\n",
            "60 [D loss: 0.102746, acc.: 95.6543%] [G loss: 4.327809]\n",
            "0.6570969368460859 0.6591911764705882\n",
            "61 [D loss: 0.109169, acc.: 95.3857%] [G loss: 4.257890]\n",
            "0.6571284507752426 0.6591911764705882\n",
            "62 [D loss: 0.108603, acc.: 95.5566%] [G loss: 4.142762]\n",
            "0.6571284507752426 0.6591911764705882\n",
            "63 [D loss: 0.105309, acc.: 95.9717%] [G loss: 4.288312]\n",
            "0.6571599647043993 0.659264705882353\n",
            "64 [D loss: 0.111336, acc.: 95.4834%] [G loss: 4.172830]\n",
            "0.6571599647043993 0.6591911764705882\n",
            "65 [D loss: 0.106066, acc.: 95.6909%] [G loss: 3.910084]\n",
            "0.6571284507752426 0.6591911764705882\n",
            "66 [D loss: 0.110248, acc.: 95.4590%] [G loss: 4.322244]\n",
            "0.6571284507752426 0.6591911764705882\n",
            "67 [D loss: 0.105734, acc.: 95.5688%] [G loss: 4.129316]\n",
            "0.6571599647043993 0.6591911764705882\n",
            "68 [D loss: 0.104889, acc.: 95.8130%] [G loss: 3.949784]\n",
            "0.6571284507752426 0.6591911764705882\n",
            "69 [D loss: 0.104700, acc.: 95.7642%] [G loss: 4.093643]\n",
            "0.6571284507752426 0.659264705882353\n",
            "70 [D loss: 0.101508, acc.: 95.9839%] [G loss: 3.895353]\n",
            "0.6571284507752426 0.6591911764705882\n",
            "71 [D loss: 0.106887, acc.: 95.5566%] [G loss: 3.947093]\n",
            "0.6570969368460859 0.659264705882353\n",
            "72 [D loss: 0.105026, acc.: 95.6177%] [G loss: 4.038900]\n",
            "0.6570969368460859 0.659264705882353\n",
            "73 [D loss: 0.102843, acc.: 96.1304%] [G loss: 3.970898]\n",
            "0.6571284507752426 0.659264705882353\n",
            "74 [D loss: 0.107204, acc.: 95.8374%] [G loss: 3.922553]\n",
            "0.6571284507752426 0.659264705882353\n",
            "75 [D loss: 0.102923, acc.: 96.0205%] [G loss: 3.869424]\n",
            "0.6571284507752426 0.659264705882353\n",
            "76 [D loss: 0.102956, acc.: 95.9229%] [G loss: 4.071828]\n",
            "0.6571599647043993 0.6591911764705882\n",
            "77 [D loss: 0.100146, acc.: 96.0449%] [G loss: 3.950373]\n",
            "0.6571284507752426 0.6591911764705882\n",
            "78 [D loss: 0.098639, acc.: 96.1304%] [G loss: 3.995207]\n",
            "0.6570654229169293 0.6591911764705882\n",
            "79 [D loss: 0.112262, acc.: 95.2515%] [G loss: 3.551081]\n",
            "0.6570023950586159 0.6589705882352941\n",
            "80 [D loss: 0.092875, acc.: 96.1670%] [G loss: 4.027338]\n",
            "0.6569393672003025 0.6586764705882353\n",
            "81 [D loss: 0.098608, acc.: 95.9351%] [G loss: 4.134778]\n",
            "0.6569078532711459 0.65875\n",
            "82 [D loss: 0.094967, acc.: 96.0205%] [G loss: 4.040324]\n",
            "0.6569078532711459 0.6586029411764706\n",
            "83 [D loss: 0.103580, acc.: 95.7275%] [G loss: 4.059800]\n",
            "0.6569078532711459 0.6586029411764706\n",
            "84 [D loss: 0.099300, acc.: 95.7153%] [G loss: 3.816670]\n",
            "0.6568763393419892 0.6586764705882353\n",
            "85 [D loss: 0.099505, acc.: 95.8008%] [G loss: 4.252195]\n",
            "0.6568763393419892 0.6586764705882353\n",
            "86 [D loss: 0.101544, acc.: 95.6421%] [G loss: 4.210129]\n",
            "0.6569078532711459 0.6586764705882353\n",
            "87 [D loss: 0.096765, acc.: 95.9717%] [G loss: 4.183764]\n",
            "0.6569078532711459 0.6586764705882353\n",
            "88 [D loss: 0.092704, acc.: 95.8862%] [G loss: 4.194052]\n",
            "0.6568763393419892 0.6585294117647059\n",
            "89 [D loss: 0.091572, acc.: 96.3257%] [G loss: 4.195430]\n",
            "0.6569078532711459 0.6586029411764706\n",
            "90 [D loss: 0.088790, acc.: 96.2036%] [G loss: 4.251822]\n",
            "0.6569078532711459 0.6586764705882353\n",
            "91 [D loss: 0.092568, acc.: 96.2158%] [G loss: 4.136515]\n",
            "0.6568763393419892 0.65875\n",
            "92 [D loss: 0.092076, acc.: 96.0449%] [G loss: 3.986567]\n",
            "0.6569078532711459 0.6586029411764706\n",
            "93 [D loss: 0.094642, acc.: 95.9839%] [G loss: 4.212057]\n",
            "0.6568763393419892 0.6586764705882353\n",
            "94 [D loss: 0.093881, acc.: 96.0571%] [G loss: 4.101975]\n",
            "0.6568763393419892 0.65875\n",
            "95 [D loss: 0.101829, acc.: 95.7153%] [G loss: 4.175849]\n",
            "0.6568448254128325 0.6583823529411764\n",
            "96 [D loss: 0.099557, acc.: 95.5200%] [G loss: 3.667901]\n",
            "0.6568448254128325 0.6583823529411764\n",
            "97 [D loss: 0.095579, acc.: 96.0205%] [G loss: 4.230829]\n",
            "0.6568448254128325 0.6583823529411764\n",
            "98 [D loss: 0.101689, acc.: 95.6177%] [G loss: 4.050073]\n",
            "0.6568448254128325 0.6583823529411764\n",
            "99 [D loss: 0.088588, acc.: 96.0449%] [G loss: 3.933291]\n",
            "0.6568448254128325 0.6583823529411764\n",
            "100 [D loss: 0.095115, acc.: 96.0205%] [G loss: 4.396621]\n",
            "0.6568448254128325 0.6583823529411764\n",
            "101 [D loss: 0.088795, acc.: 96.2158%] [G loss: 4.130525]\n",
            "0.6568448254128325 0.6583823529411764\n",
            "102 [D loss: 0.083860, acc.: 96.4355%] [G loss: 4.310825]\n",
            "0.6568448254128325 0.6583823529411764\n",
            "103 [D loss: 0.095880, acc.: 95.9961%] [G loss: 4.161559]\n",
            "0.6568448254128325 0.6583823529411764\n",
            "104 [D loss: 0.085367, acc.: 96.4355%] [G loss: 4.393118]\n",
            "0.6568448254128325 0.6583823529411764\n",
            "105 [D loss: 0.089495, acc.: 96.2158%] [G loss: 4.085164]\n",
            "0.6568448254128325 0.6583823529411764\n",
            "106 [D loss: 0.089771, acc.: 96.0205%] [G loss: 4.250759]\n",
            "0.6568448254128325 0.6583823529411764\n",
            "107 [D loss: 0.095324, acc.: 95.9351%] [G loss: 4.125203]\n",
            "0.6568448254128325 0.6583823529411764\n",
            "108 [D loss: 0.089131, acc.: 95.9961%] [G loss: 4.378640]\n",
            "0.6568448254128325 0.6583823529411764\n",
            "109 [D loss: 0.095918, acc.: 95.9961%] [G loss: 4.163900]\n",
            "0.6568448254128325 0.6583823529411764\n",
            "110 [D loss: 0.086773, acc.: 96.1792%] [G loss: 4.608970]\n",
            "0.6568448254128325 0.6583823529411764\n",
            "111 [D loss: 0.090085, acc.: 96.1548%] [G loss: 4.193970]\n",
            "0.6568448254128325 0.6583823529411764\n",
            "112 [D loss: 0.089544, acc.: 95.9106%] [G loss: 4.033053]\n",
            "0.6568448254128325 0.6583823529411764\n",
            "113 [D loss: 0.095621, acc.: 95.6909%] [G loss: 4.374466]\n",
            "0.6568448254128325 0.6583823529411764\n",
            "114 [D loss: 0.086744, acc.: 96.2769%] [G loss: 4.461183]\n",
            "0.6568448254128325 0.6583823529411764\n",
            "115 [D loss: 0.093099, acc.: 96.0083%] [G loss: 4.356842]\n",
            "0.6568448254128325 0.6583823529411764\n",
            "116 [D loss: 0.084343, acc.: 96.6064%] [G loss: 4.413743]\n",
            "0.6568448254128325 0.6583823529411764\n",
            "117 [D loss: 0.090838, acc.: 96.0449%] [G loss: 4.524134]\n",
            "0.6568448254128325 0.6583823529411764\n",
            "118 [D loss: 0.096219, acc.: 95.8130%] [G loss: 4.270024]\n",
            "0.6568448254128325 0.6583823529411764\n",
            "119 [D loss: 0.086311, acc.: 96.1182%] [G loss: 4.241720]\n",
            "0.6568448254128325 0.6583823529411764\n",
            "120 [D loss: 0.082480, acc.: 96.5454%] [G loss: 4.395162]\n",
            "0.6568448254128325 0.6583823529411764\n",
            "121 [D loss: 0.087440, acc.: 96.2769%] [G loss: 4.482706]\n",
            "0.6568448254128325 0.6583823529411764\n",
            "122 [D loss: 0.091211, acc.: 96.0449%] [G loss: 4.299043]\n",
            "0.6568448254128325 0.6583823529411764\n",
            "123 [D loss: 0.092374, acc.: 95.8252%] [G loss: 4.247725]\n",
            "0.6568448254128325 0.6583823529411764\n",
            "124 [D loss: 0.093440, acc.: 95.8374%] [G loss: 4.589417]\n",
            "0.6568448254128325 0.6583823529411764\n",
            "125 [D loss: 0.091270, acc.: 96.1304%] [G loss: 4.576042]\n",
            "0.6568448254128325 0.6583823529411764\n",
            "126 [D loss: 0.092697, acc.: 95.7642%] [G loss: 4.643795]\n",
            "0.6568448254128325 0.6583823529411764\n",
            "127 [D loss: 0.087459, acc.: 96.1060%] [G loss: 4.801466]\n",
            "0.6568448254128325 0.6583823529411764\n",
            "128 [D loss: 0.091327, acc.: 96.0205%] [G loss: 4.403059]\n",
            "0.6568448254128325 0.6583823529411764\n",
            "129 [D loss: 0.088775, acc.: 96.1182%] [G loss: 4.877906]\n",
            "0.6568448254128325 0.6583823529411764\n",
            "130 [D loss: 0.087636, acc.: 96.1792%] [G loss: 4.693658]\n",
            "0.6568448254128325 0.6583823529411764\n",
            "131 [D loss: 0.093694, acc.: 95.9839%] [G loss: 4.961149]\n",
            "0.6568448254128325 0.6583823529411764\n",
            "132 [D loss: 0.085786, acc.: 96.3013%] [G loss: 5.100176]\n",
            "0.6568448254128325 0.6583823529411764\n",
            "133 [D loss: 0.100557, acc.: 95.6787%] [G loss: 4.840249]\n",
            "0.6568448254128325 0.6583823529411764\n",
            "134 [D loss: 0.092177, acc.: 95.9961%] [G loss: 4.960397]\n",
            "0.6568448254128325 0.6583088235294118\n",
            "135 [D loss: 0.089104, acc.: 96.0571%] [G loss: 5.004936]\n",
            "0.6568448254128325 0.6583823529411764\n",
            "136 [D loss: 0.095282, acc.: 95.6543%] [G loss: 4.704324]\n",
            "0.6568763393419892 0.6584558823529412\n",
            "137 [D loss: 0.089137, acc.: 96.0327%] [G loss: 4.828541]\n",
            "0.6570023950586159 0.6585294117647059\n",
            "138 [D loss: 0.084974, acc.: 96.3135%] [G loss: 4.853562]\n",
            "0.6607840665574184 0.6619117647058823\n",
            "139 [D loss: 0.396348, acc.: 81.5308%] [G loss: 11.868048]\n",
            "0.6614143451405521 0.6624264705882353\n",
            "140 [D loss: 0.164520, acc.: 92.0410%] [G loss: 11.745702]\n",
            "0.6616979705029623 0.6625735294117647\n",
            "141 [D loss: 0.117598, acc.: 95.5078%] [G loss: 12.451019]\n",
            "0.6616664565738056 0.6629411764705883\n",
            "142 [D loss: 0.127437, acc.: 95.0928%] [G loss: 12.770456]\n",
            "0.6608155804865751 0.6618382352941177\n",
            "143 [D loss: 0.140272, acc.: 95.1782%] [G loss: 13.388004]\n",
            "0.6605634690533215 0.6613970588235294\n",
            "144 [D loss: 0.220955, acc.: 92.8467%] [G loss: 10.828472]\n",
            "0.6602798436909114 0.66125\n",
            "145 [D loss: 0.245943, acc.: 92.2119%] [G loss: 9.693927]\n",
            "0.659113828312114 0.6598529411764706\n",
            "146 [D loss: 0.317485, acc.: 88.1226%] [G loss: 10.407142]\n",
            "0.6558678936089751 0.6564705882352941\n",
            "147 [D loss: 0.272826, acc.: 89.9780%] [G loss: 6.249873]\n",
            "0.6546073364427076 0.6552205882352942\n",
            "148 [D loss: 0.202867, acc.: 93.8843%] [G loss: 4.753001]\n",
            "0.6549224757342745 0.6556617647058823\n",
            "149 [D loss: 0.166953, acc.: 93.8110%] [G loss: 3.395504]\n",
            "0.6552061010966848 0.6566176470588235\n",
            "150 [D loss: 0.200200, acc.: 93.9819%] [G loss: 4.499899]\n",
            "0.6555527543174083 0.6569117647058823\n",
            "151 [D loss: 0.154967, acc.: 94.5801%] [G loss: 4.133760]\n",
            "0.6553006428841548 0.6567647058823529\n",
            "152 [D loss: 0.156625, acc.: 94.9341%] [G loss: 4.422710]\n",
            "0.6552376150258414 0.6566176470588235\n",
            "153 [D loss: 0.144736, acc.: 94.8853%] [G loss: 3.962565]\n",
            "0.655080045380058 0.6566176470588235\n",
            "154 [D loss: 0.125491, acc.: 95.4956%] [G loss: 4.070927]\n",
            "0.6550170175217446 0.6563970588235294\n",
            "155 [D loss: 0.124717, acc.: 95.1660%] [G loss: 3.985420]\n",
            "0.6550170175217446 0.6563235294117648\n",
            "156 [D loss: 0.123870, acc.: 95.0562%] [G loss: 3.899825]\n",
            "0.6550170175217446 0.65625\n",
            "157 [D loss: 0.115524, acc.: 95.3125%] [G loss: 4.008125]\n",
            "0.6549539896634312 0.6563235294117648\n",
            "158 [D loss: 0.115664, acc.: 95.2026%] [G loss: 3.866107]\n",
            "0.6549539896634312 0.65625\n",
            "159 [D loss: 0.113239, acc.: 95.3735%] [G loss: 4.147535]\n",
            "0.6549539896634312 0.6563235294117648\n",
            "160 [D loss: 0.102429, acc.: 95.7520%] [G loss: 3.676533]\n",
            "0.6549224757342745 0.6561029411764706\n",
            "161 [D loss: 0.110974, acc.: 95.2515%] [G loss: 4.169882]\n",
            "0.6550170175217446 0.65625\n",
            "162 [D loss: 0.101890, acc.: 95.8008%] [G loss: 3.999888]\n",
            "0.6549855035925879 0.6563235294117648\n",
            "163 [D loss: 0.114727, acc.: 95.4712%] [G loss: 3.943504]\n",
            "0.6549539896634312 0.65625\n",
            "164 [D loss: 0.109628, acc.: 95.4712%] [G loss: 4.015519]\n",
            "0.6549224757342745 0.6561764705882352\n",
            "165 [D loss: 0.108254, acc.: 95.6421%] [G loss: 4.038557]\n",
            "0.6548279339468045 0.6561029411764706\n",
            "166 [D loss: 0.103835, acc.: 95.7886%] [G loss: 4.131111]\n",
            "0.6549224757342745 0.6561764705882352\n",
            "167 [D loss: 0.100099, acc.: 95.7520%] [G loss: 4.116239]\n",
            "0.6550170175217446 0.6561029411764706\n",
            "168 [D loss: 0.118726, acc.: 95.5811%] [G loss: 3.248417]\n",
            "0.6555212403882517 0.6569852941176471\n",
            "169 [D loss: 0.113674, acc.: 95.6787%] [G loss: 3.414767]\n",
            "0.6562145468296987 0.6579411764705883\n",
            "170 [D loss: 0.103521, acc.: 95.7764%] [G loss: 3.549275]\n",
            "0.6564351443337956 0.6583088235294118\n",
            "171 [D loss: 0.103591, acc.: 96.0327%] [G loss: 3.562562]\n",
            "0.6563406025463254 0.6583088235294118\n",
            "172 [D loss: 0.105224, acc.: 95.7031%] [G loss: 3.545828]\n",
            "0.6572229925627128 0.6593382352941176\n",
            "173 [D loss: 0.097913, acc.: 96.0693%] [G loss: 3.668763]\n",
            "0.6572545064918695 0.6593382352941176\n",
            "174 [D loss: 0.103432, acc.: 95.7886%] [G loss: 3.699672]\n",
            "0.6572545064918695 0.6594117647058824\n",
            "175 [D loss: 0.100530, acc.: 95.9839%] [G loss: 3.595278]\n",
            "0.6572229925627128 0.6594117647058824\n",
            "176 [D loss: 0.104542, acc.: 95.7031%] [G loss: 3.487922]\n",
            "0.6572229925627128 0.6594117647058824\n",
            "177 [D loss: 0.114594, acc.: 95.2148%] [G loss: 3.752984]\n",
            "0.6572229925627128 0.6594852941176471\n",
            "178 [D loss: 0.101226, acc.: 95.7275%] [G loss: 3.574534]\n",
            "0.6636833480398336 0.665514705882353\n",
            "179 [D loss: 0.273615, acc.: 90.4297%] [G loss: 10.260442]\n",
            "0.6675595613261062 0.6704411764705882\n",
            "180 [D loss: 0.229049, acc.: 90.5396%] [G loss: 11.132240]\n",
            "0.6665196016639354 0.6681617647058824\n",
            "181 [D loss: 0.201867, acc.: 92.4805%] [G loss: 12.315809]\n",
            "0.6642190848354973 0.6661029411764706\n",
            "182 [D loss: 0.164914, acc.: 93.6768%] [G loss: 12.155967]\n",
            "0.663746375898147 0.6656617647058823\n",
            "183 [D loss: 0.130847, acc.: 95.0317%] [G loss: 11.673681]\n",
            "0.6635888062523635 0.6653676470588236\n",
            "184 [D loss: 0.124773, acc.: 95.5322%] [G loss: 11.711311]\n",
            "0.6635888062523635 0.665\n",
            "185 [D loss: 0.118068, acc.: 95.5933%] [G loss: 11.968316]\n",
            "0.6635257783940501 0.665\n",
            "186 [D loss: 0.125496, acc.: 95.1538%] [G loss: 10.827814]\n",
            "0.6635257783940501 0.665\n",
            "187 [D loss: 0.117462, acc.: 95.4590%] [G loss: 10.526124]\n",
            "0.6635572923232068 0.6649264705882353\n",
            "188 [D loss: 0.124339, acc.: 95.1294%] [G loss: 10.175898]\n",
            "0.6634627505357368 0.665\n",
            "189 [D loss: 0.110584, acc.: 95.7397%] [G loss: 10.182974]\n",
            "0.6632106391024833 0.6647058823529411\n",
            "190 [D loss: 0.120627, acc.: 95.0684%] [G loss: 9.625757]\n",
            "0.6628009580234464 0.6646323529411765\n",
            "191 [D loss: 0.119459, acc.: 95.4224%] [G loss: 9.402059]\n",
            "0.6624858187318795 0.6639705882352941\n",
            "192 [D loss: 0.129544, acc.: 95.2515%] [G loss: 9.909248]\n",
            "0.6590823143829573 0.66125\n",
            "193 [D loss: 0.136317, acc.: 94.8608%] [G loss: 8.991911]\n",
            "0.6577902432875331 0.6598529411764706\n",
            "194 [D loss: 0.118933, acc.: 95.3613%] [G loss: 8.354534]\n",
            "0.6573805622084962 0.6596323529411765\n",
            "195 [D loss: 0.119937, acc.: 95.7031%] [G loss: 6.551990]\n",
            "0.6574120761376528 0.6596323529411765\n",
            "196 [D loss: 0.130055, acc.: 95.5444%] [G loss: 3.883364]\n",
            "0.6574435900668095 0.6597794117647059\n",
            "197 [D loss: 0.158428, acc.: 95.5200%] [G loss: 3.818869]\n",
            "0.6575066179251229 0.6597794117647059\n",
            "198 [D loss: 0.148357, acc.: 95.5444%] [G loss: 3.804048]\n",
            "0.6573805622084962 0.6596323529411765\n",
            "199 [D loss: 0.142243, acc.: 95.7520%] [G loss: 3.874677]\n",
            "0.6573490482793395 0.6595588235294118\n",
            "200 [D loss: 0.162743, acc.: 95.1782%] [G loss: 3.586573]\n",
            "0.6573175343501828 0.6594117647058824\n",
            "201 [D loss: 0.125526, acc.: 95.4834%] [G loss: 3.501010]\n",
            "0.6572860204210261 0.6594852941176471\n",
            "202 [D loss: 0.149402, acc.: 94.9585%] [G loss: 3.518744]\n",
            "0.6573175343501828 0.6595588235294118\n",
            "203 [D loss: 0.127119, acc.: 95.5078%] [G loss: 3.441548]\n",
            "0.6573175343501828 0.6594852941176471\n",
            "204 [D loss: 0.134943, acc.: 95.3613%] [G loss: 3.289780]\n",
            "0.6572545064918695 0.6594852941176471\n",
            "205 [D loss: 0.121773, acc.: 95.4468%] [G loss: 3.372820]\n",
            "0.6573175343501828 0.6594852941176471\n",
            "206 [D loss: 0.129031, acc.: 95.3979%] [G loss: 3.234914]\n",
            "0.6572229925627128 0.6595588235294118\n",
            "207 [D loss: 0.114216, acc.: 95.5078%] [G loss: 3.065035]\n",
            "0.6572545064918695 0.6594117647058824\n",
            "208 [D loss: 0.126444, acc.: 95.0562%] [G loss: 3.305594]\n",
            "0.6573175343501828 0.6594852941176471\n",
            "209 [D loss: 0.123225, acc.: 95.7397%] [G loss: 3.005744]\n",
            "0.6572229925627128 0.6594852941176471\n",
            "210 [D loss: 0.111083, acc.: 96.0205%] [G loss: 3.167079]\n",
            "0.6573175343501828 0.6594117647058824\n",
            "211 [D loss: 0.117052, acc.: 95.9229%] [G loss: 3.224643]\n",
            "0.6573175343501828 0.6594852941176471\n",
            "212 [D loss: 0.112683, acc.: 95.6421%] [G loss: 3.092083]\n",
            "0.6573175343501828 0.6594117647058824\n",
            "213 [D loss: 0.122003, acc.: 95.3613%] [G loss: 3.201941]\n",
            "0.6573175343501828 0.6593382352941176\n",
            "214 [D loss: 0.108913, acc.: 95.5688%] [G loss: 3.084019]\n",
            "0.6573175343501828 0.6593382352941176\n",
            "215 [D loss: 0.112618, acc.: 95.5566%] [G loss: 3.117304]\n",
            "0.6572229925627128 0.6594117647058824\n",
            "216 [D loss: 0.107358, acc.: 95.9229%] [G loss: 3.278666]\n",
            "0.6572229925627128 0.6594117647058824\n",
            "217 [D loss: 0.112091, acc.: 95.7031%] [G loss: 3.192626]\n",
            "0.6572860204210261 0.6594852941176471\n",
            "218 [D loss: 0.114040, acc.: 95.3003%] [G loss: 3.104177]\n",
            "0.6573175343501828 0.6594852941176471\n",
            "219 [D loss: 0.114477, acc.: 95.5688%] [G loss: 3.245064]\n",
            "0.6572860204210261 0.6594117647058824\n",
            "220 [D loss: 0.106782, acc.: 95.6665%] [G loss: 3.185364]\n",
            "0.6573490482793395 0.6593382352941176\n",
            "221 [D loss: 0.113281, acc.: 95.5933%] [G loss: 3.128611]\n",
            "0.6572860204210261 0.6594852941176471\n",
            "222 [D loss: 0.100416, acc.: 95.9106%] [G loss: 3.077902]\n",
            "0.6572545064918695 0.6594117647058824\n",
            "223 [D loss: 0.111110, acc.: 95.7031%] [G loss: 3.096011]\n",
            "0.6573175343501828 0.6594852941176471\n",
            "224 [D loss: 0.107148, acc.: 95.4224%] [G loss: 3.203203]\n",
            "0.6572545064918695 0.6594117647058824\n",
            "225 [D loss: 0.110434, acc.: 95.6177%] [G loss: 3.136950]\n",
            "0.6572545064918695 0.6594852941176471\n",
            "226 [D loss: 0.107386, acc.: 95.6909%] [G loss: 3.223523]\n",
            "0.6572860204210261 0.6595588235294118\n",
            "227 [D loss: 0.112652, acc.: 95.3003%] [G loss: 3.224789]\n",
            "0.6572545064918695 0.6594852941176471\n",
            "228 [D loss: 0.102900, acc.: 95.7275%] [G loss: 3.076722]\n",
            "0.6573805622084962 0.6594852941176471\n",
            "229 [D loss: 0.101167, acc.: 95.9717%] [G loss: 3.151564]\n",
            "0.6572860204210261 0.6595588235294118\n",
            "230 [D loss: 0.107689, acc.: 95.5200%] [G loss: 3.358565]\n",
            "0.6572229925627128 0.6594852941176471\n",
            "231 [D loss: 0.106579, acc.: 95.6543%] [G loss: 3.097919]\n",
            "0.6572545064918695 0.6595588235294118\n",
            "232 [D loss: 0.106971, acc.: 95.5200%] [G loss: 3.271724]\n",
            "0.6572860204210261 0.6594852941176471\n",
            "233 [D loss: 0.102990, acc.: 95.6665%] [G loss: 3.307987]\n",
            "0.6572229925627128 0.6594117647058824\n",
            "234 [D loss: 0.108022, acc.: 95.6055%] [G loss: 3.094297]\n",
            "0.6572860204210261 0.6594852941176471\n",
            "235 [D loss: 0.104977, acc.: 95.8130%] [G loss: 3.233890]\n",
            "0.6573175343501828 0.6594117647058824\n",
            "236 [D loss: 0.100047, acc.: 95.7886%] [G loss: 3.223990]\n",
            "0.6572229925627128 0.6593382352941176\n",
            "237 [D loss: 0.098715, acc.: 95.8862%] [G loss: 3.393322]\n",
            "0.6572860204210261 0.6593382352941176\n",
            "238 [D loss: 0.102127, acc.: 95.7886%] [G loss: 3.170908]\n",
            "0.6572545064918695 0.6594117647058824\n",
            "239 [D loss: 0.107293, acc.: 95.3491%] [G loss: 3.057432]\n",
            "0.657191478633556 0.6595588235294118\n",
            "240 [D loss: 0.103213, acc.: 95.6787%] [G loss: 3.246977]\n",
            "0.6572545064918695 0.6594117647058824\n",
            "241 [D loss: 0.113234, acc.: 95.4224%] [G loss: 3.423765]\n",
            "0.6572860204210261 0.6595588235294118\n",
            "242 [D loss: 0.107759, acc.: 95.6177%] [G loss: 3.495678]\n",
            "0.6573805622084962 0.6595588235294118\n",
            "243 [D loss: 0.101935, acc.: 95.8984%] [G loss: 3.384829]\n",
            "0.6573805622084962 0.6595588235294118\n",
            "244 [D loss: 0.108773, acc.: 95.3125%] [G loss: 3.555314]\n",
            "0.6574120761376528 0.6594117647058824\n",
            "245 [D loss: 0.102685, acc.: 95.8374%] [G loss: 3.376732]\n",
            "0.6572545064918695 0.6594852941176471\n",
            "246 [D loss: 0.100070, acc.: 95.6543%] [G loss: 3.390604]\n",
            "0.6573805622084962 0.6595588235294118\n",
            "247 [D loss: 0.102692, acc.: 95.7153%] [G loss: 3.459609]\n",
            "0.6575066179251229 0.6597794117647059\n",
            "248 [D loss: 0.104690, acc.: 95.5444%] [G loss: 3.462247]\n",
            "0.6575381318542796 0.6598529411764706\n",
            "249 [D loss: 0.104417, acc.: 95.6543%] [G loss: 3.516999]\n",
            "0.6575066179251229 0.6598529411764706\n",
            "250 [D loss: 0.100240, acc.: 95.6421%] [G loss: 3.476700]\n",
            "0.6575066179251229 0.6599264705882353\n",
            "251 [D loss: 0.096683, acc.: 95.9106%] [G loss: 3.361897]\n",
            "0.6575066179251229 0.6598529411764706\n",
            "252 [D loss: 0.101767, acc.: 95.5688%] [G loss: 3.533524]\n",
            "0.6575381318542796 0.66\n",
            "253 [D loss: 0.104188, acc.: 95.6177%] [G loss: 3.888418]\n",
            "0.6575381318542796 0.66\n",
            "254 [D loss: 0.105448, acc.: 95.5444%] [G loss: 3.584857]\n",
            "0.6575066179251229 0.6599264705882353\n",
            "255 [D loss: 0.106055, acc.: 95.6177%] [G loss: 3.866453]\n",
            "0.6575381318542796 0.66\n",
            "256 [D loss: 0.100336, acc.: 95.9839%] [G loss: 3.548571]\n",
            "0.6575381318542796 0.6597794117647059\n",
            "257 [D loss: 0.107854, acc.: 95.7642%] [G loss: 3.898944]\n",
            "0.6576326736417496 0.6598529411764706\n",
            "258 [D loss: 0.098606, acc.: 96.0083%] [G loss: 3.616987]\n",
            "0.6575066179251229 0.66\n",
            "259 [D loss: 0.098471, acc.: 95.9839%] [G loss: 3.778352]\n",
            "0.6574751039959662 0.6600735294117647\n",
            "260 [D loss: 0.102392, acc.: 95.8618%] [G loss: 3.777480]\n",
            "0.6574751039959662 0.6598529411764706\n",
            "261 [D loss: 0.107495, acc.: 95.5444%] [G loss: 3.671461]\n",
            "0.6575066179251229 0.6598529411764706\n",
            "262 [D loss: 0.101800, acc.: 95.6299%] [G loss: 3.659667]\n",
            "0.6575381318542796 0.6597794117647059\n",
            "263 [D loss: 0.106569, acc.: 95.6787%] [G loss: 3.771821]\n",
            "0.6574435900668095 0.6597794117647059\n",
            "264 [D loss: 0.102259, acc.: 95.7642%] [G loss: 3.715978]\n",
            "0.6574751039959662 0.66\n",
            "265 [D loss: 0.109279, acc.: 95.3003%] [G loss: 3.764363]\n",
            "0.6575381318542796 0.6597794117647059\n",
            "266 [D loss: 0.093182, acc.: 96.1426%] [G loss: 3.628017]\n",
            "0.6574435900668095 0.6597058823529411\n",
            "267 [D loss: 0.102622, acc.: 96.0449%] [G loss: 4.003913]\n",
            "0.6574120761376528 0.6597058823529411\n",
            "268 [D loss: 0.107944, acc.: 95.6787%] [G loss: 4.052239]\n",
            "0.6574435900668095 0.6597794117647059\n",
            "269 [D loss: 0.106926, acc.: 95.6909%] [G loss: 3.925126]\n",
            "0.6574435900668095 0.6597058823529411\n",
            "270 [D loss: 0.101613, acc.: 95.7642%] [G loss: 3.954782]\n",
            "0.6573805622084962 0.6597058823529411\n",
            "271 [D loss: 0.114260, acc.: 95.5811%] [G loss: 3.814560]\n",
            "0.6573490482793395 0.6597794117647059\n",
            "272 [D loss: 0.108759, acc.: 95.6665%] [G loss: 3.115261]\n",
            "0.6574435900668095 0.6597058823529411\n",
            "273 [D loss: 0.099088, acc.: 96.1670%] [G loss: 3.417842]\n",
            "0.6575066179251229 0.6597794117647059\n",
            "274 [D loss: 0.105478, acc.: 95.8374%] [G loss: 2.762181]\n",
            "0.6575696457834362 0.6597794117647059\n",
            "275 [D loss: 0.103657, acc.: 95.7520%] [G loss: 2.778174]\n",
            "0.6575381318542796 0.6597058823529411\n",
            "276 [D loss: 0.107978, acc.: 95.7886%] [G loss: 2.628380]\n",
            "0.6575696457834362 0.6598529411764706\n",
            "277 [D loss: 0.116137, acc.: 95.2515%] [G loss: 2.710996]\n",
            "0.6576326736417496 0.6600735294117647\n",
            "278 [D loss: 0.101855, acc.: 96.3135%] [G loss: 3.134947]\n",
            "0.6576011597125929 0.6597794117647059\n",
            "279 [D loss: 0.107383, acc.: 95.6055%] [G loss: 2.877846]\n",
            "0.6579793268624732 0.6601470588235294\n",
            "280 [D loss: 0.106851, acc.: 95.4224%] [G loss: 3.133835]\n",
            "0.6579162990041598 0.6600735294117647\n",
            "281 [D loss: 0.108769, acc.: 95.5688%] [G loss: 3.132090]\n",
            "0.6578217572166898 0.6604411764705882\n",
            "282 [D loss: 0.116188, acc.: 95.3247%] [G loss: 3.188801]\n",
            "0.6579162990041598 0.6603676470588236\n",
            "283 [D loss: 0.115710, acc.: 95.4956%] [G loss: 3.437269]\n",
            "0.6579793268624732 0.6599264705882353\n",
            "284 [D loss: 0.122538, acc.: 94.9829%] [G loss: 3.373849]\n",
            "0.6579162990041598 0.6602941176470588\n",
            "285 [D loss: 0.101441, acc.: 95.6421%] [G loss: 3.392810]\n",
            "0.6578847850750031 0.6602205882352942\n",
            "286 [D loss: 0.117276, acc.: 95.7520%] [G loss: 3.620167]\n",
            "0.6580108407916299 0.6604411764705882\n",
            "287 [D loss: 0.119681, acc.: 95.2759%] [G loss: 3.817690]\n",
            "0.6580738686499433 0.6606617647058823\n",
            "288 [D loss: 0.109500, acc.: 95.7031%] [G loss: 3.387243]\n",
            "0.6581368965082567 0.6605882352941177\n",
            "289 [D loss: 0.114001, acc.: 95.7397%] [G loss: 3.511750]\n",
            "0.6579793268624732 0.6602205882352942\n",
            "290 [D loss: 0.112713, acc.: 95.5200%] [G loss: 3.585578]\n",
            "0.6579162990041598 0.6604411764705882\n",
            "291 [D loss: 0.112476, acc.: 95.5078%] [G loss: 3.538105]\n",
            "0.65819992436657 0.6603676470588236\n",
            "292 [D loss: 0.117388, acc.: 95.2515%] [G loss: 3.721386]\n",
            "0.6580423547207865 0.6600735294117647\n",
            "293 [D loss: 0.115544, acc.: 95.3247%] [G loss: 3.489154]\n",
            "0.6581684104374134 0.6603676470588236\n",
            "294 [D loss: 0.105352, acc.: 95.9106%] [G loss: 3.817712]\n",
            "0.6580738686499433 0.6607352941176471\n",
            "295 [D loss: 0.115055, acc.: 95.4102%] [G loss: 3.459239]\n",
            "0.6581053825791 0.6606617647058823\n",
            "296 [D loss: 0.105358, acc.: 95.8130%] [G loss: 3.006675]\n",
            "0.6581684104374134 0.6608088235294117\n",
            "297 [D loss: 0.121606, acc.: 95.3369%] [G loss: 3.085768]\n",
            "0.6581053825791 0.660514705882353\n",
            "298 [D loss: 0.125937, acc.: 95.3979%] [G loss: 2.980137]\n",
            "0.6582629522248834 0.6606617647058823\n",
            "299 [D loss: 0.113394, acc.: 95.4834%] [G loss: 3.190718]\n",
            "0.6582944661540401 0.6605882352941177\n",
            "300 [D loss: 0.112566, acc.: 95.4224%] [G loss: 2.827464]\n",
            "0.6582629522248834 0.6606617647058823\n",
            "301 [D loss: 0.122340, acc.: 95.0928%] [G loss: 2.888269]\n",
            "0.6582629522248834 0.6607352941176471\n",
            "302 [D loss: 0.110033, acc.: 95.6909%] [G loss: 3.072593]\n",
            "0.6582314382957267 0.6602941176470588\n",
            "303 [D loss: 0.115326, acc.: 95.8008%] [G loss: 2.862243]\n",
            "0.6581684104374134 0.6603676470588236\n",
            "304 [D loss: 0.110373, acc.: 95.7886%] [G loss: 2.878343]\n",
            "0.6580108407916299 0.660514705882353\n",
            "305 [D loss: 0.107206, acc.: 95.8252%] [G loss: 3.110976]\n",
            "0.6581684104374134 0.660514705882353\n",
            "306 [D loss: 0.106953, acc.: 95.6909%] [G loss: 3.090993]\n",
            "0.6580423547207865 0.6605882352941177\n",
            "307 [D loss: 0.110072, acc.: 95.6543%] [G loss: 3.084489]\n",
            "0.6583574940123534 0.6607352941176471\n",
            "308 [D loss: 0.111857, acc.: 95.6055%] [G loss: 3.269356]\n",
            "0.6582944661540401 0.6604411764705882\n",
            "309 [D loss: 0.106592, acc.: 95.5933%] [G loss: 3.210684]\n",
            "0.6581684104374134 0.6602941176470588\n",
            "310 [D loss: 0.109570, acc.: 95.6909%] [G loss: 3.011997]\n",
            "0.6584835497289802 0.6611764705882353\n",
            "311 [D loss: 0.108034, acc.: 95.8130%] [G loss: 3.111093]\n",
            "0.6587356611622337 0.6608823529411765\n",
            "312 [D loss: 0.121293, acc.: 95.3613%] [G loss: 2.901807]\n",
            "0.6586411193747637 0.6613970588235294\n",
            "313 [D loss: 0.112339, acc.: 95.6299%] [G loss: 3.027511]\n",
            "0.6589247447371739 0.66125\n",
            "314 [D loss: 0.109669, acc.: 95.5811%] [G loss: 2.981482]\n",
            "0.658609605445607 0.6616176470588235\n",
            "315 [D loss: 0.119769, acc.: 95.5811%] [G loss: 3.110981]\n",
            "0.6588302029497037 0.6617647058823529\n",
            "316 [D loss: 0.112885, acc.: 95.4224%] [G loss: 3.387192]\n",
            "0.6588932308080171 0.6618382352941177\n",
            "317 [D loss: 0.119158, acc.: 95.4346%] [G loss: 3.538214]\n",
            "0.6586726333039203 0.6616911764705883\n",
            "318 [D loss: 0.118800, acc.: 95.4224%] [G loss: 3.683032]\n",
            "0.6590823143829573 0.6619117647058823\n",
            "319 [D loss: 0.112812, acc.: 95.6055%] [G loss: 3.574505]\n",
            "0.6587671750913904 0.6616176470588235\n",
            "320 [D loss: 0.117361, acc.: 95.6299%] [G loss: 3.948564]\n",
            "0.659208370099584 0.6616911764705883\n",
            "321 [D loss: 0.127302, acc.: 95.1294%] [G loss: 2.855405]\n",
            "0.6591453422412706 0.6621323529411764\n",
            "322 [D loss: 0.121559, acc.: 95.3491%] [G loss: 3.014458]\n",
            "0.659302911887054 0.6621323529411764\n",
            "323 [D loss: 0.131230, acc.: 95.0806%] [G loss: 3.146822]\n",
            "0.6594919954619942 0.6617647058823529\n",
            "324 [D loss: 0.124747, acc.: 95.0928%] [G loss: 3.237625]\n",
            "0.659712592966091 0.6617647058823529\n",
            "325 [D loss: 0.125284, acc.: 95.3613%] [G loss: 3.342410]\n",
            "0.6599647043993445 0.6624264705882353\n",
            "326 [D loss: 0.124116, acc.: 94.8853%] [G loss: 3.167769]\n",
            "0.6599962183285012 0.6629411764705883\n",
            "327 [D loss: 0.134246, acc.: 94.9951%] [G loss: 3.530950]\n",
            "0.6603113576200681 0.6624264705882353\n",
            "328 [D loss: 0.121513, acc.: 95.0684%] [G loss: 3.560810]\n",
            "0.6601853019034413 0.6625735294117647\n",
            "329 [D loss: 0.122351, acc.: 95.2393%] [G loss: 3.290243]\n",
            "0.660626496911635 0.6627941176470589\n",
            "330 [D loss: 0.125699, acc.: 94.8853%] [G loss: 3.562330]\n",
            "0.6604689272658515 0.6627205882352941\n",
            "331 [D loss: 0.115441, acc.: 95.6299%] [G loss: 3.281493]\n",
            "0.6604374133366948 0.6630147058823529\n",
            "332 [D loss: 0.125637, acc.: 94.9585%] [G loss: 3.177173]\n",
            "0.6602798436909114 0.6629411764705883\n",
            "333 [D loss: 0.120052, acc.: 95.3735%] [G loss: 3.575075]\n",
            "0.6600907601159712 0.6626470588235294\n",
            "334 [D loss: 0.119164, acc.: 95.6177%] [G loss: 3.080705]\n",
            "0.6601537879742846 0.6621323529411764\n",
            "335 [D loss: 0.120206, acc.: 95.5078%] [G loss: 3.397116]\n",
            "0.6601853019034413 0.6628676470588235\n",
            "336 [D loss: 0.121227, acc.: 95.1660%] [G loss: 3.239374]\n",
            "0.6599331904701878 0.6626470588235294\n",
            "337 [D loss: 0.137699, acc.: 95.0439%] [G loss: 3.294650]\n",
            "0.6596180511786209 0.6622058823529412\n",
            "338 [D loss: 0.118126, acc.: 95.4468%] [G loss: 3.321879]\n",
            "0.6593344258162107 0.6616176470588235\n",
            "339 [D loss: 0.118778, acc.: 95.1782%] [G loss: 3.312376]\n",
            "0.6592398840287407 0.6613970588235294\n",
            "340 [D loss: 0.121475, acc.: 95.3003%] [G loss: 2.928392]\n",
            "0.6589877725954872 0.6614705882352941\n",
            "341 [D loss: 0.141099, acc.: 95.3125%] [G loss: 2.830399]\n",
            "0.6586411193747637 0.6610294117647059\n",
            "342 [D loss: 0.119530, acc.: 95.5078%] [G loss: 2.854676]\n",
            "0.6591453422412706 0.6616176470588235\n",
            "343 [D loss: 0.123794, acc.: 95.3003%] [G loss: 2.924088]\n",
            "0.659302911887054 0.66125\n",
            "344 [D loss: 0.126997, acc.: 95.1904%] [G loss: 3.194012]\n",
            "0.6590508004538006 0.6609558823529412\n",
            "345 [D loss: 0.125530, acc.: 95.2881%] [G loss: 3.141930]\n",
            "0.6587356611622337 0.6607352941176471\n",
            "346 [D loss: 0.117929, acc.: 95.4956%] [G loss: 3.133690]\n",
            "0.658515063658137 0.6603676470588236\n",
            "347 [D loss: 0.118976, acc.: 95.3857%] [G loss: 3.127738]\n",
            "0.658515063658137 0.6602941176470588\n",
            "348 [D loss: 0.108941, acc.: 95.7153%] [G loss: 3.462795]\n",
            "0.6579162990041598 0.66\n",
            "349 [D loss: 0.122545, acc.: 95.1294%] [G loss: 3.218225]\n",
            "0.6577587293583764 0.6600735294117647\n",
            "350 [D loss: 0.103726, acc.: 96.0449%] [G loss: 3.449603]\n",
            "0.6578532711458465 0.6597058823529411\n",
            "351 [D loss: 0.103140, acc.: 95.9839%] [G loss: 3.765118]\n",
            "0.6577902432875331 0.6599264705882353\n",
            "352 [D loss: 0.114682, acc.: 95.8496%] [G loss: 3.915361]\n",
            "0.6577902432875331 0.6597794117647059\n",
            "353 [D loss: 0.096885, acc.: 95.9106%] [G loss: 4.046623]\n",
            "0.6578217572166898 0.6597058823529411\n",
            "354 [D loss: 0.106598, acc.: 95.8008%] [G loss: 3.799942]\n",
            "0.6578217572166898 0.6597794117647059\n",
            "355 [D loss: 0.099323, acc.: 96.0815%] [G loss: 4.145448]\n",
            "0.6577587293583764 0.6599264705882353\n",
            "356 [D loss: 0.110233, acc.: 95.4102%] [G loss: 4.162115]\n",
            "0.6577587293583764 0.6598529411764706\n",
            "357 [D loss: 0.102122, acc.: 95.6543%] [G loss: 4.321439]\n",
            "0.6578532711458465 0.66\n",
            "358 [D loss: 0.114945, acc.: 95.5688%] [G loss: 4.164841]\n",
            "0.6577272154292197 0.6599264705882353\n",
            "359 [D loss: 0.104209, acc.: 96.0327%] [G loss: 4.004580]\n",
            "0.6578532711458465 0.6600735294117647\n",
            "360 [D loss: 0.108665, acc.: 95.5322%] [G loss: 4.036614]\n",
            "0.6578217572166898 0.6597058823529411\n",
            "361 [D loss: 0.107837, acc.: 96.0205%] [G loss: 4.204374]\n",
            "0.6577272154292197 0.6597794117647059\n",
            "362 [D loss: 0.125932, acc.: 95.5200%] [G loss: 3.493924]\n",
            "0.6577272154292197 0.6597058823529411\n",
            "363 [D loss: 0.128397, acc.: 95.4590%] [G loss: 3.173332]\n",
            "0.6576957015000631 0.6597794117647059\n",
            "364 [D loss: 0.121632, acc.: 95.2881%] [G loss: 3.509411]\n",
            "0.6577587293583764 0.6598529411764706\n",
            "365 [D loss: 0.108578, acc.: 95.8740%] [G loss: 3.429087]\n",
            "0.6577902432875331 0.6598529411764706\n",
            "366 [D loss: 0.097553, acc.: 96.2646%] [G loss: 3.460433]\n",
            "0.6577272154292197 0.6597058823529411\n",
            "367 [D loss: 0.122961, acc.: 95.5933%] [G loss: 3.682194]\n",
            "0.6577587293583764 0.6598529411764706\n",
            "368 [D loss: 0.113926, acc.: 95.6787%] [G loss: 3.667582]\n",
            "0.6577587293583764 0.6600735294117647\n",
            "369 [D loss: 0.115398, acc.: 95.4956%] [G loss: 3.780115]\n",
            "0.6578532711458465 0.6599264705882353\n",
            "370 [D loss: 0.113103, acc.: 95.6787%] [G loss: 3.996274]\n",
            "0.6579478129333165 0.66\n",
            "371 [D loss: 0.123204, acc.: 95.4712%] [G loss: 3.950047]\n",
            "0.6579478129333165 0.66\n",
            "372 [D loss: 0.111418, acc.: 95.6787%] [G loss: 4.403300]\n",
            "0.6577902432875331 0.6600735294117647\n",
            "373 [D loss: 0.113508, acc.: 95.3979%] [G loss: 4.046723]\n",
            "0.6579162990041598 0.6599264705882353\n",
            "374 [D loss: 0.112031, acc.: 95.5200%] [G loss: 4.017979]\n",
            "0.6578532711458465 0.66\n",
            "375 [D loss: 0.105103, acc.: 95.8618%] [G loss: 4.193156]\n",
            "0.6578217572166898 0.6598529411764706\n",
            "376 [D loss: 0.101122, acc.: 96.0083%] [G loss: 4.377601]\n",
            "0.6576641875709064 0.6599264705882353\n",
            "377 [D loss: 0.108891, acc.: 95.7153%] [G loss: 4.409782]\n",
            "0.6577587293583764 0.6599264705882353\n",
            "378 [D loss: 0.105555, acc.: 95.8374%] [G loss: 4.510931]\n",
            "0.6577272154292197 0.6597794117647059\n",
            "379 [D loss: 0.105819, acc.: 95.8252%] [G loss: 4.784677]\n",
            "0.6577272154292197 0.6597058823529411\n",
            "380 [D loss: 0.104544, acc.: 95.5200%] [G loss: 4.626043]\n",
            "0.6576957015000631 0.6597794117647059\n",
            "381 [D loss: 0.105965, acc.: 95.6665%] [G loss: 4.504121]\n",
            "0.6577272154292197 0.6598529411764706\n",
            "382 [D loss: 0.098633, acc.: 96.0205%] [G loss: 4.428838]\n",
            "0.6577587293583764 0.6597058823529411\n",
            "383 [D loss: 0.102674, acc.: 95.3979%] [G loss: 4.327357]\n",
            "0.6575381318542796 0.6596323529411765\n",
            "384 [D loss: 0.099971, acc.: 96.0938%] [G loss: 4.560297]\n",
            "0.6575066179251229 0.6596323529411765\n",
            "385 [D loss: 0.107452, acc.: 95.6299%] [G loss: 4.905228]\n",
            "0.6575066179251229 0.6597058823529411\n",
            "386 [D loss: 0.098089, acc.: 95.8984%] [G loss: 4.509079]\n",
            "0.6574435900668095 0.6594117647058824\n",
            "387 [D loss: 0.100012, acc.: 95.8496%] [G loss: 4.721385]\n",
            "0.6574435900668095 0.6594117647058824\n",
            "388 [D loss: 0.101114, acc.: 95.8618%] [G loss: 4.805625]\n",
            "0.6573175343501828 0.6594117647058824\n",
            "389 [D loss: 0.098928, acc.: 95.8374%] [G loss: 4.901094]\n",
            "0.657191478633556 0.6590441176470588\n",
            "390 [D loss: 0.100007, acc.: 95.7764%] [G loss: 4.949562]\n",
            "0.6570654229169293 0.6588970588235294\n",
            "391 [D loss: 0.103011, acc.: 95.2148%] [G loss: 4.766104]\n",
            "0.6570654229169293 0.65875\n",
            "392 [D loss: 0.094608, acc.: 95.9839%] [G loss: 4.999653]\n",
            "0.6570339089877726 0.6586764705882353\n",
            "393 [D loss: 0.103677, acc.: 95.8130%] [G loss: 5.074351]\n",
            "0.6570339089877726 0.6586764705882353\n",
            "394 [D loss: 0.096351, acc.: 95.9473%] [G loss: 4.934216]\n",
            "0.6570339089877726 0.6586764705882353\n",
            "395 [D loss: 0.099046, acc.: 96.0449%] [G loss: 5.123916]\n",
            "0.6570339089877726 0.6586764705882353\n",
            "396 [D loss: 0.105890, acc.: 95.5322%] [G loss: 4.978959]\n",
            "0.6569708811294592 0.6586764705882353\n",
            "397 [D loss: 0.100431, acc.: 95.6177%] [G loss: 5.270360]\n",
            "0.6570023950586159 0.6586764705882353\n",
            "398 [D loss: 0.094837, acc.: 95.9229%] [G loss: 5.237569]\n",
            "0.6569708811294592 0.6586764705882353\n",
            "399 [D loss: 0.095667, acc.: 96.1060%] [G loss: 5.482376]\n",
            "0.6569708811294592 0.6586764705882353\n",
            "400 [D loss: 0.101012, acc.: 95.8130%] [G loss: 4.993269]\n",
            "0.6569708811294592 0.6586764705882353\n",
            "401 [D loss: 0.094574, acc.: 95.8618%] [G loss: 5.412846]\n",
            "0.6570023950586159 0.6586764705882353\n",
            "402 [D loss: 0.101794, acc.: 95.8008%] [G loss: 5.176084]\n",
            "0.6569393672003025 0.6586029411764706\n",
            "403 [D loss: 0.100377, acc.: 95.6177%] [G loss: 5.416216]\n",
            "0.6569708811294592 0.6586029411764706\n",
            "404 [D loss: 0.093122, acc.: 96.0083%] [G loss: 5.542533]\n",
            "0.6569393672003025 0.6586029411764706\n",
            "405 [D loss: 0.098773, acc.: 95.8130%] [G loss: 5.469354]\n",
            "0.6569393672003025 0.6585294117647059\n",
            "406 [D loss: 0.094378, acc.: 96.1426%] [G loss: 5.460619]\n",
            "0.6568448254128325 0.6583823529411764\n",
            "407 [D loss: 0.101007, acc.: 95.7031%] [G loss: 5.360208]\n",
            "0.6568448254128325 0.6583823529411764\n",
            "408 [D loss: 0.100235, acc.: 95.6665%] [G loss: 5.237461]\n",
            "0.6568448254128325 0.6583823529411764\n",
            "409 [D loss: 0.095158, acc.: 95.7886%] [G loss: 5.669440]\n",
            "0.6568448254128325 0.6583823529411764\n",
            "410 [D loss: 0.094676, acc.: 95.7520%] [G loss: 5.479319]\n",
            "0.6568448254128325 0.6583823529411764\n",
            "411 [D loss: 0.099279, acc.: 95.6299%] [G loss: 5.526134]\n",
            "0.6568448254128325 0.6583823529411764\n",
            "412 [D loss: 0.087575, acc.: 96.1792%] [G loss: 5.410386]\n",
            "0.6568448254128325 0.6583823529411764\n",
            "413 [D loss: 0.092924, acc.: 95.9473%] [G loss: 5.541410]\n",
            "0.6568448254128325 0.6583823529411764\n",
            "414 [D loss: 0.100289, acc.: 95.6299%] [G loss: 5.435069]\n",
            "0.6568448254128325 0.6583823529411764\n",
            "415 [D loss: 0.092507, acc.: 95.6909%] [G loss: 5.407677]\n",
            "0.6568448254128325 0.6583823529411764\n",
            "416 [D loss: 0.093706, acc.: 95.9351%] [G loss: 5.517971]\n",
            "0.6568448254128325 0.6583823529411764\n",
            "417 [D loss: 0.095659, acc.: 95.9106%] [G loss: 5.710537]\n",
            "0.6568448254128325 0.6583823529411764\n",
            "418 [D loss: 0.101441, acc.: 95.8496%] [G loss: 5.669272]\n",
            "0.6568448254128325 0.6583823529411764\n",
            "419 [D loss: 0.095393, acc.: 95.7520%] [G loss: 5.704467]\n",
            "0.6568448254128325 0.6583823529411764\n",
            "420 [D loss: 0.096250, acc.: 95.9595%] [G loss: 5.660359]\n",
            "0.6568448254128325 0.6583823529411764\n",
            "421 [D loss: 0.091142, acc.: 95.8618%] [G loss: 5.389362]\n",
            "0.6568448254128325 0.6583823529411764\n",
            "422 [D loss: 0.093944, acc.: 95.9839%] [G loss: 5.680601]\n",
            "0.6568448254128325 0.6583823529411764\n",
            "423 [D loss: 0.089638, acc.: 96.0571%] [G loss: 5.658627]\n",
            "0.6568448254128325 0.6583823529411764\n",
            "424 [D loss: 0.094132, acc.: 96.0205%] [G loss: 5.779334]\n",
            "0.6568448254128325 0.6583823529411764\n",
            "425 [D loss: 0.094276, acc.: 95.8740%] [G loss: 5.706230]\n",
            "0.6568448254128325 0.6583823529411764\n",
            "426 [D loss: 0.095230, acc.: 95.6055%] [G loss: 5.971910]\n",
            "0.6568448254128325 0.6583823529411764\n",
            "427 [D loss: 0.098792, acc.: 95.7886%] [G loss: 6.119806]\n",
            "0.6568448254128325 0.6583823529411764\n",
            "428 [D loss: 0.092564, acc.: 95.8008%] [G loss: 6.111746]\n",
            "0.6568448254128325 0.6583823529411764\n",
            "429 [D loss: 0.093167, acc.: 96.1914%] [G loss: 6.127753]\n",
            "0.6568448254128325 0.6583823529411764\n",
            "430 [D loss: 0.101295, acc.: 95.8252%] [G loss: 5.851423]\n",
            "0.6568448254128325 0.6583823529411764\n",
            "431 [D loss: 0.092840, acc.: 95.9106%] [G loss: 5.735626]\n",
            "0.6568448254128325 0.6583823529411764\n",
            "432 [D loss: 0.098373, acc.: 95.8252%] [G loss: 5.878819]\n",
            "0.6568448254128325 0.6583823529411764\n",
            "433 [D loss: 0.098541, acc.: 95.7397%] [G loss: 6.238568]\n",
            "0.6568448254128325 0.6583823529411764\n",
            "434 [D loss: 0.091182, acc.: 95.9229%] [G loss: 6.022405]\n",
            "0.6568448254128325 0.6583823529411764\n",
            "435 [D loss: 0.097147, acc.: 95.9961%] [G loss: 6.074491]\n",
            "0.6568448254128325 0.6583823529411764\n",
            "436 [D loss: 0.100873, acc.: 95.5444%] [G loss: 6.126462]\n",
            "0.6568448254128325 0.6583823529411764\n",
            "437 [D loss: 0.092565, acc.: 95.9229%] [G loss: 5.846169]\n",
            "0.6568448254128325 0.6583823529411764\n",
            "438 [D loss: 0.096265, acc.: 95.8008%] [G loss: 6.354695]\n",
            "0.6568448254128325 0.6583823529411764\n",
            "439 [D loss: 0.101562, acc.: 95.5322%] [G loss: 6.135602]\n",
            "0.6568448254128325 0.6583823529411764\n",
            "440 [D loss: 0.092097, acc.: 96.0693%] [G loss: 5.928998]\n",
            "0.6568448254128325 0.6583823529411764\n",
            "441 [D loss: 0.095552, acc.: 95.9229%] [G loss: 6.456328]\n",
            "0.6568448254128325 0.6583823529411764\n",
            "442 [D loss: 0.094576, acc.: 95.6787%] [G loss: 6.313620]\n",
            "0.6568448254128325 0.6583823529411764\n",
            "443 [D loss: 0.087764, acc.: 96.0938%] [G loss: 6.329786]\n",
            "0.6568448254128325 0.6583823529411764\n",
            "444 [D loss: 0.091282, acc.: 96.0083%] [G loss: 6.170107]\n",
            "0.6568448254128325 0.6583823529411764\n",
            "445 [D loss: 0.094763, acc.: 96.0205%] [G loss: 6.556873]\n",
            "0.6568448254128325 0.6583823529411764\n",
            "446 [D loss: 0.098618, acc.: 95.7153%] [G loss: 6.293419]\n",
            "0.6568448254128325 0.6583823529411764\n",
            "447 [D loss: 0.089893, acc.: 95.9473%] [G loss: 6.299188]\n",
            "0.6568448254128325 0.6583823529411764\n",
            "448 [D loss: 0.091773, acc.: 96.1548%] [G loss: 6.535243]\n",
            "0.6568448254128325 0.6583823529411764\n",
            "449 [D loss: 0.085263, acc.: 96.2646%] [G loss: 6.293643]\n",
            "0.6568448254128325 0.6583823529411764\n",
            "450 [D loss: 0.093190, acc.: 95.7520%] [G loss: 6.759751]\n",
            "0.6568448254128325 0.6583823529411764\n",
            "451 [D loss: 0.093215, acc.: 96.0449%] [G loss: 6.417244]\n",
            "0.6568448254128325 0.6583823529411764\n",
            "452 [D loss: 0.091350, acc.: 95.9839%] [G loss: 6.445061]\n",
            "0.6568448254128325 0.6583823529411764\n",
            "453 [D loss: 0.092049, acc.: 95.9839%] [G loss: 6.756990]\n",
            "0.6568448254128325 0.6583823529411764\n",
            "454 [D loss: 0.087983, acc.: 96.0571%] [G loss: 7.123652]\n",
            "0.6568448254128325 0.6583823529411764\n",
            "455 [D loss: 0.090433, acc.: 95.9839%] [G loss: 6.552165]\n",
            "0.6568448254128325 0.6583823529411764\n",
            "456 [D loss: 0.088675, acc.: 96.0449%] [G loss: 6.407659]\n",
            "0.6568448254128325 0.6583823529411764\n",
            "457 [D loss: 0.086355, acc.: 96.2402%] [G loss: 6.613726]\n",
            "0.6568448254128325 0.6583823529411764\n",
            "458 [D loss: 0.093980, acc.: 95.7886%] [G loss: 6.986226]\n",
            "0.6568448254128325 0.6583823529411764\n",
            "459 [D loss: 0.088304, acc.: 96.2036%] [G loss: 6.656324]\n",
            "0.6568763393419892 0.6583823529411764\n",
            "460 [D loss: 0.088936, acc.: 96.3623%] [G loss: 7.019010]\n",
            "0.6568448254128325 0.6583823529411764\n",
            "461 [D loss: 0.095434, acc.: 95.6665%] [G loss: 6.810009]\n",
            "0.6568448254128325 0.6583823529411764\n",
            "462 [D loss: 0.093223, acc.: 95.9473%] [G loss: 7.319594]\n",
            "0.6568448254128325 0.6583823529411764\n",
            "463 [D loss: 0.092753, acc.: 95.8130%] [G loss: 6.821195]\n",
            "0.6568448254128325 0.6583823529411764\n",
            "464 [D loss: 0.096541, acc.: 95.6055%] [G loss: 7.358975]\n",
            "0.6568448254128325 0.6583823529411764\n",
            "465 [D loss: 0.090709, acc.: 95.8130%] [G loss: 6.705060]\n",
            "0.6568448254128325 0.6583823529411764\n",
            "466 [D loss: 0.090996, acc.: 96.2280%] [G loss: 6.887969]\n",
            "0.6568448254128325 0.6583823529411764\n",
            "467 [D loss: 0.095960, acc.: 95.8252%] [G loss: 7.124938]\n",
            "0.6568448254128325 0.6583823529411764\n",
            "468 [D loss: 0.087310, acc.: 96.2769%] [G loss: 7.058019]\n",
            "0.6568448254128325 0.6584558823529412\n",
            "469 [D loss: 0.097882, acc.: 95.7275%] [G loss: 7.159733]\n",
            "0.6568448254128325 0.6583823529411764\n",
            "470 [D loss: 0.089141, acc.: 96.2769%] [G loss: 6.828462]\n",
            "0.6568448254128325 0.6583823529411764\n",
            "471 [D loss: 0.091506, acc.: 95.8862%] [G loss: 6.863525]\n",
            "0.6568448254128325 0.6583823529411764\n",
            "472 [D loss: 0.092958, acc.: 95.9473%] [G loss: 7.176717]\n",
            "0.6568448254128325 0.6583823529411764\n",
            "473 [D loss: 0.092612, acc.: 95.9229%] [G loss: 6.923538]\n",
            "0.6568448254128325 0.6583823529411764\n",
            "474 [D loss: 0.095172, acc.: 95.6421%] [G loss: 7.806479]\n",
            "0.6568763393419892 0.6584558823529412\n",
            "475 [D loss: 0.096911, acc.: 95.8252%] [G loss: 7.593034]\n",
            "0.6569393672003025 0.6586029411764706\n",
            "476 [D loss: 0.085606, acc.: 96.2524%] [G loss: 7.310752]\n",
            "0.6569393672003025 0.6586029411764706\n",
            "477 [D loss: 0.094494, acc.: 95.8252%] [G loss: 7.236849]\n",
            "0.6569708811294592 0.6586029411764706\n",
            "478 [D loss: 0.086243, acc.: 96.1914%] [G loss: 7.514739]\n",
            "0.6569708811294592 0.6586764705882353\n",
            "479 [D loss: 0.090388, acc.: 96.1060%] [G loss: 7.500816]\n",
            "0.6569393672003025 0.6586764705882353\n",
            "480 [D loss: 0.090591, acc.: 95.7520%] [G loss: 7.344001]\n",
            "0.6569708811294592 0.6586764705882353\n",
            "481 [D loss: 0.089880, acc.: 95.9717%] [G loss: 7.406330]\n",
            "0.6569393672003025 0.6586764705882353\n",
            "482 [D loss: 0.093279, acc.: 95.9473%] [G loss: 7.523210]\n",
            "0.6569708811294592 0.6586029411764706\n",
            "483 [D loss: 0.093451, acc.: 95.8374%] [G loss: 7.353225]\n",
            "0.6569393672003025 0.6586029411764706\n",
            "484 [D loss: 0.090960, acc.: 95.9351%] [G loss: 7.813691]\n",
            "0.6569393672003025 0.6586029411764706\n",
            "485 [D loss: 0.087100, acc.: 96.0815%] [G loss: 7.917039]\n",
            "0.6569078532711459 0.6584558823529412\n",
            "486 [D loss: 0.091855, acc.: 95.9473%] [G loss: 7.592794]\n",
            "0.6569078532711459 0.6585294117647059\n",
            "487 [D loss: 0.095219, acc.: 95.8862%] [G loss: 7.456991]\n",
            "0.6568763393419892 0.6585294117647059\n",
            "488 [D loss: 0.089448, acc.: 96.1914%] [G loss: 7.763173]\n",
            "0.6568763393419892 0.6585294117647059\n",
            "489 [D loss: 0.095731, acc.: 96.0205%] [G loss: 7.723441]\n",
            "0.6568448254128325 0.6584558823529412\n",
            "490 [D loss: 0.086844, acc.: 96.0327%] [G loss: 8.186597]\n",
            "0.6568448254128325 0.6583823529411764\n",
            "491 [D loss: 0.097192, acc.: 95.4102%] [G loss: 8.038233]\n",
            "0.6568448254128325 0.6583823529411764\n",
            "492 [D loss: 0.091216, acc.: 96.0083%] [G loss: 7.608647]\n",
            "0.6568448254128325 0.6583823529411764\n",
            "493 [D loss: 0.092083, acc.: 95.7642%] [G loss: 7.927797]\n",
            "0.6568448254128325 0.6583823529411764\n",
            "494 [D loss: 0.090626, acc.: 95.8862%] [G loss: 8.244402]\n",
            "0.6568448254128325 0.6583823529411764\n",
            "495 [D loss: 0.087859, acc.: 96.2036%] [G loss: 8.201707]\n",
            "0.6568448254128325 0.6583823529411764\n",
            "496 [D loss: 0.090528, acc.: 96.0938%] [G loss: 7.993324]\n",
            "0.6568448254128325 0.6583823529411764\n",
            "497 [D loss: 0.090029, acc.: 95.9229%] [G loss: 8.460251]\n",
            "0.6568448254128325 0.6583823529411764\n",
            "498 [D loss: 0.091454, acc.: 96.2036%] [G loss: 8.265182]\n",
            "0.6568448254128325 0.6583823529411764\n",
            "499 [D loss: 0.092511, acc.: 95.9717%] [G loss: 8.543421]\n",
            "\n",
            "\n",
            "---GBC SameTrainData\n",
            "\n",
            "Original_Train_TPR: 0.9429913021555527, Adver_Train_TPR: 0.6568448254128325\n",
            "\n",
            "Original_Test_TPR: 0.9435294117647058, Adver_Test_TPR: 0.6583823529411764\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "---TPR after the blackbox_detector is retrained (Before retraining MalGAN).\n",
            "\n",
            "Train_TPR: 1.0, Test_TPR: 1.0\n",
            "[0.945480902558931] [0.9469117647058823] \n",
            "\n",
            "Training epochs.....\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "1.0 1.0\n",
            "\n",
            "\n",
            "---GBC SameTrainData\n",
            "\n",
            "Original_Train_TPR: 0.945480902558931, Adver_Train_TPR: 1.0\n",
            "\n",
            "Original_Test_TPR: 0.9469117647058823, Adver_Test_TPR: 1.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}